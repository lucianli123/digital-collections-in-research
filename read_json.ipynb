{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e763bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7947278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bbf72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def strip(s):\n",
    "    s=' '.join(s.split())\n",
    "    return re.sub(r'[^A-Za-z0-9 ]+', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8559dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(i):\n",
    "    date=i['datePublished']\n",
    "    title=i[\"title\"]\n",
    "    try:\n",
    "        authors=i[\"creator\"]\n",
    "    except:\n",
    "        authors=[]\n",
    "    try:\n",
    "        abstract=i['abstract']\n",
    "    except:\n",
    "        try:\n",
    "            abstract=i['keyphrase']\n",
    "        except:\n",
    "            abstract=\"\"\n",
    "    try:\n",
    "        url = i[\"doi\"]\n",
    "    except:\n",
    "        try:\n",
    "            url= i[\"id\"]\n",
    "        except:\n",
    "            url=\"\"\n",
    "    try:\n",
    "        tag=i[\"tdmCategory\"]\n",
    "    except:\n",
    "        tag=[]\n",
    "    try:\n",
    "        text=\"\"\n",
    "        for t in i[\"fullText\"]:\n",
    "            text+=t\n",
    "            text+=\" \"\n",
    "        text=strip(text)\n",
    "    except:\n",
    "        text=i[\"unigramCount\"]\n",
    "    try:\n",
    "        journal=i[\"isPartOf\"]\n",
    "    except:\n",
    "        try:\n",
    "            journal=i[\"publisher\"]\n",
    "        except:\n",
    "            journal=\"\"\n",
    "    return [date,title,tag, authors,abstract,text,url, journal]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d769ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08a89836-6f0b-fdba-e0c7-ed5ce511059f-jsonl.jsonl\n",
      "1879b970-bc49-8f12-b8d5-e9279ace8f33-jsonl.jsonl\n",
      "1879b970-bc49-8f12-b8d5-e9279ace8f33-sampled-jsonl.jsonl\n",
      "49b3f7b9-835a-8f33-ea27-5e303125247c-jsonl.jsonl\n",
      "4d634c82-7b8e-ee41-12d4-93aa8435de25-jsonl.jsonl\n",
      "64c11d86-45cb-7312-da8b-b8e222d52ff6-jsonl.jsonl\n",
      "75715766-a042-4820-5155-1d67c5f5e801-jsonl.jsonl\n",
      "8d492fd9-b327-ba11-2ea2-df1bc76d26c0-jsonl.jsonl\n",
      "b382a487-73af-bdf6-f98a-8f1ff1849902-jsonl.jsonl\n",
      "bc55078a-82ca-cfa3-e885-72fae3d7dd61-jsonl.jsonl\n",
      "c508f178-ee0c-4fca-86ac-8aa203500c44-jsonl.jsonl\n",
      "da5068fb-dedb-2b04-edb2-1b0cbc5eab1b-jsonl.jsonl\n",
      "f86b2b79-a93e-c952-a4f5-f231fd0c2518-jsonl.jsonl\n",
      "fc2dcb98-c985-bfe3-cd2b-8616fe68f932-jsonl.jsonl\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "ret=[]\n",
    "for file in glob.glob(\"*.jsonl\"):\n",
    "    print(file)\n",
    "    data=[]\n",
    "    #with open('49b3f7b9-835a-8f33-ea27-5e303125247c-jsonl.jsonl/49b3f7b9-835a-8f33-ea27-5e303125247c-jsonl.jsonl') as f:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    for d in data:\n",
    "        ret.append(annotate(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d58e95d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a06fbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(ret)\n",
    "df.columns=[\"date\", \"title\",\"tag\",\"author\", \"abstract\", \"text\", \"url\", \"journal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c45e87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht=df[df['text'].apply(lambda x: not isinstance(x, str))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9431e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht=df[df[\"text\"]!=\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa32159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht=ht.drop_duplicates([\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "990b0314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>Frequency distributions of punctuation marks i...</td>\n",
       "      <td>[Linguistics - Language]</td>\n",
       "      <td>[Rong Wang, Kun Sun]</td>\n",
       "      <td>[punctuation, frequency, frequency distributio...</td>\n",
       "      <td>{'use,': 1, 'referee': 1, 'suggestions': 2, 'i...</td>\n",
       "      <td>10.1017/S0266078418000512</td>\n",
       "      <td>English Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Technological Innovation: On the Origins and D...</td>\n",
       "      <td>[Biological sciences - Ecology, Philosophy - A...</td>\n",
       "      <td>[BENOÎT GODIN]</td>\n",
       "      <td>Over the last several decades, many students o...</td>\n",
       "      <td>{'disorder': 1, '57.': 1, '1898-1930.\"': 1, '(...</td>\n",
       "      <td>http://www.jstor.org/stable/44017443</td>\n",
       "      <td>Technology and Culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>Unit</td>\n",
       "      <td>[Arts - Art history]</td>\n",
       "      <td>[ANDREW M. SHANKEN]</td>\n",
       "      <td>This essay peers through the peephole of the w...</td>\n",
       "      <td>{'(Lon-': 1, 'double': 1, 'however,': 2, '105....</td>\n",
       "      <td>http://www.jstor.org/stable/26504452</td>\n",
       "      <td>Representations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>List of illustrations</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Lin Foxhall]</td>\n",
       "      <td></td>\n",
       "      <td>{'right': 2, '(Whitby': 1, 'text': 1, '2008,':...</td>\n",
       "      <td>ark://27927/phzntngp2c5</td>\n",
       "      <td>Interrogating Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>GAY RIGHTS AND THE CONSTITUTION OF REASONS</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[Stephen Macedo]</td>\n",
       "      <td>AbstractThe public debate over gay rights gene...</td>\n",
       "      <td>{'whether': 8, 'doctor’s': 1, 'people.': 1, 's...</td>\n",
       "      <td>10.2307/j.ctt1h4mhnr.5</td>\n",
       "      <td>Just Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>American Association for the History of Medicine</td>\n",
       "      <td>[Education - Educational resources, Informatio...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'composed': 1, 'money-losing': 1, 'Juan,': 1,...</td>\n",
       "      <td>http://www.jstor.org/stable/26305938</td>\n",
       "      <td>Bulletin of the History of Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>Marianne Moore’s Cabinets of Curiosity</td>\n",
       "      <td>[Arts - Art history]</td>\n",
       "      <td>[Sarah Berry]</td>\n",
       "      <td>[decorative art, objects, art objects, decorat...</td>\n",
       "      <td>{'spectrum’s': 1, 'semiophore,': 2, 'maintaine...</td>\n",
       "      <td>ark://27927/phz31mpv8b5</td>\n",
       "      <td>Journal of Modern Literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>HUMAN AND CIVIL RIGHTS IN AFRICA AND THE DIASPORA</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[BONNY IBHAWOH]</td>\n",
       "      <td>[rights, africa, global africa, african diaspo...</td>\n",
       "      <td>{'concept': 1, 'follow': 1, 'context,': 1, 'st...</td>\n",
       "      <td>10.1017/S0021853719000288</td>\n",
       "      <td>The Journal of African History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>Court Painting at Udaipur: Art under the Patro...</td>\n",
       "      <td>[Religion - Spiritual belief systems]</td>\n",
       "      <td>[Andrew Topsfield]</td>\n",
       "      <td></td>\n",
       "      <td>{'grow-': 1, '27,': 11, 'thicket,': 1, '37)116...</td>\n",
       "      <td>http://www.jstor.org/stable/1522717</td>\n",
       "      <td>Artibus Asiae. Supplementum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>Poster Presentations</td>\n",
       "      <td>[Health sciences - Medical specialties]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[endoscopy, colonoscopy, patients, imaging dia...</td>\n",
       "      <td>{'CORNU,': 2, '49+10': 1, 'leguminous': 3, '(T...</td>\n",
       "      <td>10.1111/jgh.12363_2</td>\n",
       "      <td>Journal of Gastroenterology and Hepatology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7662 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                              title  \\\n",
       "37     2019-12-01  Frequency distributions of punctuation marks i...   \n",
       "38     2016-07-01  Technological Innovation: On the Origins and D...   \n",
       "39     2018-07-01                                               Unit   \n",
       "40     2021-06-30                              List of illustrations   \n",
       "41     2015-06-09         GAY RIGHTS AND THE CONSTITUTION OF REASONS   \n",
       "...           ...                                                ...   \n",
       "13294  2013-10-01   American Association for the History of Medicine   \n",
       "13297  2018-08-15             Marianne Moore’s Cabinets of Curiosity   \n",
       "13298  2019-03-01  HUMAN AND CIVIL RIGHTS IN AFRICA AND THE DIASPORA   \n",
       "13299  2002-01-01  Court Painting at Udaipur: Art under the Patro...   \n",
       "13300  2013-10-01                               Poster Presentations   \n",
       "\n",
       "                                                     tag  \\\n",
       "37                              [Linguistics - Language]   \n",
       "38     [Biological sciences - Ecology, Philosophy - A...   \n",
       "39                                  [Arts - Art history]   \n",
       "40                                                    []   \n",
       "41                     [Philosophy - Applied philosophy]   \n",
       "...                                                  ...   \n",
       "13294  [Education - Educational resources, Informatio...   \n",
       "13297                               [Arts - Art history]   \n",
       "13298                  [Philosophy - Applied philosophy]   \n",
       "13299              [Religion - Spiritual belief systems]   \n",
       "13300            [Health sciences - Medical specialties]   \n",
       "\n",
       "                     author  \\\n",
       "37     [Rong Wang, Kun Sun]   \n",
       "38           [BENOÎT GODIN]   \n",
       "39      [ANDREW M. SHANKEN]   \n",
       "40            [Lin Foxhall]   \n",
       "41         [Stephen Macedo]   \n",
       "...                     ...   \n",
       "13294                    []   \n",
       "13297         [Sarah Berry]   \n",
       "13298       [BONNY IBHAWOH]   \n",
       "13299    [Andrew Topsfield]   \n",
       "13300                    []   \n",
       "\n",
       "                                                abstract  \\\n",
       "37     [punctuation, frequency, frequency distributio...   \n",
       "38     Over the last several decades, many students o...   \n",
       "39     This essay peers through the peephole of the w...   \n",
       "40                                                         \n",
       "41     AbstractThe public debate over gay rights gene...   \n",
       "...                                                  ...   \n",
       "13294                                                      \n",
       "13297  [decorative art, objects, art objects, decorat...   \n",
       "13298  [rights, africa, global africa, african diaspo...   \n",
       "13299                                                      \n",
       "13300  [endoscopy, colonoscopy, patients, imaging dia...   \n",
       "\n",
       "                                                    text  \\\n",
       "37     {'use,': 1, 'referee': 1, 'suggestions': 2, 'i...   \n",
       "38     {'disorder': 1, '57.': 1, '1898-1930.\"': 1, '(...   \n",
       "39     {'(Lon-': 1, 'double': 1, 'however,': 2, '105....   \n",
       "40     {'right': 2, '(Whitby': 1, 'text': 1, '2008,':...   \n",
       "41     {'whether': 8, 'doctor’s': 1, 'people.': 1, 's...   \n",
       "...                                                  ...   \n",
       "13294  {'composed': 1, 'money-losing': 1, 'Juan,': 1,...   \n",
       "13297  {'spectrum’s': 1, 'semiophore,': 2, 'maintaine...   \n",
       "13298  {'concept': 1, 'follow': 1, 'context,': 1, 'st...   \n",
       "13299  {'grow-': 1, '27,': 11, 'thicket,': 1, '37)116...   \n",
       "13300  {'CORNU,': 2, '49+10': 1, 'leguminous': 3, '(T...   \n",
       "\n",
       "                                        url  \\\n",
       "37                10.1017/S0266078418000512   \n",
       "38     http://www.jstor.org/stable/44017443   \n",
       "39     http://www.jstor.org/stable/26504452   \n",
       "40                  ark://27927/phzntngp2c5   \n",
       "41                   10.2307/j.ctt1h4mhnr.5   \n",
       "...                                     ...   \n",
       "13294  http://www.jstor.org/stable/26305938   \n",
       "13297               ark://27927/phz31mpv8b5   \n",
       "13298             10.1017/S0021853719000288   \n",
       "13299   http://www.jstor.org/stable/1522717   \n",
       "13300                   10.1111/jgh.12363_2   \n",
       "\n",
       "                                          journal  \n",
       "37                                  English Today  \n",
       "38                         Technology and Culture  \n",
       "39                                Representations  \n",
       "40                         Interrogating Networks  \n",
       "41                                   Just Married  \n",
       "...                                           ...  \n",
       "13294         Bulletin of the History of Medicine  \n",
       "13297                Journal of Modern Literature  \n",
       "13298              The Journal of African History  \n",
       "13299                 Artibus Asiae. Supplementum  \n",
       "13300  Journal of Gastroenterology and Hepatology  \n",
       "\n",
       "[7662 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60de48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht.to_csv(\"jstor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdb81f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates([\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "162a4076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>The Development of Japan Special Operations Co...</td>\n",
       "      <td>[Political science - Military science, Philoso...</td>\n",
       "      <td>[Ryota Akiba]</td>\n",
       "      <td>It has been 71 years since Japan experienced w...</td>\n",
       "      <td>The Development of Japan Special Operations Co...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep13997</td>\n",
       "      <td>Daniel K. Inouye Asia-Pacific Center for Secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>@PhilosTEI:</td>\n",
       "      <td>[Information science - Informetrics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>The main objective of the CLARIN-NL project @ ...</td>\n",
       "      <td>UP 033 odijk odijkprinter 20171215 1557 Page 3...</td>\n",
       "      <td>http://www.jstor.org/stable/j.ctv3t5qjk.39</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Neither High-Church, Low-Church, nor No-Church...</td>\n",
       "      <td>[Arts - Literature, History - Historical metho...</td>\n",
       "      <td>[Christian Dickinson]</td>\n",
       "      <td>[church, bleak house, esther, religious, angli...</td>\n",
       "      <td>105325dickstudannu4920349 Dickens Studies Annu...</td>\n",
       "      <td>ark://27927/phzjr66v4k5</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Searching for Dr. Johnson:</td>\n",
       "      <td>[Information science - Informetrics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>As you enter the Rare Books and Music Reading ...</td>\n",
       "      <td>Part 3 Archival Limits  UN</td>\n",
       "      <td>http://www.jstor.org/stable/10.1163/j.ctvbqs8w9.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>“RESEARCH BASED ADVOCACY FOR POLICY CHANGE: Ba...</td>\n",
       "      <td>[Business - Industry]</td>\n",
       "      <td>[Shiza Durrani, Hafsa Bashir, Mahmood A. Khwaja]</td>\n",
       "      <td>Mercury is naturally occurring element in envi...</td>\n",
       "      <td>EXECUTIVE SUMMARY This report describes and di...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep24369</td>\n",
       "      <td>Sustainable Development Policy Institute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13294</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>American Association for the History of Medicine</td>\n",
       "      <td>[Education - Educational resources, Informatio...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.jstor.org/stable/26305938</td>\n",
       "      <td>The Johns Hopkins University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>Marianne Moore’s Cabinets of Curiosity</td>\n",
       "      <td>[Arts - Art history]</td>\n",
       "      <td>[Sarah Berry]</td>\n",
       "      <td>[decorative art, objects, art objects, decorat...</td>\n",
       "      <td></td>\n",
       "      <td>ark://27927/phz31mpv8b5</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>HUMAN AND CIVIL RIGHTS IN AFRICA AND THE DIASPORA</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[BONNY IBHAWOH]</td>\n",
       "      <td>[rights, africa, global africa, african diaspo...</td>\n",
       "      <td></td>\n",
       "      <td>10.1017/S0021853719000288</td>\n",
       "      <td>Cambridge University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>Court Painting at Udaipur: Art under the Patro...</td>\n",
       "      <td>[Religion - Spiritual belief systems]</td>\n",
       "      <td>[Andrew Topsfield]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.jstor.org/stable/1522717</td>\n",
       "      <td>Artibus Asiae Publishers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>Poster Presentations</td>\n",
       "      <td>[Health sciences - Medical specialties]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[endoscopy, colonoscopy, patients, imaging dia...</td>\n",
       "      <td></td>\n",
       "      <td>10.1111/jgh.12363_2</td>\n",
       "      <td>John Wiley &amp; Sons, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8071 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                              title  \\\n",
       "0      2017-05-24  The Development of Japan Special Operations Co...   \n",
       "1      2017-01-01                                        @PhilosTEI:   \n",
       "2      2018-01-01  Neither High-Church, Low-Church, nor No-Church...   \n",
       "3      2018-01-01                         Searching for Dr. Johnson:   \n",
       "4      2018-09-01  “RESEARCH BASED ADVOCACY FOR POLICY CHANGE: Ba...   \n",
       "...           ...                                                ...   \n",
       "13294  2013-10-01   American Association for the History of Medicine   \n",
       "13297  2018-08-15             Marianne Moore’s Cabinets of Curiosity   \n",
       "13298  2019-03-01  HUMAN AND CIVIL RIGHTS IN AFRICA AND THE DIASPORA   \n",
       "13299  2002-01-01  Court Painting at Udaipur: Art under the Patro...   \n",
       "13300  2013-10-01                               Poster Presentations   \n",
       "\n",
       "                                                     tag  \\\n",
       "0      [Political science - Military science, Philoso...   \n",
       "1                   [Information science - Informetrics]   \n",
       "2      [Arts - Literature, History - Historical metho...   \n",
       "3                   [Information science - Informetrics]   \n",
       "4                                  [Business - Industry]   \n",
       "...                                                  ...   \n",
       "13294  [Education - Educational resources, Informatio...   \n",
       "13297                               [Arts - Art history]   \n",
       "13298                  [Philosophy - Applied philosophy]   \n",
       "13299              [Religion - Spiritual belief systems]   \n",
       "13300            [Health sciences - Medical specialties]   \n",
       "\n",
       "                                                 author  \\\n",
       "0                                         [Ryota Akiba]   \n",
       "1                                                    []   \n",
       "2                                 [Christian Dickinson]   \n",
       "3                                                    []   \n",
       "4      [Shiza Durrani, Hafsa Bashir, Mahmood A. Khwaja]   \n",
       "...                                                 ...   \n",
       "13294                                                []   \n",
       "13297                                     [Sarah Berry]   \n",
       "13298                                   [BONNY IBHAWOH]   \n",
       "13299                                [Andrew Topsfield]   \n",
       "13300                                                []   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      It has been 71 years since Japan experienced w...   \n",
       "1      The main objective of the CLARIN-NL project @ ...   \n",
       "2      [church, bleak house, esther, religious, angli...   \n",
       "3      As you enter the Rare Books and Music Reading ...   \n",
       "4      Mercury is naturally occurring element in envi...   \n",
       "...                                                  ...   \n",
       "13294                                                      \n",
       "13297  [decorative art, objects, art objects, decorat...   \n",
       "13298  [rights, africa, global africa, african diaspo...   \n",
       "13299                                                      \n",
       "13300  [endoscopy, colonoscopy, patients, imaging dia...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      The Development of Japan Special Operations Co...   \n",
       "1      UP 033 odijk odijkprinter 20171215 1557 Page 3...   \n",
       "2      105325dickstudannu4920349 Dickens Studies Annu...   \n",
       "3                             Part 3 Archival Limits  UN   \n",
       "4      EXECUTIVE SUMMARY This report describes and di...   \n",
       "...                                                  ...   \n",
       "13294                                                      \n",
       "13297                                                      \n",
       "13298                                                      \n",
       "13299                                                      \n",
       "13300                                                      \n",
       "\n",
       "                                                     url  \\\n",
       "0                http://www.jstor.org/stable/resrep13997   \n",
       "1             http://www.jstor.org/stable/j.ctv3t5qjk.39   \n",
       "2                                ark://27927/phzjr66v4k5   \n",
       "3      http://www.jstor.org/stable/10.1163/j.ctvbqs8w9.8   \n",
       "4                http://www.jstor.org/stable/resrep24369   \n",
       "...                                                  ...   \n",
       "13294               http://www.jstor.org/stable/26305938   \n",
       "13297                            ark://27927/phz31mpv8b5   \n",
       "13298                          10.1017/S0021853719000288   \n",
       "13299                http://www.jstor.org/stable/1522717   \n",
       "13300                                10.1111/jgh.12363_2   \n",
       "\n",
       "                                                 journal  \n",
       "0      Daniel K. Inouye Asia-Pacific Center for Secur...  \n",
       "1                                                         \n",
       "2                                           Project MUSE  \n",
       "3                                                         \n",
       "4               Sustainable Development Policy Institute  \n",
       "...                                                  ...  \n",
       "13294                 The Johns Hopkins University Press  \n",
       "13297                                       Project MUSE  \n",
       "13298                         Cambridge University Press  \n",
       "13299                           Artibus Asiae Publishers  \n",
       "13300                            John Wiley & Sons, Inc.  \n",
       "\n",
       "[8071 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c271ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"jstor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f2620a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>author</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-06-10</td>\n",
       "      <td>Digital Comics, Circulation, and the Importanc...</td>\n",
       "      <td>[Arts - Literature, Education - Educational re...</td>\n",
       "      <td>[Darren S. -- (Darren Sean),  -- Wershler-Henry]</td>\n",
       "      <td>[comics, digital comics, marvel, fantastic fou...</td>\n",
       "      <td>Cinema Journal 50  No 3  Spring 2011 127 Digit...</td>\n",
       "      <td>10.1353/cj.2011.0035</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Does Culture Determine Democratic Leadership i...</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[Bumsoo Kim, Sunhyuk Kim]</td>\n",
       "      <td>[chosun ilbo, president, leadership, moo hyun,...</td>\n",
       "      <td>Does Culture Determine Democratic Leadership i...</td>\n",
       "      <td>10.1353/apr.2013.0015</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>Social Media in Dental Education: A Call for R...</td>\n",
       "      <td>[Education - Educational resources]</td>\n",
       "      <td>[Marnie Oakley D.M.D., Heiko Spallek D.M.D.,  ...</td>\n",
       "      <td>[social, facebook, accessed, students, profess...</td>\n",
       "      <td>March 2012  Journal of Dental Education 279 So...</td>\n",
       "      <td>10.1002/j.0022-0337.2012.76.3.tb05256.x</td>\n",
       "      <td>John Wiley &amp; Sons, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>Capital after Capitalism: The Evolution of the...</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[Hardy Hanappi]</td>\n",
       "      <td></td>\n",
       "      <td>World revieW of Political economy vol 9 no 1 S...</td>\n",
       "      <td>10.13169/worlrevipoliecon.9.1.0061</td>\n",
       "      <td>Pluto Journals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Jethro Tull's Protegee: Vernon Tull's Helping ...</td>\n",
       "      <td>[Arts - Literature]</td>\n",
       "      <td>[Cliff Staebler]</td>\n",
       "      <td>[spotted horses, staebler jethro, wallstreet p...</td>\n",
       "      <td>Jethro Tulls Protegee Vernon Tulls Helping Han...</td>\n",
       "      <td>10.1353/fau.2015.0007</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Front Matter</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Andrew Kelly]</td>\n",
       "      <td>[isbn digital, digital ebook, corin throsby, a...</td>\n",
       "      <td></td>\n",
       "      <td>http://www.jstor.org/stable/j.ctv5zfv3m.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>Hacktivism and the Humanities:</td>\n",
       "      <td>[Philosophy - Applied philosophy]</td>\n",
       "      <td>[]</td>\n",
       "      <td>On June 16, 2009, Professor Cathy Davidson of ...</td>\n",
       "      <td>part iii  Chapter 10 Hacktivism and the Humani...</td>\n",
       "      <td>http://www.jstor.org/stable/10.5749/j.ctttv8hq.13</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>DOMESTIC INTELLIGENCE: NEW POWERS, NEW RISKS</td>\n",
       "      <td>[Law - Judicial system, Law - Criminal law]</td>\n",
       "      <td>[Emily Berman]</td>\n",
       "      <td>Each of the following examples of law enforcem...</td>\n",
       "      <td>InTRoduCTIon Each of the following examples of...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep28471</td>\n",
       "      <td>Brennan Center for Justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>EVALUATION OF THE 2015 DOD CYBER STRATEGY: MIL...</td>\n",
       "      <td>[Law - Computer law]</td>\n",
       "      <td>[Jeffrey L. Caton]</td>\n",
       "      <td>In 2011, the Department of Defense (DoD) relea...</td>\n",
       "      <td>FOR THIS AND OTHER PUBLICATIONS VISIT US AT ar...</td>\n",
       "      <td>http://www.jstor.org/stable/resrep11354</td>\n",
       "      <td>Strategic Studies Institute, US Army War College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2007-04-06</td>\n",
       "      <td>From Fair Use to Exemption</td>\n",
       "      <td>[Law - Computer law]</td>\n",
       "      <td>[Peter. Decherney]</td>\n",
       "      <td>[fair use, exemption, digital, digital media, ...</td>\n",
       "      <td>he finds the protection of old business models...</td>\n",
       "      <td>10.1353/cj.2007.0012</td>\n",
       "      <td>Project MUSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                              title  \\\n",
       "0    2011-06-10  Digital Comics, Circulation, and the Importanc...   \n",
       "1    2013-01-01  Does Culture Determine Democratic Leadership i...   \n",
       "2    2012-03-01  Social Media in Dental Education: A Call for R...   \n",
       "3    2018-04-01  Capital after Capitalism: The Evolution of the...   \n",
       "4    2015-01-01  Jethro Tull's Protegee: Vernon Tull's Helping ...   \n",
       "..          ...                                                ...   \n",
       "316  2018-01-01                                       Front Matter   \n",
       "317  2012-01-01                     Hacktivism and the Humanities:   \n",
       "318  2011-01-01       DOMESTIC INTELLIGENCE: NEW POWERS, NEW RISKS   \n",
       "319  2017-11-01  EVALUATION OF THE 2015 DOD CYBER STRATEGY: MIL...   \n",
       "320  2007-04-06                         From Fair Use to Exemption   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    [Arts - Literature, Education - Educational re...   \n",
       "1                    [Philosophy - Applied philosophy]   \n",
       "2                  [Education - Educational resources]   \n",
       "3                    [Philosophy - Applied philosophy]   \n",
       "4                                  [Arts - Literature]   \n",
       "..                                                 ...   \n",
       "316                                                 []   \n",
       "317                  [Philosophy - Applied philosophy]   \n",
       "318        [Law - Judicial system, Law - Criminal law]   \n",
       "319                               [Law - Computer law]   \n",
       "320                               [Law - Computer law]   \n",
       "\n",
       "                                                author  \\\n",
       "0     [Darren S. -- (Darren Sean),  -- Wershler-Henry]   \n",
       "1                            [Bumsoo Kim, Sunhyuk Kim]   \n",
       "2    [Marnie Oakley D.M.D., Heiko Spallek D.M.D.,  ...   \n",
       "3                                      [Hardy Hanappi]   \n",
       "4                                     [Cliff Staebler]   \n",
       "..                                                 ...   \n",
       "316                                     [Andrew Kelly]   \n",
       "317                                                 []   \n",
       "318                                     [Emily Berman]   \n",
       "319                                 [Jeffrey L. Caton]   \n",
       "320                                 [Peter. Decherney]   \n",
       "\n",
       "                                              abstract  \\\n",
       "0    [comics, digital comics, marvel, fantastic fou...   \n",
       "1    [chosun ilbo, president, leadership, moo hyun,...   \n",
       "2    [social, facebook, accessed, students, profess...   \n",
       "3                                                        \n",
       "4    [spotted horses, staebler jethro, wallstreet p...   \n",
       "..                                                 ...   \n",
       "316  [isbn digital, digital ebook, corin throsby, a...   \n",
       "317  On June 16, 2009, Professor Cathy Davidson of ...   \n",
       "318  Each of the following examples of law enforcem...   \n",
       "319  In 2011, the Department of Defense (DoD) relea...   \n",
       "320  [fair use, exemption, digital, digital media, ...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Cinema Journal 50  No 3  Spring 2011 127 Digit...   \n",
       "1    Does Culture Determine Democratic Leadership i...   \n",
       "2    March 2012  Journal of Dental Education 279 So...   \n",
       "3    World revieW of Political economy vol 9 no 1 S...   \n",
       "4    Jethro Tulls Protegee Vernon Tulls Helping Han...   \n",
       "..                                                 ...   \n",
       "316                                                      \n",
       "317  part iii  Chapter 10 Hacktivism and the Humani...   \n",
       "318  InTRoduCTIon Each of the following examples of...   \n",
       "319  FOR THIS AND OTHER PUBLICATIONS VISIT US AT ar...   \n",
       "320  he finds the protection of old business models...   \n",
       "\n",
       "                                                   url  \\\n",
       "0                                 10.1353/cj.2011.0035   \n",
       "1                                10.1353/apr.2013.0015   \n",
       "2              10.1002/j.0022-0337.2012.76.3.tb05256.x   \n",
       "3                   10.13169/worlrevipoliecon.9.1.0061   \n",
       "4                                10.1353/fau.2015.0007   \n",
       "..                                                 ...   \n",
       "316          http://www.jstor.org/stable/j.ctv5zfv3m.1   \n",
       "317  http://www.jstor.org/stable/10.5749/j.ctttv8hq.13   \n",
       "318            http://www.jstor.org/stable/resrep28471   \n",
       "319            http://www.jstor.org/stable/resrep11354   \n",
       "320                               10.1353/cj.2007.0012   \n",
       "\n",
       "                                              journal  \n",
       "0                                        Project MUSE  \n",
       "1                                        Project MUSE  \n",
       "2                             John Wiley & Sons, Inc.  \n",
       "3                                      Pluto Journals  \n",
       "4                                        Project MUSE  \n",
       "..                                                ...  \n",
       "316                                                    \n",
       "317                                                    \n",
       "318                        Brennan Center for Justice  \n",
       "319  Strategic Studies Institute, US Army War College  \n",
       "320                                      Project MUSE  \n",
       "\n",
       "[321 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f03fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63f831f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creator': ['Jiayong Liu', 'Cheng Huang', 'Liguo Zhang', 'Shun Lv', 'Yu Su'],\n",
       " 'datePublished': '2020-12-17',\n",
       " 'docType': 'article',\n",
       " 'doi': '10.1155/2020/6662166',\n",
       " 'fullText': [\"Research Article\\nDetecting Web Spam Based on Novel Features from Web Page\\nSource Code\\nJiayong Liu,1 Yu Su,1 Shun Lv,2 and Cheng Huang 1\\n1College of Cybersecurity, Sichuan University, Chengdu, China\\n2College of Computer Science, Sichuan University, Chengdu, Sichuan, China\\nCorrespondence should be addressed to Cheng Huang; opcodesec@gmail.com\\nReceived 1 November 2020; Revised 24 November 2020; Accepted 4 December 2020; Published 17 December 2020\\nAcademic Editor: Liguo Zhang\\nCopyright © 2020 Jiayong Liu et al. 'is is an open access article distributed under the Creative Commons Attribution License,\\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\\nSearch engine is critical in people’s daily life because it determines the information quality people obtain through searching. Fierce\\ncompetition for the ranking in search engines is not conducive to both users and search engines. Existing research mainly studies\\nthe content and links of websites. However, none of these techniques focused on semantic analysis of link and anchor text for\\ndetection. In this paper, we propose a web spam detection method by extracting novel feature sets from the homepage source code\\nand choosing the random forest (RF) as the classifier. 'e novel feature sets are extracted from the homepage’s links, hypertext\\nmarkup language (HTML) structure, and semantic similarity of content. We conduct experiments on the WEBSPAM-UK2007\\nand UK-2011 dataset using a five-fold cross-validation method. Besides, we design three sets of experiments to evaluate the\\nperformance of the proposed method.'e proposed method with novel feature sets is compared with different indicators and has\\nbetter performance than other methods with a precision of 0.929 and a recall of 0.930. Experiment results show that the proposed\\nmodel could effectively detect web spam.\\n1. Introduction\\nWith the rapid development of the network, web applications\\nare becoming more and more popular in the recent years,\\namong which search engines are one of the most common web\\ntools for people to gain information every day [1]. As the most\\npopular search engine worldwide, Google processes over 40,000\\nsearch queries every second on average, which translates to over\\n3.5 billion searches per day and 1.2 trillion searches per year\\nworldwide in 2012 [2]. 'ere are data [3, 4] indicating that 85%\\nof Internet users find websites through search engines and 90%\\nof Internet users do not go past the first three pages on search\\nresults. Spammers design pages delicately to improve rankings\\nas most users only access the first page of search results. 'ere\\nhas been a brief definition of web spamming in the literature [5];\\nshortly speaking, web spamming is a black-hat search engine\\noptimization (SEO) that deceive search engines to increase the\\nranking of a page in search engine results. 'ese web pages are\\ncalled web spam. As evident, spammers try to deceive search\\nengines and attract end users to click on web spam sites. 'ey\\nnot only reduce the effectiveness and efficiency of search engine\\nresults sinceweb spampages takemuch time to process butmay\\nalso be full of malicious content and links. Lina et al. [6] present\\nthreats and related attacks about web spam. Although search\\nengine companies have utilized various methods to counter\\nspam [7], it is still a challenge to prevent the increase of blackhat\\nSEO technology and the growth of spam pages nowadays.\\n'erefore, it is of great significance to detect web spam with\\nefficiency and accuracy.\\nMany researchers and experts have conducted much\\nresearch on spam in this field. Several researchers have relied\\non feature extraction from text and links on the web page\\n[8, 9]. Some other researchers detect web spam by crawlers\\nobserving different versions of the web page returned to\\nsearch engines and ordinary users [10, 11], as well as there\\nare methods based on spam purposes and user access logs\\n[12]. Detection methods have also evolved continuously\\nfrom the original statistical characteristics to determine\\nwhether a web page is spam to automatic monitoring using\\nmachine learning and deep learning, and the efficiency and\\nHindawi\\nSecurity and Communication Networks\\nVolume 2020, Article ID 6662166, 14 pages\\nhttps://doi.org/10.1155/2020/6662166\\n\",\n",
       "  \"accuracy of detection are also continuously improved. We\\nare motivated by previous work in the field of web spam\\ndetection and cybersecurity, which has proved the viability\\nof web spam detection using a combination of machine\\nlearning and effective features. We use similar insights to\\nsupport the discovery of web spam based on novel features.\\nOur method is different from that in previous studies in that\\nwe extract not only link-based statistical features but also\\nsemantic features based on text content analysis and\\nstructural features based on the structure of web pages from\\nthe source code. Additionally, in terms of real-world aerial\\napplications, the proposed method could be deployed in the\\nbrowser. For example, the judgment of each web page in the\\nusers’ search results by the proposed method can provide\\nconstructive conclusions to users and browser manufacturers.\\nAs the proposed method has features based on se-\\nmantics, it is helpful to detect spam in web pages where links\\nto spam content are easily injected into.\\nIn this paper, we proposed a method using machine\\nlearning algorithm RF that combines feature extraction and\\nfeature selection to classify whether a web page is spam or not.\\nNote that, for a binary classification problem, the classifier\\naims to distinguish the web page as spam or nonspam. 'e\\nmain contributions of this paper are as follows:\\n(1) 'is paper considers some previously undescribed\\nfeatures for web spam detection. We extract three\\nnovel feature subsets by studying homepage’s links,\\ntexts, and structure based on statistical and semantic\\nsimilarity analysis. 'e experimental results prove\\nthat the importance of novel features ranks high and\\neffective.\\n(2) 'is paper applies a feature selection method for\\nprecomputed features related to the homepage to\\nreduce computational consumption and improve\\naccuracy. We introduce random forest algorithm for\\nbuilding the web spam detection model. 'e method\\ncould automatically distinguish web spam and a\\nnormal page from the website homepage.\\n(3) We evaluate the proposed method with comprehensive\\nevaluation metrics for binary classification\\nproblems. Our method achieves the F1 score of\\n92.9%, which is higher than that of the existing\\nmethods. 'e experimental results show that our\\nmethod can effectively detect web spam.\\n'e rest of this paper is organized as follows. Section 2\\npresents related work regarding web spam detection. Section\\n3 describes the proposed approach in detail, and Section 4\\nevaluates the proposed method and the results of our experiments.\\nFinally, we discuss our conclusions and future\\nwork.\\n2. Related Work\\nWeb spam is often categorized into four classes: content\\nspam, link spam, cloaking, and redirection. Several researchers\\nand experts present kinds of methods to combat\\nweb spam correspondingly.\\n'ere were many research methods from different\\nperspectives in the early stages. For example, Jakub Piskorski\\net al. [13] explored linguistic features focused on the utility of\\ncontent-based linguistic features with computing 208 linguistic\\nattributes, Benczúr et al. [14] conducted commercial\\nintent analysis because other than the ordinary methods\\ndepending on the website itself; the authors thought much\\nweb spam was for commercial purpose, Bı́ró et al. [15]\\napplied an extension of latent Dirichlet allocation (LDA)\\nwhich is a linked LDA technique for web spam classification\\nsince topics are propagated along with links in such a way\\nthat the linked document directly influences the words in the\\nlinking document, and Liu et al. [16] analyzed web spam\\nwith user behavior where user visiting patterns of spam\\npages and three user behavior features are proposed to\\nseparate web spam from ordinary ones. Luca et al. [17]\\nstudied the spectrum of black-hat cloaking techniques that\\ntarget browser, network, or contextual cues to detect organic\\nvisitors. 'eir anticloaking system can detect whether a web\\npage would split view content returned to two or more\\ndistinct browsing profiles.\\nWith machine learning developing by, a plurality of\\npopular machine learning algorithms combined with sorts of\\nfeature engineering methods are applied to detect web spam.\\nMachine learning techniques are more flexible than other\\nmethods; some difficult problems can be solved and more\\naccuracy becomes a reality. Liu et al. [18] used a sentiment\\nanalysis model based on topic enhanced word embedding to\\nobtain more complete text context information. 'e document\\ntopic distribution matrix is used to extract the\\ndocument features. Reza Mohammadi et al. [19] proposed a\\nmethod to improve support vector machine (SVM) algorithm\\nby using two nonlinear kernels in twin support vector\\nmachine (MKTWSVM), which was experimented on both\\nUK-2006 and UK-2007 datasets. 'e authors used a language-model\\napproach and qualified-link analysis on de-\\ntection. Fdez-Glez et al. [20] proposed a new framework\\naccording to combine different techniques, particularly\\nsuitable for filtering spam content on web pages. Mei et al.\\n[21] proposed an improved PageRank algorithm based on\\nweb page differentiation (DPR), which evaluates pages authority\\naccording to its links’ numbers and assigns corre-\\nsponding weights according to its authoritativeness when\\nassigning PageRank values. 'ey combined DPR with\\nK-means, designed a differentiation page-based K-means\\nalgorithm. Jelodar et al. [22] presented a systematic\\nframework based on the chi-squared automatic interaction\\ndetector algorithm and a modified string matching algorithm.\\n'e author used the modified knuth–morris–pratt\\nalgorithm to extract features from Alexa Top 500 Global\\nSites and Bing search engine results in 500 queries; then, they\\ngenerated a tree model with useful attributes that can detect\\nweb spam. Asdaghi and Soleimani [23] proposed a new\\nbackward elimination feature selection approach with the\\nNaive Bayes (NB) classifier.\\nMany experts also used different neural networks and\\ndeep learning algorithms to detect web spam. RenatoMoraes\\net al. [24] presented a performance evaluation of different\\nmodels of artificial neural networks used to automatically\\n2 Security and Communication Networks\\n\",\n",
       "  \"classify and filter real samples of web spam based on their\\ncontents. Li et al. [25] introduced the deep belief networks\\nand combined with the synthetic minority oversampling\\ntechnique (SMOTE) and denoising autoencoder (DAE)\\nalgorithm to improve the classification performance of web\\nspam. In [26], the authors presented a framework called\\nFS2RNN, a feature selection scheme using recurrent neural\\nnetworks (RNNs), for the classification of spam nodes. In\\nthis framework, the dataset is preprocessed before applying\\nRNNs in which principal component analysis (PCA) is used\\nfor dimension reduction on the dataset and recursive feature\\nelimination (RFE) is used for feature selection. Belahcen\\net al. [27] addressed the web spam detection problem by\\nusing the graph neural network (GNN) architecture, which\\ncan act as a mixed transductive-inductive model that is able\\nto classify pages by using both the explicit memory of the\\nclasses assigned to the training examples and the information\\nstored in the network parameters.\\nIn addition to detecting traditional e-mail spam and web\\nspam, there are many scholars studying spam in social media\\ncalled social spam, such as spam based on blogs, tweets, and\\nYouTube videos. Fu et al. [28] presented a framework\\ndetecting spammers by measuring how careful a user is\\nwhen she is about to follow a potential spammer. Samsudin\\net al. [29] proposed a framework that extracted features by\\nusing data collected from the YouTube spam dataset to\\ndetect YouTube comments spam. To deal with users who are\\naffected by social spam, Ezpeleta et al. [30] focused on mood\\nanalysis and all content-based analysis techniques. Based on\\nthese heuristic research studies, we can apply to the problem\\nthat needs to be solved in this paper.\\n3. Proposed Method\\nIn this section, we discuss the proposed method framework,\\ngive a comprehensive process of mining novel features, and\\ndetermine classification algorithm training for the detection\\nof the web spam model presented in this paper. 'e\\nframework of the proposed method is depicted in Figure 1.\\n'e input is the web pages of sorts of websites. 'e output is\\na list of web pages with predicted classification scores, where\\na higher score indicates that the web page is more likely to be\\nweb spam. 'e proposed method is composed of 3 components:\\nthe prepossessing, features, and detection model.\\n'e number in brackets is the number of features. Next, we\\nwill describe the functionality and specific implementation\\nmethods of each component in detail.\\n3.1. Data Augmentation. We design our method based on\\nthe WEBSPAM-UK2007 dataset [31]. In the labeled samples\\ngiven by the original dataset, the proportion of spam is only\\n6%. One of the main challenges we face is that the data are\\nvery imbalanced. 'ere is no doubt that machine learning\\nalgorithms are data-driven approaches. It means that the\\nperformance of the model is highly related to data. 'erefore,\\nto augment the data, we extract more original data from\\nthe results of previous studies on this dataset. 'e summary\\nof the augmented data method is to select the labeled data\\nfrom the labeling results with high accuracy of the previous\\nstudies on the dataset, which are used as the labels of our\\ndata. Detailed information about data augmentation is given\\nin Section 4.1.\\n3.2. WARC Parser. First of all, the dataset is structured, but\\nthe complex structured data cannot be directly applied\\nbecause it contains unnecessary information. We need to\\nprocess raw data. 'e original web pages’ HTML documents\\nin each host are arranged in sequence and stored in separate\\nWeb Archive (WARC) format proposed by the Internet\\nArchive. 'e WARC format is an extension of the ARC File\\nFormat that has traditionally been used to store “web crawls”\\nas sequences of content blocks harvested from the World\\nWide Web. Figure 2 shows a code snippet of a WARC file.\\nWe can see that each capture in aWARC file is preceded by a\\none-line header (line 1) that very briefly describes the\\nharvested content and its length. Next to the one-line header,\\nHTTP protocol response headers (from line 5 to line 16) are\\nrecorded, and then, multiple lines of HTML documents\\n(from line 18 to line 43) are followed. We develop a WARC\\nparser to separate the blocks into multiple individual HTML\\ndocuments one by one and store them in different file folders\\naccording to what the domain extracted from the one-line\\nheader uniform resource locator (https://chato.cl/webspam/\\ndatasets/uk2007/contents/excerpt.txt) field the HTML\\ndocument belongs to. Since the domain of each host is\\ndifferent, the folder name is the domain name.\\n3.3. Homepage Extraction and Check. A website contains at\\nleast one web page, and some websites are up to several\\nhundred pages. 'e results obtained by users searching for\\nkeywords in search engines are just one web page for users,\\nand it is challenging to get all the web pages of the website to\\nwhich the current web page belongs. In other words, getting\\nall the web pages is not easy, but getting the homepage is still\\nrelatively simple. Moreover, the homepage is the core of a\\nwebsite, covering the main content that a website wants to\\nexpress to those who are visiting the website. For example,\\nsome companies, governments, and schools’ websites will\\ndisplay related information about companies, governments,\\nand schools such as history, main business, and contact\\ninformation on the homepage. Statistics show that web spam\\npages are more inclined to improve their rankings in search\\nengine results pages, especially homepages. Figure 3 shows\\nthat the percentage of a homepage with the largest PageRank\\nvalue among all pages on the website of spam websites is\\nhigher than that of nonspam websites. It indicates that when\\nspammers create a website, they intentionally make the\\nhomepage with the highest ranking. Some well-known algorithms\\nfor calculating page rankings include PageRank\\nPage Score and TrustRank [32]. 'erefore, it is very representative\\nto check whether the homepage is spam. To some\\nextent, the homepage can represent whether the entire\\nwebsite is spam.\\n'e next step is to determine which HTML document is\\nthe homepage of a website. In the process of parsing HTML\\ndocuments fromWARC files, we have judged whether a web\\nSecurity and Communication Networks 3\\n\",\n",
       "  'page is a homepage from the URL path roughly.We set every\\nHTML document name as its pathname and store it under\\nthe website to which it belongs. Here are some simple rules,\\nfor example, the URL path is only the root path “/” could be\\nas homepage, and the first-level path with the distinct\\nkeywords such as “index,” “home,” and “homepage,” is also\\nthe homepage. Of course, all web pages under some hosts do\\nnot match these rules, so a manual check is required.\\n3.4. Features. We extract some novel features from the\\nsource code of the web page and divide them into four\\ncategories mixed with existing features: homepage links\\nfeatures, semantic similarity features, homepage structure\\ncomplexity features, and existing features. Although some\\nfeatures based on links, content, and structure have been\\nused in previous papers, in this paper, we have studied these\\nfeatures from a different perspective.\\n1 warc/0.91572responsehttp://horwichrmicc.co.uk/20060920234350message/http uuid:e9004f91–fd17–4f40–b7d5–6c3e0b70f3d3\\n2 BUbiNG–guessed–charset: windows–1252\\n3 BUbiNG–content–digest: f05592c825fa9619306efcccd187391e\\n4\\n5 HTTP/1.1200 OK\\n6 x–powered–by: ASP.NET\\n7 connection: close\\n8 content–type: text/html\\n9 accept–ranges: bytes\\n10 content–location: http://horwichrmicc.co.uk/index.htm\\n11 server: Microso\\x02–IIS/6.0\\n12 content−length: 987\\n13 last–modified: Sun, 16 Apr2006 09:02:19 GMT\\n14 etag: “b5571d773461c61: b506b”\\n15 date: Wed, 26 Apr2006 13:11:10 GMT\\n16 ubi–http–equiv–charset: windows–1252\\n17\\n18 <html>\\n19 <head>\\n20 <meta http–equiv = “Content-Language”content = “en-us”>\\n21 <meta http–equiv = “Content-Type” content = “text/html; charset = windows–1252”>\\n22 <meta name = “horwich”“rmi”“winter hey lane”“pike”“reebok”“beehive\"\"rivington”“lostock”“blackrod”“lee lane”“chorley\\n23 new road” content = “Microso\\x02 FrontPage 5.0”>\\n24 <metaname = “ProgId” content = “FrontPage.Editor.Document”>\\n25 <title>Horwich RMI CC</title>\\n26 </head>\\n27 <body>\\n28 <palign = “center”>\\n29 <ahref = “home%20.htm”><img border = “0” src = “bannerentry.gif ” width = “700” height = “400”></a>\\n30 </p>\\n31 <p align = “center”>\\n32 <b><script language = “JavaScript” type = “text/javascript” src = “http://pub24.bravenet.com/counter/code.php?id = 363671\\n33 &usernum = 2057536663&cpv = 2”>\\n34 </script><!-- End Bravenet.com Service Code--></b>\\n35 </p>\\n36 <p align = “center”>\\n37 <b><font size = “7”>Sponsored by Bespoke Flooring</font></b>\\n38 </p>\\n39 <palign = “center”>&nbsp;</p>\\n40 <p align = “center”>\\n41 <font color = “#FFFFFF”>THE OFFICIAL HORWICH R.M.I CRICKET WEBSITE</font>\\n42 </p>\\n43 </html>\\nFigure 2: An example data in the WARC format.\\nWARC parser\\nHomepage \\ncheck\\nFeature \\nsets\\nFeature subsets\\nPre-computed features\\nRandom forest\\nWeb spam \\nclassification model\\nWeb spam \\nNonspam \\n1. Pre-processing 2. Features 3. Detection model\\nLink \\nfeatures (2)\\nSemantic \\nfeatures (2)\\nStructure \\nfeatures (3)\\nWebsites folder\\ncontins web pages\\nHomepages\\nWARC file \\nLink-based \\nfeatures (6)\\nContent-based \\nfeatures (2)\\nfeatures (6)\\nCross validationTransformed link-based \\nFeature \\nextraction\\n1\\nFeature \\nselection\\n2\\nFigure 1: \\'e framework of the proposed detecting web spam method.\\n4 Security and Communication Networks\\n',\n",
       "  \"3.4.1. Link Features. It is necessary to consider link characteristics\\nbecause the spammers deliberately set up a large\\nnumber of hyperlinks between the spam websites to point to\\neach other which can increase the clickthrough rate and the\\nPageRank value of the website’s homepage. 'ere are some\\nspecific measures, such as inserting hyperlinks in the\\nhomepage to point to essential or well-known websites and\\nattract other pages to point to their own pages or using\\ninformation hiding technology to publish valuable information\\non the Internet, but hidden text or hyperlinks that\\nare invisible to users, pointing to spam homepages. 'ese\\npractices all increase the entry link, also called indegree of\\nthe homepage of the spam websites. 'is makes the PageRank\\nvalue of the homepage increase and leads to the\\nadvance of the spam page in the ranking of search engines,\\nwhereas the production of normal hosts is reasonable and\\nstandardized, and the host owner will not deliberately increase\\nthe homepage’s incoming link. Many previous studies\\nonly focused on the number of all links, without considering\\nexternal links and cross links separately. But, the impact of\\nthese two features on the construction of web spam is\\ndifferent. Based on this perspective, this paper extracts these\\ntwo features separately. As discussed above, we propose two\\nlink features, number of external links and number of cross\\nlinks, based on all the links in the homepage.\\n(1) Number of external links: external links defined as\\nhyperlinks that point at an external domain which\\nmeans any domain other than the domain the link\\nexists on.We compared the domain of each link in the\\nhomepage with the domain to which the homepage\\nbelongs and counted the number of external links.\\n(2) Number of cross links: in contrast to external links,\\ncross links also called internal links are links that,\\nfrom within a website, point to another page which\\nbelongs to the same website. Similarly, the number of\\ncross links is obtained by subtracting the number of\\nexternal links from the total number of links.\\n3.4.2. Semantic Similarity Features. Generally, for content\\nspam, the primary method is to repeat the same or similar\\nkeywords in large numbers. Some web pages directly copy\\nthe content of some standard high-quality websites. When\\nusers search for a specific keyword, these plagiarized websites\\nwill also have a relatively high ranking. Users will not be\\naware of this is spam page through only the restricted\\ncontent displayed in the search engine results. 'ese pages\\nadd partial anchor texts link to some marketing and authority\\nwebsites, even malicious websites such as gambling\\nand pornographic websites, to entice users to click and earn\\nprofits. 'is malicious behavior can be challenging to detect.\\nMany web pages with interactive functions are easily used by\\nspammers. For example, in the comments section of a blog,\\nit is easy to evade censorship and spread malicious websites\\nto entice users to click. In previous studies of content-based\\nweb spam, researchers mainly focused on the topics and\\nkeywords of the entire website. 'e method of detecting web\\nspam from the entire content of the website is not accurate\\nenough, and it will make web spam using this technology\\nevade detection. Also, the partial web spam technique has\\nnot been widely studied yet. After analysis and manual\\ncheck, we observe that the semantic analysis between the\\nanchor text and the current web page is helpful for web spam\\ndetection. 'erefore, we extract two semantic similarity\\nfeatures, namely, similarity of texts and links.\\n(1) Similarity of texts: the feature represents the semantic\\nsimilarity between the textual description,\\nalso known as anchor text of the external links in the\\npage and some textual description of the web page. It\\ncan reflect the similarity between the link’s anchor\\ntext inserted in the web page and the main content of\\nthe web page.\\n(2) Similarity of links: the feature represents the semantic\\nsimilarity of each domain of all links in the\\npage and page’s domain. It can reflect the similarity\\nbetween the link inserted on this web page and the\\npage’s domain.\\nIn this paper, we choose word mover’s distance (WMD)\\nas a metric to measure semantic similarity. 'e WMD is a\\nnovel distance function between text documents presented\\nin [33]. In a supervised learning task, semantic similarities\\nare useful for classification. WMD measures the difference\\nbetween two texts and calculates the minimum distance that\\na word vector of one text “moves” to a word vector of\\nanother text. As shown in Figure 4, after removing stop\\nwords (not bold), the remaining words are embedded into a\\nvector in the vector space. 'e WMD distance between the\\ntwo short texts is the minimum cumulative distance calculated\\nby word vectors in short text 1 travel to short text 2.\\nSince the WMD distance can use the word-level semantic\\ninformation represented by word2vec [34], it can achieve\\nbetter results in the short text semantic distance calculation.\\n'us, WMD is suitable for computing the semantic similarity\\nfeatures in this paper. 'e smaller the WMD value, the\\nmore similar the two short texts. To automatically extract the\\nsemantic similarity features from the homepage’s HTML\\nHomepage without\\nmax pagerank value \\nHomepage with\\nmax pagerank value \\n100\\n80\\n60\\n40\\n20\\n0\\nSpam\\nNonspam\\n(%)\\nFigure 3: 'e percentage of homepage with max pagerank value of\\nboth spam and nonspam websites.\\nSecurity and Communication Networks 5\\n\",\n",
       "  \"document, we propose an algorithm and complete it\\nthrough the three steps: short text cleaning, represent words\\nas vectors, and computing WMD distance. 'e pseudocode\\nof this algorithm is shown in Algorithm 1.\\nAs described in Algorithm 1, line 1 and line 2 show that\\nthe homepage and domain name of each website is required.\\nLine 3 creates three lists: texthp contains the homepage text,\\nlinkexternal includes all external links, and textexternal is for\\nstoring the anchor text corresponding to each external link.\\nLine 4 to line 24 is the process of calculating semantic\\nsimilarity features. 'ere are five functions in the proposed\\nmethod.\\n(i) ExtractText(): this function extracts the homepage’s\\ntitle, keywords, description in meta tags\\n(ii) Collectlinks(): this function extracts all external\\nlinks of the homepage\\n(iii) ExtractLinkText(): it extracts the anchor text of\\neach link in turn\\n(iv) ExtractDomain(): this function extracts the domain\\nof each link in turn\\n(v) WMD(): it calculates theWMDdistance between the\\nhomepage text and each anchor text of the external\\nlink and calculates the WMD distance between the\\nhomepage domain and each external link domain\\nNext, we introduce each step in detail.\\nStep 1 Short Text Cleaning.'e HTML document of the\\nhomepage contains much information, but only a\\nfew parts are used to extract WMD features. To\\nextract the title, the keywords and descriptions in\\nthe metafield, external links, and text description\\nof every external link from the homepage of each\\nwebsite, we first need to parse the HTML tags\\nwith the Beautiful Soup Python library [35] and\\nconvert HTML entities to characters with the\\nHTML Python library. Moreover, we remove\\nsome punctuations and stop words in raw texts.\\nWe utilize stop words from the NLTK library,\\nwhich contains 127 English words. Besides, to\\nensure a hyperlink is an external link, it is necessary\\nto extract each website’s domain. Note that\\nthe external link includes neither relative paths\\nnor links under the same domain which we\\nmentioned in Section 3.1.1. 'en, we splice the\\ncontent of the homepage’s title and keywords and\\ndescription of metatag together as the texthp.\\nBesides, we should process two parts for each\\nexternal link, the link itself and the anchor text of\\nthe link. Some websites contain more than one\\nexternal link while some contain none. We push\\nall the external links to a list as linkexternal. For\\neach link’s anchor text, we also push all the\\nanchor texts corresponding to each link into the\\ntextexternal in turn, which is separated by spaces.\\ntexthp � texttitle, textkeywords, textdescription\\U0010ff6e \\U0010ff6f,\\nlinkexternal � link1, link2, . . . , linkn\\U0010ff08 \\U0010ff09, n ∈ N\\n∗\\n,\\ntextexternal � textlink1, textlink2, . . . , textlinkn\\U0010ff6e \\U0010ff6f, n ∈ N\\n∗\\n.\\n(1)\\nStep 2 Represent Words as Vectors. Since models accept\\nnumerical input only and the words in short texts\\nare natural languages such as English, these\\nwords need to be converted into numerical forms\\nor embedded in mathematical space. 'e vector\\nmapped to real numbers is called word vectors.\\n'e embedding method is called word embedding,\\nand word2vec is a kind of word embedding\\nmethod. Word2Vec is a tool to transform the text\\nprocessing into a vector in the multidimensional\\nvector space, representing the text’s semantic\\nsimilarity based on the similarity in the vector\\nspace. We use a pretrained model, Google News\\n[36], to train word vectors. It contains 3 million\\npretrained English word embeddings.\\nStep 3 Computing WMD Distance. After obtaining the\\noriginal short texts and links’ word vectors, we\\nthen calculate theWMD distance to represent the\\nsimilarity, which is illustrated as follows:\\nWMD � min\\nT≥0\\n\\U0010ff58\\nn\\ni,j�1\\nTijc(i, j). (2)\\nT is a sparse matrix where Tij is the weight of word i in\\ndocument di move to word j in document dj, c(i, j) is the\\nEuclidean distance between word i and word j, as equation\\n(3) shows, and xi, xj is the word i, j’s word vector after\\nembedding, respectively.\\nc(i, j) � xi − xj\\n�����\\n�����2\\n. (3)\\n'e sum of weight of word i to another document\\n\\U0010ff50\\nn\\nj�1 Tij is equal to the weight of word i in the first document\\ndi, and the sum of weight of word j to another document\\n\\U0010ff50\\nn\\nj�1 Tij is equal to the weight of word j in the first document\\ndj.\\n\\U0010ff58\\nn\\nj�1\\nTij � di, ∀i ∈ 1, . . . , n{ },\\n\\U0010ff58\\nn\\ni�1\\nTij � dj, ∀j ∈ 1, . . . , n{ }.\\n(4)\\nThe\\nwebsite\\npresented\\na paper\\nof\\na\\ngalaxy\\nA\\nblog\\nposted\\nan \\narticle\\nabout\\nthe moon\\nShort text 1 Short text 2Website\\nWord2vec embedding\\nPresented\\nPaper\\nGalaxy\\nBlog\\nPosted\\nArticle\\nMoon\\nFigure 4: An illustration of the word mover’s distance.\\n6 Security and Communication Networks\\n\",\n",
       "  \"di can be calculated by equation (5), where ci is word i\\nappear times in the document I.\\ndi �\\nci\\n\\U0010ff50\\nn\\nj�1 cj\\n. (5)\\nIn the case of this article, document I corresponds to the\\ntexthp and document J corresponds to the links linkexternal\\nand anchor text textexternal of external links. So, there are\\nmultiple short texts. We need to compare the semantic\\nsimilarity of each external link with the homepage. 'en, we\\ncalculate the average by equations (6) and (7), respectively.\\nWMDtext �\\n\\U0010ff50\\nn\\ni�1 WMD texthp, textlinki\\U0010ff10 \\U0010ff11\\nn\\n, (6)\\nWMDlink �\\n\\U0010ff50\\nn\\ni�1 WMD domainhp, domainlinki\\U0010ff10 \\U0010ff11\\nn\\n. (7)\\n3.4.3. Structure Complexity Features. It is necessary to\\nconsider the characteristics of the homepage’s document\\nobject model (DOM) structure because we discover that\\nmany web pages use the same templates, such as domain\\nparking services, personal blog websites, and some government\\nwebsites. It can be considered that there are certain\\nregularities. According to MDN [37], a web page is a\\ndocument of which structure and content are represented as\\nnodes and objects by DOM. Structural features can reflect\\nthe complexity of web pages. Similar web pages have a\\nsimilar DOM structure because web spam is often a welldesigned\\ntemplate, unlike normal web pages that have\\ndifferent characteristics. 'e previous method of identifying\\nweb spam mainly focused on the difference in content and\\nlinks, but we also consider the web page’s structural characteristics\\nin this paper. Previous methods also studied the\\nstructure of HTML, such as extracting the number of <a>\\ntags and <img> tags. However, this method may not be very\\neffective for some specific websites, such as online shopping\\nwebsites and stock picture websites, which have an obvious\\ntendency of certain types of HTML tags.We not only analyze\\na certain type of tags but also analyze the complexity of the\\nweb page’s structure from a more general perspective. We\\nhave analyzed the three features of the number and diversity\\nof HTML tags and the depth of element nodes. For example,\\nthe domain parking service, where the parking platform\\noften has a fixed template. We aim to identify such a web\\npage. 'us, it is necessary to research the web page’s\\nstructure, and we have extracted the following structural\\nfeatures from the source code of the homepage.\\n(1) Number of HTML tags: the DOM represents an\\nHTML document as a tree structure of tags, which is\\na DOM tree. We only consider the element-type\\nnodes, HTML tags. By traversing the DOM, the total\\nnumber of tags contained in the homepage is\\ncalculated.\\n(2) Diversity of HTML tags: different types of websites\\nhave different distributions of their tags. For example,\\nthe web pages in some link factories contain a large\\nnumber of hyperlinks, and the ¡a¿ tag implements\\nthese hyperlinks. 'ere are many image tags in online\\nstores, while personal blogs have many paragraph\\ntags. We also counted each type of label on each\\nhomepage.\\n(3) Depth of element nodes: by traversing each branch of\\nthe DOM tree, we calculated the maximum depth of\\nthe DOM tree of the homepage. It reflects the\\ncomplexity of a DOM tree structure and the complexity\\nof the homepage’s HTML structure.\\n3.4.4. Precomputed Features. 'ere are 277 precomputed\\nfeatures in total, which categorize into 4 sets, direct features\\nset with 2 features, content-based features set with 96 features,\\nlink-based features set with 41 features and trans-\\nformed link-based features set with 138 features, which are\\nobtained by mathematically transforming the link-based\\nfeatures. If all features are considered for experiments, it is\\nevident that those with high dimensions will undoubtedly\\nconsume a lot of resources and cause a long execution time.\\nIn fact, many features are redundant. By removing several\\nredundant features, both efficiency and accuracy can be\\nimproved. 'erefore, we only take the features related to the\\nhomepage into consideration.\\nFirst of all, by checking the meaning of each feature, we\\npreliminarily filter out 106 precomputed features from these\\nfour feature sets that are all about the homepage (hp),\\nwithout considering the page with the maximum PageRank\\n(mp) value. 'en we select features from the 106 features.\\nWe use a new backward elimination approach, Smart-BT,\\nproposed by Asdaghi and Soleimani [23] to accomplish\\nfeature selection. 'is method differs from sequence backward\\nelimination in that it measures the impact on the\\nclassification result after eliminating a set of features, rather\\nthan eliminating a single feature. In summary, we extracted 7\\nnew features and selected 14 features from the existing\\nfeatures. 'ere are 21 features in total. 'ese features will be\\ninput into the detection model.\\n3.5. Classification Algorithm. Judging whether a web page is\\nspam or not is a problem with less clear boundaries. It is a\\nsubjective issue to some extent, so classifying web pages as\\nspam or nonspam is challenging. Because of the apparent\\ndifferences between spam and nonspam web pages in some\\nfeatures, we can use these features to build machine learning\\nmodels that allow experts or researchers to identify web\\nspam and reduce losses on the ground quickly. Classic algorithms,\\nsuch as NB, logistic regression (LR), SVM, RF,\\nconvolutional neural networks (CNNs), RNN, and long\\nshort-term memory (LSTM), have different advantages and\\ndisadvantages. In [38, 39], a large-scale empirical comparison\\nbetween these machine learning methods is presented.\\nA CNN has an excellent performance spatial mapping, such\\nas image data. An RNN is more suitable for sequence\\ncontent, such as text analysis. But, an RNN has the problem\\nof gradient disappearance; it is challenging to process long\\nSecurity and Communication Networks 7\\n\",\n",
       "  \"sequence data. LSTM can avoid the vanishing of gradient of\\nconventional as a special case of the RNN.\\nConsidering the characteristics of the dataset is imbalanced\\nand features in the feature set are independent and\\nbased on the cost of different methods, the RF [40], which\\ncombines a multitude of decision trees, is more suitable for\\nthe problem solved in this paper. As an ensemble learning\\nmethod for classification, RF solves the shortcomings of the\\nweak generalization ability of decision trees since it predicts\\na sample by lots of decision trees voting for the final result.\\nFurthermore, there are several advantages to selecting RF as\\nthe classifier. It is inherently easy to interpret and understand.\\nFurthermore, RF algorithm is easy to implement and\\ncosts less than deep learning. 'erefore, we chose to use RF\\nas the automatic classifier in this paper.\\n4. Experiments and Evaluation\\nIn this section, we have first illustrated the environment of\\nexperiments and detailed the source and composition of the\\ndataset used in this paper. 'en, the metrics utilized for the\\nmeasurement of the performance of the proposed model are\\ndiscussed, and later, experiment results are analyzed.\\n'e experiments studies are conducted on the Ubuntu\\noperating system. 'e homepages extraction and data\\npreprocessing are developed in some libraries written in\\nPython. Also, the process of model building and classification\\nis implemented by scikit-learn [41] and keras [42]\\nwith TensorFlow backend [43]. 'e experimental environment\\nconfiguration is shown in Table 1.\\nSince this paper focuses on the extraction and effects of\\nnovel features, the parameters in the detection model should\\nbe set or adjusted as little as possible. 'e simpler the\\nmachine learning model, the more likely it is that good\\nexperimental results are not based solely on specific samples.\\nFor example, in the detection model RF, we only set the\\nnumber of trees parameter “n_estimators” to be 100 empirically.\\nIn fact, the default value of “n_estimators” changed\\nfrom 10 to 100 in scikit-learn v0.22. 'ere is no specific\\nsetting for the other hyperparameters, which means other\\nhyperparameters are set by default. 'e advantage is that the\\nclassifier of this paper is not aimed at a specific dataset, but\\nhas generalization capabilities. 'ere is a reason to believe\\nthat the proposedmethod is not too data dependent and easy\\nto apply for new users.When encountering a new dataset, we\\nonly need to extract the features proposed in this paper\\naccording to the method in Section 3 and input these features\\ninto the classifier for classification. However, machine\\nlearning is dependent on data, and different data types have\\ndifferent targeting models, which we mentioned in Section\\n3.2. For data with similar regularities, the proposed method\\nhas generalization ability. Firstly, different web spam pages\\nhave similar characteristics, such as too many links for linkbased\\nweb spam or a large number of repetitions of text\\ncontent for content-based web spam. Secondly, cross-validation\\nis used to evaluate the prediction performance of the\\nmodel, especially the performance of the trained model on\\nnew data. 'e cross-validation can reduce overfitting to a\\ncertain extent and better evaluate the generalization quality\\nof the model by repeatedly dividing the dataset.\\nRequire:\\n(1) hp: homepage of each domain\\n(2) dhp: homepage’s domain\\n(3) Initialize the list texthp, linkexternal and textexternal set to null\\n(4) if (hp is not null) then\\n(5) texthp:� ExtractText (hp)\\n(6) /∗ extract hp’s title, keywords, description ∗/\\n(7) linkexternal:� Collectlinks (hp)\\n(8) /∗ collect all external links in hp ∗/\\n(9) if (linkexternal and texthp is not null) then\\n(10) for each link ∈∈linkexternal do\\n(11) textexternal:� ExtractLinkText (link)\\n(12) dlink:� ExtractDomain (link)\\n(13) /∗ extract link’s anchor text ∗/\\n(14) end for\\n(15) WMDtext � WMD (texthp, textexternal)\\n(16) /∗ computing the WMD distance between hp’s text and external link’s anchor text∗/\\n(17) WMDlink � WMD (dhp, dlink)\\n(18) /∗ computing the WMD distance between hp’s domain and external link’s domain∗/\\n(19) else if (linkexternal is not null and texthp is null) then\\n(20) WMDtext � 0\\n(21) else\\n(22) WMDtext �WMDlink � 0\\n(23) end if\\n(24) end if\\n(25) return WMDtext, WMDlink\\nALGORITHM 1: Calculating semantic similarity features from the homepage.\\n8 Security and Communication Networks\\n\",\n",
       "  \"4.1. Dataset. We run our experiments on the WEBSPAMUK2007\\ndataset [31] which is a large collection of\\n105,896,555 pages in 114,529 hosts based on a crawl of the\\n“uk” domain that was conducted in May 2007. It is also used\\nas the Web Spam Challenge 2008 dataset. Although the\\namount of the dataset is large, only few were labeled by a\\ngroup of volunteers. As shown in Table 2, among the all 6479\\nlabeled data, we discard the data labeled as “undecided”\\nbecause it means that the volunteers were still uncertain as to\\nwhether they were spam or nonspam and discard the data\\nwithout content features. Meanwhile, we delete these data\\nthat their features are not complete. As a result, 5797 data\\nremain.\\nAs Table 2 depicts, the number of spam is 321, and the\\nproportion of spam is only 6%; the ratio of samples of\\nnonspam class to spam class is nearly 16 :1, which means\\nthat the data are very imbalanced. In such scenarios, machine\\nlearning models cannot learn the characteristic be-\\nhavior of the minority spam class. Classifying samples as\\nspam or nonspam accurately presents considerable challenges.\\nTo address this issue, we re-extracted 1215 pieces of\\ndata after removing duplicate data in the original dataset\\nfrom the results given by the top three [44] in theWeb Spam\\nChallenge 2008. 'ese data were consistently labeled as\\n“spam” by the top three teams. To a certain extent, these data\\ncan be considered reliable. Although we extracted more\\nlabeled data, these data were already 13 years old, so we also\\nconsidered the newer dataset UK-2011 [45], which was\\nderived from the WEBSPAM-UK2007 dataset. After\\ndeduplication, we find that all pages on many websites are\\ninvalid websites. “Invalid” means the source code of these\\npages has no content or is meaningless. 'ere are probably\\nthe situations “301 Moved Permanently,” “Object Moved,”\\n“'is IP has been banned,” and “302 Found.” Since these\\npages have no research value, they need to be deleted. In\\naddition, we have also removed some pages that are not in\\nEnglish. In the end, as Table 2 depicts, we have 6189 pages\\nconsisting of 4745 nonspam pages and 1444 spam pages.\\nWe have a reason to believe that conducting the study\\nwith the 13-year-old dataset has certain limitations, such as\\nwhether it is suitable for today’s rapid development of web\\napplications. 'e meaningfulness of using the dataset is as\\nfollows.\\n(1) 'is dataset is a standard dataset in the field of web\\nspam research, and its labels are judged by multiple\\nscholars. It can be considered that its labels are\\nauthoritative.\\n(2) Although it has passed 13 years, it is still in the web\\n2.0 era now. Developers build web pages, especially\\nweb spam, with some commonality technologies\\nbefore and nowadays, which indicates the dataset is\\nuniversal. Moreover, during our manual check\\nprocess, we find that some websites are still active.\\n4.2. Experimental Design. We conduct three sets of experimental\\nstudies to evaluate the performance of our model\\nfully: (1) we first evaluate the performance of our proposed\\nmethod and verify the effectiveness of the novel feature; (2)\\nwe also compare the performance of our method with some\\npopular web spam detection systems; and (3) we use hypothesis\\ntesting to verify the validity of our method and\\nanalyze the importance of features.\\n4.2.1. Experiment for Performance of Proposed Model.\\nWe first examine the performance of the RF model on the\\ndataset and compare the results with benchmark models.\\nConsidering the dataset is inadequate, especially the data for\\nthe minority class and different samples or different partitions\\nof the dataset may cause the result to be optimistically\\nbiased, we take cross validation to train our dataset. As a\\npotent tool in machine learning and deep learning, cross\\nvalidation can ensure that every page in the dataset can be\\nused in the experiment process. In this way, we ensure the\\nfull use of the data and manage to make the experimental\\nresults less biased. 'us, we apply 5-fold cross validation to\\ntrain our dataset in all detection models. We input all the\\nfeatures that comprise existing features and novel features\\ninto classification approaches to determine whether a page is\\nspam or not. We have also investigated some benchmark\\ntraditional machine learning algorithms such as NB, LR, and\\nSVM and some benchmark deep learning algorithms including\\nCNN, RNN, and LSTM as basic comparative ex-\\nperiments. Secondly, we compare the classification effects of\\neach model on only existing features and all features.\\n4.2.2. Experiment for Comparison of Detection Rate. We also\\nhave compared some state-of-art methods; for example,\\nMittal and Juneja [46] presented a mutual informationbased\\nfeature selection method which selects content-based\\nfeatures and with a SVM classifier to distinguish web spam,\\nMakkar et al. [26] used PCA and RFE to deal with link-based\\nfeatures and incorporated the features into an RNN classifier\\nto detect spam, and Asdaghi and Soleimani [23] proposed an\\nTable 1: Experimental environment Configuration.\\nDesignation Information\\nOperating system Ubuntu server 16.04 LTS\\nSystem\\nconfiguration\\nCPU:Intel i7-7700K, 3.60GHz, 32GB\\nRAM\\nGPU:Nvidia RTX 2080 8G\\nGenism 3.8.1\\nTensorFlow 2.0.0\\nBeautifulsoup4 4.4.1\\nPython library\\nNLTK 3.4.5\\nKeras 2.3.1\\nScikit-learn 0.21.3\\nMatplotlib 3.1.1\\nStatsmodels 0.9.0\\nR library pROC 1.16.2\\nTable 2: Statistics of experiments dataset.\\nCategory UK2007 UK2011 Dataset used in this paper\\nNonspam 5476 1768 4745\\nSpam 321 1998 1444\\nTotal 5797 3766 6189\\nSecurity and Communication Networks 9\\n\",\n",
       "  \"effective feature selectionmethod to select fewer features and\\nput the features into NBmodel to achieve high performance.\\nWe used the same method as these papers to divide the\\ndataset into training, validation, and test sets. In order to\\nmake a comparison on the dataset used in this paper, we\\nreproduced these experiments.\\n4.2.3. Experiment for Validity of the Proposed Features.\\nAs one of themodels considered is the LRmodel and the best\\nmodel is RF, followed by comes LR, we believe that reporting\\nthe logistic regression model results with statistical inference\\nwould be very useful for more than one reason. We use\\nstatsmodels [47] for the estimation of many different statistical\\nmodels. Firstly, it would verify that some of the\\nfeatures identified in Section 3.1 can actually be used to\\ndetect spam, and it would demonstrate which variables are\\nthe most important in this regard. Secondly, it could then be\\nused as a benchmark against which the other models could\\nbe compared. We use the open-source package “pROC”\\nprovided in Robin et al. [48] to compare two different\\nmodels’ area under the curve (AUC). It helps us compare the\\nsuperiority of different models more rigorously, especially\\nwhen the p value is less than 0.05, and the results are more\\nconvincing.\\nWe also use two methods including mean decrease\\nimpurity (MDI) and mean decrease accuracy (MDA) also\\nknown as permutation importance (PI) in RF for feature\\nimportance analysis. 'ere are two main problems of impurity-based\\nfeature importance methods are that it biased\\ntowards high cardinality features, and the impurity-based\\nimportances are computed on the training set. Hence, it is\\nnot certain that features are also useful on the test set,\\nwhereas MDA is an alternative that can mitigate those\\nlimitations. We add up the ranked results of each feature and\\ncalculate the average importance score because of cross\\nvalidation.\\n4.3. Evaluation Metrics. In binary classification problems,\\nthe most popular performance evaluation indicators are\\naccuracy, precision, recall, and F1 score, which are described\\nin detail as follows.\\nAccuracy is the number of correct predictions over the\\nnumber of total predictions of the model.\\nAccuracy �\\nTP + TN\\nTP + TN + FP + FN\\n. (8)\\nWe judge a sample with a prediction score greater than\\nthe threshold as positive (spam class), and the threshold is\\n0.5. Where true positive (TP) is the number of spam samples\\nthat are correctly classified, true negative (TN) is the number\\nof nonspam samples that are correctly identified, false\\nnegative (FN) is the number of spam samples that are\\nmistakenly classified as a nonspam sample, and false positive\\n(FP) is the number of nonspam samples that are mistakenly\\nclassified as spam.\\nRecall, also called true positive rate (TPR), is the proportion\\nof the number of spam samples was identified\\ncorrectly as spam in all spam samples and defined in\\nequation (9). Precision is the proportion of the true predictions\\nof the spam samples over total samples predicted as\\nspam which is defined in equation (10).\\nRecall �\\nTP\\nTP + FN\\n, (9)\\nPrecision �\\nTP\\nTP + FP\\n. (10)\\nF1 score is the harmonic average of precision and recall\\nand defined in the following equation:\\nF1 �\\n2 · Precision · Recall\\nPrecision + Recall\\n. (11)\\nFalse positive rate (FPR) is defined as follows:\\nFPR �\\nFP\\nFP + TN\\n. (12)\\nReceiver operating characteristics (ROC) curve must be\\nregarded as a widely used indicator when it comes to metrics\\nfor performance evaluation in classification problems. Because\\nthe ROC curve has an outstanding characteristic, the\\nROC curve can remain unchanged when the distribution of\\npositive and negative samples in the test set changes. Also,\\nAUC, which utilizes TPR and FPR (equations (9) and (12),\\nrespectively), represents classifiers’ performance. 'e larger\\nthe AUC value, the better the classifier is in detecting web\\nspam.\\n4.4. Results and Analysis\\n4.4.1. Classifier Performance Result. We show the performance\\nof the binary classifiers in detecting web spam in\\nTable 3, which demonstrates the results of different baseline\\nmodels using the evaluation indicators described in Section\\n4.3. Figure 5 illustrates the graphical view of the performance\\nof the different classifiers in web spam detection. It can be\\nseen from the table and figure that the RF model yields the\\nbest performance in all aspects of our experiments, with a\\nprecision rate of 0.929 and a recall rate of 0.930 and has the\\nlargest curve area. Trees of RF algorithm are independent\\nduring the training process. 'e final result is obtained by\\nvoting of all trees. For imbalanced data sets, RF can balance\\nerrors [49]. LR is closely followed, and SVM, CNN, and\\nRNN perform well but relatively worse. However, NB and\\nLSTM performance are slightly worse. NB is relatively\\nsimple, more sensitive to minority class data. LSTM is\\nsuitable for longer sequence data, so the dataset in this paper\\ndoes not highlight its advantages. 'e result of experiment\\nfor performance of the proposed model demonstrates that\\nthe RF model can use the features effectively. We can\\nconclude that the selected novel features combined with the\\nchosen classifier RF yields better results. In Table 4, we can\\nsee the existing features and novel features, as well as the\\nresults of all features under different evaluation indicators.\\nWithout novel features, the result is inferior to that of with\\nnovel features, which means that the novel features we\\nextracted are practical.\\n10 Security and Communication Networks\\n\",\n",
       "  \"4.4.2. Comparison Experiment Result. In this paper, we\\nreproduced three representative methods as comparative\\nexperiments that we explained in Section 4.2. 'e three\\nstudies were chosen for the comparisons based on the\\nconsideration that the researches were relatively new and\\ntheir results performed well. Also, they all used the same\\ndataset as this paper. As in Table 5, which demonstrates the\\nresults of three state-of-art methods, paper [46] achieved an\\nF1 score of 0.883 on our dataset, which was less than our\\nmethod by nearly 5%. Our method uses fewer features and\\nachieves better results. It is concluded that these methods are\\nworse than our method and our proposed method performs\\nwell.\\n4.4.3. Validity Verification Result. Table 6 demonstrates\\nsome regression results of the features used in this paper. It\\nincludes each feature’s coefficients, standard error, and p\\nvalue by logit regression analysis. It can be seen that the\\nnovel features contribute significantly to the model.\\n“Two ROC curves are ‘paired’ if they derive from\\nmultiple measurements on the same sample” described by\\nRobin et al. [48]. 'us, we compare the ROC curve of RF\\nwith other models’ ROC curves, respectively. We use\\n“roc.test()” command from “pROC” package in R to calculate\\nthe p value. All paired ROC curves’ p value is less than\\n2.2e-16, which is far less than 0.05. We could say that the RF\\nmodel (AUC� 0.957) has an AUC that is significantly\\nTable 3: Results of different classification models. 'ese bold values indicate the best performance under different evaluation metrics.\\nModel Accuracy Precision Recall F1 score\\nNB 0.850 0.843 0.850 0.844\\nLR 0.888 0.884 0.888 0.883\\nSVM 0.891 0.899 0.891 0.880\\nRF 0.930 0.929 0.930 0.929\\nLSTM 0.810 0.835 0.810 0.758\\nCNN 0.859 0.861 0.859 0.842\\nRNN 0.875 0.872 0.875 0.865\\nReceiver operating characteristic curve\\n1.0\\n0.6\\n0.8\\n0.4\\n0.2\\n0.0\\n0.0 0.2 0.4\\nFalse positive rate\\nROC curve of RF (area = 0.957)\\nROC curve of SVM (area = 0.896)\\nROC curve of NB (area = 0.875)\\nROC curve of LR (area = 0.902)\\nROC curve of LSTM (area = 0.833)\\nROC curve of CNN (area = 0.843)\\nROC curve of RNN (area = 0.879)\\nTr\\nue\\n p\\nos\\niti\\nve\\n ra\\nte\\n0.6 0.8 1.0\\nFigure 5: 'e ROC curve of 7 models (5-fold cross validation).\\nTable 4: Results of using different 3 feature sets on random forest model.\\nFeature set Accuracy Precision Recall F1 score AUC\\nSelected existing features 0.911 0.909 0.911 0.909 0.937\\nNovel features 0.911 0.910 0.911 0.907 0.917\\nSelected existing + novel features 0.930 0.929 0.930 0.829 0.957\\nSecurity and Communication Networks 11\\n\",\n",
       "  \"greater than the second-best model (AUC� 0.902). Also, the\\nresults are not accidental which proves that our method is\\ncorrect and effective.\\nAs can be observed in Figure 6, the Figure 6(a) is the\\nresult of using MDI, and the Figure 6(b) is the result of using\\nMDA. 'e results of the two RF feature importance ranking\\nmethods are not exactly the same. 'e ones with ∗ on the Yaxis\\nare novel features. It is clear that the novel features\\nextracted in this paper rank top overall. 'e advantage of the\\nfeatures proposed in this paper is that it is convenient to\\nextract, whereas the precomputed existing features extraction\\nrequires more stringent conditions such as construction\\nof web graph. 'e novel features are general and easily\\naccessible.\\n∗Number of external links\\n∗Number of cross links\\n∗Depth of element nodes\\nL_outdegree_hp\\nOutdegree_hp\\nPagerank_hp\\nL_truncatedpagerank_1_hp\\nL_truncatedpagerank_4_hp\\nL_truncatedpagerank_2_hp\\nL_truncatedpagerank_3_hp\\nTruncatedpagerank_4_hp\\nTruncatedpagerank_1_hp\\nTruncatedpagerank_3_hp\\n0.00 0.05 0.10 0.15\\nTruncatedpagerank_2_hp\\n∗Similarity of texts\\n∗Similarity of links\\n∗Diversity of html tags\\nHST_19\\n∗Number of html tags\\nL_pagerank_hp\\nHST_20\\n(a)\\n∗Number of external links\\n∗Number of cross links\\n∗Depth of element nodes\\nL_outdegree_hp\\nOutdegree_hp\\nPagerank_hp\\nL_truncatedpagerank_1_hp\\nL_truncatedpagerank_4_hp\\nL_truncatedpagerank_2_hp\\nL_truncatedpagerank_3_hp\\nTruncatedpagerank_4_hp\\nTruncatedpagerank_1_hp\\nTruncatedpagerank_3_hp\\nTruncatedpagerank_2_hp\\n∗Similarity of texts\\n∗Similarity of links\\n∗Diversity of html tags\\nHST_19\\n∗Number of html tags\\nL_pagerank_hp\\nHST_20\\n0.00 0.02 0.04 0.06 0.08 0.10\\n(b)\\nFigure 6: Random forest feature importance. (a) Mean decrease impurity. (b) Mean decrease accuracy.\\nTable 6: Logit regression results.\\nType Feature Coefficients Std. error Pr(>—z—)\\nSelected existing features\\nHST_19 0.7254 0.338 0.032\\nHST_20 2.3106 0.420 0.000\\noutdegree_hp 0.0066 0.003 0.015\\npagerank_hp −9.712e + 04 4.2e + 05 0.817\\ntruncatedpagerank_1_hp −1.043e + 05 1.35e + 06 0.939\\ntruncatedpagerank_2_hp −1.079e + 05 2.35e + 06 0.963\\ntruncatedpagerank_3_hp −1.101e + 05 4.28e + 06 0.980\\ntruncatedpagerank_4_hp −1.084e + 05 2.74e + 06 0.968\\nL_outdegree_hp −0.0425 0.002 0.000\\nL_pagerank_hp 0.0472 0.012 0.000\\nL_truncatedpagerank_1_hp 6.4183 0.665 0.000\\nL_truncatedpagerank_2_hp −8.9288 1.766 0.000\\nL_truncatedpagerank_3_hp 3.5543 2.380 0.135\\nL_truncatedpagerank_4_hp −0.9848 1.369 0.472\\nNovel features\\nDiversity of HTML tags −0.0523 0.011 0.000\\nDepth of element nodes −0.0123 0.002 0.000\\nNumber of HTML tags −0.043 0.000 0.000\\nNumber of external links 0.0460 0.003 0.000\\nNumber of cross links 0.0173 0.002 0.000\\nSimilarity of texts −0.0816 0.029 0.004\\nSimilarity of links 1.7910 0.249 0.000\\nTable 5: Comparison of the results using different classification methods.\\nMethod Number of features Accuracy Precision Recall F1 score\\nOur method 21 0.930 0.929 0.930 0.929\\n'e method of Mittal et al. [46] 70 0.890 0.888 0.890 0.883\\n'e method of Makkar et al. [26] 41 0.872 0.869 0.872 0.870\\n'e method of Asdaghi et al. [23] 28 0.863 0.869 0.863 0.865\\n12 Security and Communication Networks\\n\",\n",
       "  \"5. Conclusions and Discussion\\nBased on current research, this paper proposes a new\\nmethod to distinguish web spam. We introduce a set of\\nnovel features about the homepage which we manually\\nchecked. In the meantime, we use the feature selection\\nalgorithm Smart-BT [23] to reduce the precomputed\\nexisting features’ dimension so that the method’s computational\\ncost will decrease. 'en, we use the RF model to\\ndiscriminate against web spam with efficient identification.\\n'e experiment results showed that this method could\\nreach a state-of-art level compared with other methods.\\nBesides, the model with novel features which are are\\nimpressive to web spam detection is more superior and\\nvalid than the model with only existing features. Since this\\npaper takes homepage only into account, the method is\\ngeneral and extensible because obtaining all pages of a\\nwebsite is not easy in most times. We acknowledge that\\nsome of the biases of our dataset might affect the result.\\nOur method may not work well as the web spam evolves\\nbecause the boundary between spam and nonspam is likely\\nto blur. Also, we only analyzed statically from the source\\ncode without considering the dynamic parts such as\\nJavaScript code, so our method has limitations for web\\nspam that uses dynamic technology. For example, cloaking\\nand redirection web spam. 'e proposed method only\\nfocuses on the homepage of a certain website without\\nconfirming whether the website returns different content\\nfor users and search engines so that there is a certain error\\nin detecting this type of web spam. Moreover, many\\nmalicious websites redirect to other pages to improve\\nrankings. 'ere are many ways to achieve redirection, such\\nas the redirection field in the meta tag and dynamic scripts\\nin JavaScript. 'e proposed method does not pay attention\\nto the JavaScript code and redirection web spam detection\\nis not accurate enough.\\nIn the future, mining more efficient features based on\\nstatic and dynamic analysis and using a classifier with the\\nability of high accuracy would be an interesting direction.\\n'is will be the direction we will consider later.\\nData Availability\\n'e data used to support the findings of this study are\\navailable from the corresponding author upon request.\\nConflicts of Interest\\n'e authors declare that there are no conflicts of interest\\nregarding the publication of this paper.\\nAcknowledgments\\n'is work was supported in part by the National Natural\\nScience Foundation of China under Grant no.61902265,\\nSichuan Science and Technology Program under Grant\\nnos.2020YFG0047 and 2020YFG0076, and the Fundamental\\nResearch Funds for the Central Universities.\\nReferences\\n[1] Search engine marketing statistics 2020. https://www.\\nsmartinsights.com/search-engine-marketing/search-enginestatistics/.\\n[2] Google search statistics. https://www.internetlivestats.com/\\ngoogle-search-statistics/(2019).\\n[3] Google organic click-through rates in 2014, https://moz.com/\\nblog/google-organic-click-through-rates-in-2014(2019).\\n[4] How far down the search engine results page will most people\\ngo? https://www.theleverageway.com/blog/how-far-downthe-search-engine-results-page-will-most-people-go/(2019).\\n[5] Z. Gyongyi and H. Garcia-Molina, “Web spam taxonomy,” in\\nProceedings of the First InternationalWorkshop on Adversarial\\nInformation Retrieval on the Web, Chiba, Japan, May 2005.\\n[6] A. Lina, “Towards evaluating web spam threats and countermeasures,”\\nInternational Journal of Advanced Computer\\nEnce and Applications, vol. 9, no. 10, 2018.\\n[7] M. Najork,Web Spam Detection, pp. 1–5, Springer, New York,\\nNY, USA, 2017.\\n[8] M. Mahmoudi, A. Yari, and S. Khadivi, “Web spam detection\\nbased on discriminative content and link features,” in Proceedings\\nof the 2010 5th International Symposium on\\nTelecommunications, Tehran, Iran, December 2011.\\n[9] R. K. Roul, S. R. Asthana, M. Shah, and D. Parikh, “Detecting\\nspam web pages using content and link-based techniques,”\\nSadhana, vol. 41, no. 2, pp. 193–202, 2016.\\n[10] J. Deng, H. Chen, and J. Sun, “Uncovering cloaking web pages\\nwith hybrid detection approaches,” in Proceedings of the 2013\\nInternational Symposium on Computational and Business\\nIntelligence, pp. 291–296, IEEE, New Delhi, India, August\\n2013.\\n[11] R. Duan, W. Wang, and W. Lee, “Cloaker catcher: a clientbased\\ncloaking detection system,” 2017, https://arxiv.org/abs/\\n1710.01387.\\n[12] Y. Liu, F. Chen, W. Kong et al., “Identifying web spam with\\nthe wisdom of the crowds,” ACM Transactions on the Web,\\nvol. 6, no. 1, pp. 1–30, 2012.\\n[13] J. Piskorski, M. Sydow, and D. Weiss, “Exploring linguistic\\nfeatures for web spam detection: a preliminary study,” in\\nProceedings of the 4th International Workshop on Adversarial\\nInformation Retrieval on the Web, pp. 25–28, Beijing, China,\\n2008.\\n[14] A. Benczúr, I. Bı́ró, K. . Csalogány, and T. Sarlós, “Web spam\\ndetection via commercial intent analysis,” in Proceedings of\\nthe 3rd International Workshop on Adversarial Information\\nRetrieval on the Web, pp. 89–92, Banff, Canada, May 2007.\\n[15] I. Bı́ró, D. . Siklósi, J. . Szabó, and A. A. Benczúr, “Linked\\nlatent dirichlet allocation in web spam filtering,” in Proceedings\\nof the 5th International Workshop on Adversarial\\nInformation Retrieval on the Web, pp. 37–40, Madrid, Spain,\\nApril 2009.\\n[16] Y. Liu, R. Cen, M. Zhang, S. Ma, and L. Ru, “Identifying web\\nspam with user behavior analysis,” in Proceedings of the 4th\\nInternational Workshop on Adversarial Information Retrieval\\non the Web, pp. 9–16, Beijing, China, April 2008.\\n[17] I. Luca, T. Kurt, A. Kapravelos, O. Comanescu, J.-M. Picod,\\nand E. Bursztein, “Cloak of visibility: detecting when machines\\nbrowse a different web,” in Proceedings of the 2016 IEEE\\nSymposium on Security and Privacy (SP), pp. 743–758, IEEE,\\nSan Jose, CA, USA, May 2016.\\n[18] G. Liu, X. Huang, X. Liu, and H. Fan, “Document sentiment\\nmodeling based on topic attention hierarchy memory\\nSecurity and Communication Networks 13\\n\",\n",
       "  \"network,” Journal of Sichuan University. Natural Science\\nEdition, vol. 56, no. 5, pp. 55–64, 2019.\\n[19] S. H. Reza Mohammadi and M. A. Zare Chahooki, “Web\\nspam detection using multiple kernels in twin support vector\\nmachine,” 2016, https://arxiv.org/abs/1605.02917.\\n[20] J. Fdez-Glez, D. Ruano-Ordás, R. Laza, J. R. Méndez, P. Reyes,\\nand F. Fdez-Riverola, “WSF2: a novel framework for filtering\\nweb spam,” Scientific Programming, vol. 2016, Article ID\\n6091385, , 2016.\\n[21] Y. Mei, J. Zhang, J. Wang, J. Gao, T. Xu, and R. Yu, “'e\\nresearch of spam web page detection method based on web\\npage differentiation and concrete cluster centers,” in Proceedings\\nof the International Conference on Wireless Algo-\\nrithms, Systems, and Applications, pp. 820–826, Springer,\\nTianjin, China, June 2018.\\n[22] H. Jelodar, Y. Wang, C. Yuan, and X. Jiang, “A systematic\\nframework to discover pattern for web spam classification,” in\\nProceedings of the 2017 8th IEEE Annual Information Technology,\\nElectronics and Mobile Communication Conference\\n(IEMCON), pp. 32–39, IEEE, Vancouver, Canada, November\\n2017.\\n[23] F. Asdaghi and A. Soleimani, “An effective feature selection\\nmethod for web spam detection,” Knowledge-Based Systems,\\nvol. 166, pp. 198–206, 2019.\\n[24] M. S. Renato, T. A. Almeida, and A. Yamakami, “Artificial\\nneural networks for content-based web spam detection,” in\\nProceedings on the International Conference on Artificial Intelligence\\n(ICAI), July 2012.\\n[25] Y. Li, X. Nie, and R. Huang, “Web spam classification method\\nbased on deep belief networks,” Expert Systems with Applications,\\nvol. 96, pp. 261–270, 2018.\\n[26] A. Makkar, M. S. Obaidat, and N. Kumar, “FS2RNN: feature\\nselection scheme for web spam detection using recurrent\\nneural networks,” in Proceedings of the 2018 IEEE Global\\nCommunications Conference (GLOBECOM), pp. 1–6, IEEE,\\nAbu Dhabi, UAE, December 2018.\\n[27] A. Belahcen, M. Bianchini, and S. Franco, “Web spam detection\\nusing transductive (inductive graph neural networks,”\\nin Advances in Neural Networks: Computational and ?eoretical\\nIssues, pp. 83–91, Springer, Berlin, Germany, 2015.\\n[28] H. Fu, X. Xie, Y. Rui, N. Z. Gong, G. Sun, and E. Chen,\\n“Robust spammer detection in microblogs,” ACM Transactions\\non Intelligent Systems and Technology, vol. 8, no. 6,\\npp. 1–31, 2017.\\n[29] N.’A. Maulat Samsudin, C. F. Mohd Foozy, N. Alias,\\nP. Shamala, N. F. Othman, and W. I. Sofiah Wan Din,\\n“Youtube spam detection framework using naı̈ve bayes and\\nlogistic regression,” Indonesian Journal of Electrical Engineering\\nand Computer Science, vol. 14, no. 3, pp. 1508–1517,\\n2019.\\n[30] E. Ezpeleta, M. Iturbe, I. Garitano, I. Velez de Mendizabal,\\nU. Zurutuza, and António Sáez, Edited by A. Enrique,\\nde la Cal, Á. Herrero, and H. Quintián, Eds., “Amood analysis\\non youtube comments and a method for improved social\\nspam detection,” in Hybrid Artificial Intelligent Systems,\\nE. Corchado, Ed., pp. 514–525, Springer International Publishing,\\nCham, Switzerland, 2018.\\n[31] Laboratory of Web Algorithmics (http://law.di.unimi.it/)s\\nUniversity of Milan. Web collection uk-2006/uk-2007.\\nhttps://github.com/keras-team/keras (2019).\\n[32] Z. Gyongyi, H. Garcia-Molina, and J. Pedersen, “Combating\\nweb spam with trustrank,” in Proceedings of the 30th International\\nConference on Very Large Data Bases (VLDB),\\nSunnyvale, CA, USA, November 2004.\\n[33] M. Kusner, Yu Sun, N. Kolkin, and K. Weinberger, “From\\nword embeddings to document distances,” in Proceedings of\\nthe International Conference on Machine Learning, pp. 957–\\n966, Lille, France, July 2015.\\n[34] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient\\nestimation of word representations in vector space,” 2013,\\nhttps://arxiv.org/abs/1301.3781.\\n[35] Beautiful soup documentation. https://www.crummy.com/\\nsoftware/BeautifulSoup/bs4/doc (2020).\\n[36] Googlenews-vectors-negative300. https://code.google.com/\\narchive/p/word2vec/(2019).\\n[37] Document object model-introduction to the dom. https://\\ndeveloper.mozilla.org/en-US/docs/Web/API/Document_\\nObject_Model (2020).\\n[38] R. Caruana and A. Niculescu-Mizil, “An empirical comparison\\nof supervised learning algorithms,” in Proceedings of the\\n23rd International Conference on Machine Learning,\\npp. 161–168, New York, NY, USA, June 2006.\\n[39] K. L. Goh and A. K. Singh, “Comprehensive literature review\\non machine learning structures for web spam classification,”\\nProcedia Computer Science, vol. 70, pp. 434–441, 2015.\\n[40] L. Breiman, “Random forests,” Machine Learning, vol. 45,\\nno. 1, pp. 5–32, 2001.\\n[41] F. Pedregosa, G. Varoquaux, A. Gramfort et al., “Scikit-learn:\\nmachine learning in Python,” Journal of Machine Learning\\nResearch, vol. 12, pp. 2825–2830, 2011.\\n[42] Keras: Deep learning for humans. https://github.com/kerasteam/keras\\n(2019).\\n[43] M. Abadi, A. Agarwal, B. Paul et al., “Tensorflow: large-scale\\nmachine learning on heterogeneous distributed systems,”\\n2016, https://arxiv.org/abs/1603.04467.\\n[44] Web spam challenge phase iii results. http://webspam.lip6.fr/\\nwiki/pmwiki.php?n�Main.PhaseIIIResults (2019).\\n[45] H.Wahsheh, I. Abu Doush, M. Al-Kabi, I. Alsmadi, and E. AlShawakfa,\\n“Using machine learning algorithms to detect\\ncontent-based Arabic web spam,” Journal of Information\\nAssurance & Security, vol. 7, no. 1, 2012.\\n[46] S. Mittal and A. Juneja, “Feature selection-model-based\\ncontent analysis for combating web spam,” Computer Science\\n& Information Technology, vol. 6, pp. 27–34, 2016.\\n[47] S. Seabold and J. Perktold, “Statsmodels: econometric and\\nstatistical modeling with python,” in Proceedings of the 9th\\nPython in Science Conference, Austin, TX, USA, July 2010.\\n[48] X. Robin, N. Turck, H. Alexandre et al., “proc: an open-source\\npackage for r and s+ to analyze and compare roc curves,” BMC\\nBioinformatics, vol. 12, no. 1, pp. 1–8, 2011.\\n[49] C. Chen, A. Liaw, L. Breiman et al., Using random forest to\\nlearn imbalanced data, p. 24, University of California, Berkeley,\\nCA, USA, 2004.\\n14 Security and Communication Networks\\n\"],\n",
       " 'id': 'ark://27927/phzk2jpdrwb',\n",
       " 'identifier': [{'name': 'doi', 'value': '10.1155/2020/6662166'},\n",
       "  {'name': 'issn', 'value': '1939-0122'},\n",
       "  {'name': 'issn', 'value': '1939-0114'},\n",
       "  {'name': 'local_publisher_id', 'value': '6662166'},\n",
       "  {'name': 'local_content_set', 'value': 'ISSN_19390114_33'},\n",
       "  {'name': 'journal_id', 'value': 'ark://27927/dfd9d2031m'},\n",
       "  {'name': 'issue_id', 'value': 'ark://27927/dfdbzqfc02'}],\n",
       " 'isPartOf': 'Security and Communication Networks',\n",
       " 'issueNumber': 'null',\n",
       " 'keyphrase': ['web spam',\n",
       "  'features',\n",
       "  'homepage',\n",
       "  'spam detection',\n",
       "  'dataset',\n",
       "  'websites',\n",
       "  'semantic similarity',\n",
       "  'html tags',\n",
       "  'novel features',\n",
       "  'external links'],\n",
       " 'language': ['eng'],\n",
       " 'outputFormat': ['unigram', 'fullText', 'bigram', 'trigram'],\n",
       " 'pageCount': 14,\n",
       " 'provider': 'portico',\n",
       " 'publicationYear': 2020,\n",
       " 'publisher': 'Hindawi',\n",
       " 'sequence': 101,\n",
       " 'tdmCategory': ['Applied sciences - Engineering'],\n",
       " 'title': 'Detecting Web Spam Based on Novel Features from Web Page Source Code',\n",
       " 'url': 'http://doi.org/10.1155/2020/6662166',\n",
       " 'volumeNumber': '2020',\n",
       " 'wordCount': 10800,\n",
       " 'unigramCount': {'∗/': 3,\n",
       "  '1.16.2': 1,\n",
       "  'who': 2,\n",
       "  'sample”': 1,\n",
       "  'values': 1,\n",
       "  'Accuracy': 5,\n",
       "  'higher': 3,\n",
       "  'overall.': 1,\n",
       "  'simple': 1,\n",
       "  'blocks': 2,\n",
       "  'Li': 1,\n",
       "  '29': 1,\n",
       "  'Euclidean': 1,\n",
       "  '100': 3,\n",
       "  'categorized': 1,\n",
       "  'coefficients,': 1,\n",
       "  'along': 1,\n",
       "  'language-model': 1,\n",
       "  'Fan,': 1,\n",
       "  'way,': 1,\n",
       "  '(NB)': 1,\n",
       "  'uk-2006/uk-2007.': 1,\n",
       "  '20': 2,\n",
       "  'example': 1,\n",
       "  'WEBSITE</font>': 1,\n",
       "  'learning,': 2,\n",
       "  'direction': 1,\n",
       "  'Logit': 1,\n",
       "  '6662166,': 1,\n",
       "  'computing': 5,\n",
       "  'contact': 1,\n",
       "  '820–826,': 1,\n",
       "  '2020YFG0076,': 1,\n",
       "  'close': 1,\n",
       "  '<font': 1,\n",
       "  'selection-model-based': 1,\n",
       "  '0.06': 1,\n",
       "  'gain': 1,\n",
       "  'According': 1,\n",
       "  \"'ere\": 14,\n",
       "  '5797': 2,\n",
       "  'problem,': 1,\n",
       "  'algorithm': 13,\n",
       "  '“Identifying': 2,\n",
       "  'Juneja,': 1,\n",
       "  '∈': 4,\n",
       "  'especially': 5,\n",
       "  'versions': 1,\n",
       "  'profits.': 1,\n",
       "  'last–modified:': 1,\n",
       "  'hey': 1,\n",
       "  '32': 1,\n",
       "  'results.': 8,\n",
       "  'minority': 4,\n",
       "  'RAM': 1,\n",
       "  'PageRank': 7,\n",
       "  'two': 14,\n",
       "  'Collectlinks():': 1,\n",
       "  'say': 1,\n",
       "  'techniques': 3,\n",
       "  'lot': 1,\n",
       "  'Experimental': 2,\n",
       "  'Singh,': 1,\n",
       "  'As': 14,\n",
       "  'Berkeley,': 1,\n",
       "  'Annual': 1,\n",
       "  'Engineering': 1,\n",
       "  'Sunnyvale,': 1,\n",
       "  '[47]': 2,\n",
       "  'Some': 4,\n",
       "  'accuracy,': 1,\n",
       "  'page-based': 1,\n",
       "  '“An': 2,\n",
       "  'University,': 2,\n",
       "  'shows': 2,\n",
       "  'blog,': 1,\n",
       "  '(2019).': 3,\n",
       "  'kinds': 1,\n",
       "  'parking': 3,\n",
       "  'Spammers': 1,\n",
       "  'Note': 2,\n",
       "  'j).': 1,\n",
       "  'worse': 1,\n",
       "  'people’s': 1,\n",
       "  '5,': 2,\n",
       "  'contain': 3,\n",
       "  'obvious': 1,\n",
       "  'Alexandre': 1,\n",
       "  'spaces.': 1,\n",
       "  'library,': 1,\n",
       "  'Bravenet.com': 1,\n",
       "  'homepage.': 10,\n",
       "  '[28]': 2,\n",
       "  'machine': 19,\n",
       "  'make': 4,\n",
       "  '“Cloaker': 1,\n",
       "  'j,': 1,\n",
       "  'relied': 1,\n",
       "  'approaches,”': 1,\n",
       "  'show': 5,\n",
       "  'website': 14,\n",
       "  'profiles.': 1,\n",
       "  '(HTML)': 1,\n",
       "  'characteristics.': 1,\n",
       "  '“Scikit-learn:': 1,\n",
       "  'text': 28,\n",
       "  'measuring': 1,\n",
       "  'b506b”': 1,\n",
       "  'build': 2,\n",
       "  '\\U0010ff6f,': 2,\n",
       "  '0.002': 3,\n",
       "  'converted': 1,\n",
       "  'called': 8,\n",
       "  '0.909': 2,\n",
       "  'cluster': 1,\n",
       "  'developing': 1,\n",
       "  'conclusions': 2,\n",
       "  'vectors,': 2,\n",
       "  'scholars': 1,\n",
       "  'cj': 1,\n",
       "  '[44]': 2,\n",
       "  'dhp:': 1,\n",
       "  'NLTK': 2,\n",
       "  'displayed': 1,\n",
       "  '−8.9288': 1,\n",
       "  '[29]': 2,\n",
       "  'deep': 7,\n",
       "  'unrestricted': 1,\n",
       "  '[32]': 1,\n",
       "  'reproduced': 2,\n",
       "  'cybersecurity,': 1,\n",
       "  'HTML': 21,\n",
       "  'applications.': 1,\n",
       "  'inherently': 1,\n",
       "  '[2]': 1,\n",
       "  '3.4.3.': 1,\n",
       "  'precision': 3,\n",
       "  'embeddings.': 1,\n",
       "  '−1.043e': 1,\n",
       "  '1–6,': 1,\n",
       "  '1–31,': 1,\n",
       "  'html': 4,\n",
       "  'banned,”': 1,\n",
       "  'Considering': 2,\n",
       "  '0.00': 2,\n",
       "  'interactive': 1,\n",
       "  'nonspam': 12,\n",
       "  'H.Wahsheh,': 1,\n",
       "  '[48].': 1,\n",
       "  'distance.': 2,\n",
       "  'end': 4,\n",
       "  'themodels': 1,\n",
       "  '11': 2,\n",
       "  'combination': 1,\n",
       "  '2013.': 1,\n",
       "  'validationTransformed': 1,\n",
       "  '743–758,': 1,\n",
       "  'content': 28,\n",
       "  '2': 11,\n",
       "  'author': 2,\n",
       "  'set.': 1,\n",
       "  '0.861': 1,\n",
       "  'AlShawakfa,': 1,\n",
       "  'Soup': 1,\n",
       "  'utility': 1,\n",
       "  'present': 2,\n",
       "  'regression,”': 1,\n",
       "  '0.758': 1,\n",
       "  'process.': 2,\n",
       "  '987': 1,\n",
       "  'when': 7,\n",
       "  'Science,': 3,\n",
       "  '0.863': 2,\n",
       "  'class': 4,\n",
       "  'J.-M.': 1,\n",
       "  '(texthp,': 1,\n",
       "  'run': 1,\n",
       "  'models.': 4,\n",
       "  'Nonspam': 3,\n",
       "  '<meta': 3,\n",
       "  'table': 1,\n",
       "  'values.': 1,\n",
       "  'attributes,': 1,\n",
       "  'models': 8,\n",
       "  'sites.': 1,\n",
       "  'apply': 3,\n",
       "  'bytes': 1,\n",
       "  'L_outdegree_hp': 3,\n",
       "  'request.': 1,\n",
       "  'direct': 1,\n",
       "  'element': 5,\n",
       "  'paper.': 10,\n",
       "  'parameters.': 1,\n",
       "  'balance': 1,\n",
       "  'RNNs': 1,\n",
       "  '30': 1,\n",
       "  'costs': 1,\n",
       "  'Security': 15,\n",
       "  'governments,': 2,\n",
       "  '1.35e': 1,\n",
       "  'little': 1,\n",
       "  'Liu': 3,\n",
       "  '3.4.1.': 1,\n",
       "  'diversity': 1,\n",
       "  'Huang': 1,\n",
       "  'correspondingly.': 1,\n",
       "  '2.3.1': 1,\n",
       "  'date:': 1,\n",
       "  'Algo-': 1,\n",
       "  'If': 1,\n",
       "  'command': 1,\n",
       "  'validation).': 1,\n",
       "  '2012.': 3,\n",
       "  'Jelodar': 1,\n",
       "  'Foozy,': 1,\n",
       "  '3766': 1,\n",
       "  'creates': 1,\n",
       "  'widely': 2,\n",
       "  'separately.': 2,\n",
       "  '277': 1,\n",
       "  'Commons': 1,\n",
       "  'road”': 1,\n",
       "  'functions': 2,\n",
       "  'common': 1,\n",
       "  'cleaning,': 1,\n",
       "  'iii': 1,\n",
       "  'followed.': 1,\n",
       "  'Ence': 1,\n",
       "  '43': 1,\n",
       "  'text.': 1,\n",
       "  'studying': 2,\n",
       "  'With': 2,\n",
       "  'targeting': 1,\n",
       "  'tool': 2,\n",
       "  '4,': 2,\n",
       "  'Kong': 1,\n",
       "  'becoming': 1,\n",
       "  'Initialize': 1,\n",
       "  'dividing': 1,\n",
       "  'preceded': 1,\n",
       "  'countermeasures,”': 1,\n",
       "  'description': 5,\n",
       "  'impact': 2,\n",
       "  '1.0': 2,\n",
       "  'corresponding': 3,\n",
       "  'link,': 3,\n",
       "  'or': 19,\n",
       "  '−1.101e': 1,\n",
       "  'rapid': 2,\n",
       "  'structured': 1,\n",
       "  'upon': 1,\n",
       "  '16.04': 1,\n",
       "  '105,896,555': 1,\n",
       "  'billion': 1,\n",
       "  'A.': 19,\n",
       "  'humans.': 1,\n",
       "  'Design.': 1,\n",
       "  'linkexternal': 4,\n",
       "  'average,': 1,\n",
       "  'Archive': 1,\n",
       "  '−0.0425': 1,\n",
       "  'Global': 2,\n",
       "  'Lille,': 1,\n",
       "  '4.4.3.': 1,\n",
       "  'probably': 1,\n",
       "  '}.': 1,\n",
       "  'pathname': 1,\n",
       "  'most': 7,\n",
       "  '“pROC”': 2,\n",
       "  'Learning': 1,\n",
       "  \"'eir\": 1,\n",
       "  'comments': 3,\n",
       "  'pornographic': 1,\n",
       "  'viability': 1,\n",
       "  'include': 1,\n",
       "  'natural': 1,\n",
       "  'linkexternal:�': 1,\n",
       "  'researchers': 6,\n",
       "  'proposedmethod': 1,\n",
       "  'Knowledge-Based': 1,\n",
       "  '(9)': 3,\n",
       "  'regarded': 1,\n",
       "  'file.': 1,\n",
       "  'Our': 5,\n",
       "  'numbers': 2,\n",
       "  'comprise': 1,\n",
       "  'moon': 1,\n",
       "  '6479': 1,\n",
       "  '−1.084e': 1,\n",
       "  'One': 1,\n",
       "  'before': 2,\n",
       "  'use': 16,\n",
       "  'attention': 2,\n",
       "  'their': 6,\n",
       "  'complete.': 1,\n",
       "  '<head>': 1,\n",
       "  '4.28e': 1,\n",
       "  'cloaking': 4,\n",
       "  'various': 1,\n",
       "  '∀i': 1,\n",
       "  'aimed': 1,\n",
       "  '“WSF2:': 1,\n",
       "  'Genism': 1,\n",
       "  'Similarly,': 1,\n",
       "  'parser': 2,\n",
       "  '“text/javascript”': 1,\n",
       "  'interesting': 1,\n",
       "  'remaining': 1,\n",
       "  '[34],': 1,\n",
       "  '“Tensorflow:': 1,\n",
       "  '“Two': 1,\n",
       "  '0.08': 1,\n",
       "  'word-level': 1,\n",
       "  'inference': 1,\n",
       "  'impressive': 1,\n",
       "  'short-term': 1,\n",
       "  'Conclusions': 1,\n",
       "  'papers': 1,\n",
       "  '321': 1,\n",
       "  'Evaluation': 2,\n",
       "  'SVM': 4,\n",
       "  'conducted': 4,\n",
       "  '0.930.': 1,\n",
       "  'conditions': 1,\n",
       "  'Next,': 2,\n",
       "  'documentation.': 1,\n",
       "  'https://arxiv.org/abs/1301.3781.': 1,\n",
       "  '2.74e': 1,\n",
       "  'supported': 1,\n",
       "  'tendency': 1,\n",
       "  'sum': 2,\n",
       "  'framework': 10,\n",
       "  'of': 352,\n",
       "  'time': 1,\n",
       "  'inserted': 2,\n",
       "  'qualified-link': 1,\n",
       "  'Sun,': 4,\n",
       "  'implemented': 1,\n",
       "  'remain': 1,\n",
       "  'Zare': 1,\n",
       "  'observed': 1,\n",
       "  'eliminating': 2,\n",
       "  'plurality': 1,\n",
       "  '“homepage,”': 1,\n",
       "  'Artificial': 2,\n",
       "  'identification.': 1,\n",
       "  'pROC': 1,\n",
       "  'Proposed': 3,\n",
       "  'Research,': 1,\n",
       "  '<html>': 1,\n",
       "  'crawls”': 1,\n",
       "  'i': 5,\n",
       "  'error,': 1,\n",
       "  'model,': 3,\n",
       "  'on.We': 1,\n",
       "  'https://www.internetlivestats.com/': 1,\n",
       "  'four': 3,\n",
       "  'push': 2,\n",
       "  '(hp)': 2,\n",
       "  '(7),': 1,\n",
       "  'Structural': 1,\n",
       "  'J.': 12,\n",
       "  'Caruana': 1,\n",
       "  'tweets,': 1,\n",
       "  'capture': 1,\n",
       "  'described': 4,\n",
       "  'Bases': 1,\n",
       "  '[40],': 1,\n",
       "  'Search': 2,\n",
       "  'i,j�1': 1,\n",
       "  '5–32,': 1,\n",
       "  '96': 1,\n",
       "  'protocol': 1,\n",
       "  '2014,': 1,\n",
       "  'algorithms': 7,\n",
       "  'roughly.We': 1,\n",
       "  'collected': 1,\n",
       "  'not': 29,\n",
       "  'contins': 1,\n",
       "  'could': 8,\n",
       "  'long': 3,\n",
       "  'searches': 2,\n",
       "  '0.032': 1,\n",
       "  '0.875': 2,\n",
       "  'texts.': 3,\n",
       "  'by,': 1,\n",
       "  'length.': 1,\n",
       "  '10': 3,\n",
       "  'model.': 6,\n",
       "  'practices': 1,\n",
       "  'content.': 1,\n",
       "  'should': 3,\n",
       "  '2008.': 3,\n",
       "  'Sofiah': 1,\n",
       "  'linkn\\U0010ff08': 1,\n",
       "  'heuristic': 1,\n",
       "  'Matplotlib': 1,\n",
       "  'positive': 7,\n",
       "  'types': 3,\n",
       "  'paper,': 6,\n",
       "  '3.5.': 1,\n",
       "  'methods.': 3,\n",
       "  'similarity.': 1,\n",
       "  '.': 23,\n",
       "  'RF': 19,\n",
       "  'convincing.': 1,\n",
       "  'malicious': 5,\n",
       "  'summary': 1,\n",
       "  'Metrics.': 1,\n",
       "  '18': 2,\n",
       "  '321,': 1,\n",
       "  '24,': 1,\n",
       "  'imbalanced': 3,\n",
       "  'does': 2,\n",
       "  'systems;': 1,\n",
       "  'judged': 2,\n",
       "  '0.872': 3,\n",
       "  'Correspondence': 1,\n",
       "  '37–40,': 1,\n",
       "  'deceive': 2,\n",
       "  'user': 6,\n",
       "  'hypertext': 1,\n",
       "  'Varoquaux,': 1,\n",
       "  'UK2007': 1,\n",
       "  'still': 5,\n",
       "  'samples.': 1,\n",
       "  'cost': 2,\n",
       "  '[16]': 2,\n",
       "  'accidental': 1,\n",
       "  'Vectors.': 1,\n",
       "  'Chengdu,': 2,\n",
       "  'today’s': 1,\n",
       "  'measure': 1,\n",
       "  '“undecided”': 1,\n",
       "  'Bayes': 1,\n",
       "  'Reza': 2,\n",
       "  'both': 5,\n",
       "  'while': 2,\n",
       "  'better': 6,\n",
       "  'vol.': 15,\n",
       "  '4.4.1': 1,\n",
       "  'code': 7,\n",
       "  'them': 2,\n",
       "  'Receiver': 2,\n",
       "  'rate': 6,\n",
       "  'For': 11,\n",
       "  'evaluates': 2,\n",
       "  'Rate.': 1,\n",
       "  'selects': 1,\n",
       "  'Jose,': 1,\n",
       "  'spectrum': 1,\n",
       "  '0.957)': 2,\n",
       "  \"'us,\": 4,\n",
       "  'demonstrates': 4,\n",
       "  'often': 3,\n",
       "  \"'ese\": 6,\n",
       "  'government': 1,\n",
       "  '39],': 1,\n",
       "  '[5]': 1,\n",
       "  'method’s': 1,\n",
       "  'interest': 1,\n",
       "  'importances': 1,\n",
       "  'embedding': 4,\n",
       "  'linguistic': 4,\n",
       "  'service,': 1,\n",
       "  'work': 5,\n",
       "  'methods,': 2,\n",
       "  'summary,': 1,\n",
       "  'reduce': 5,\n",
       "  'Japan,': 1,\n",
       "  'per': 2,\n",
       "  'characteristic': 2,\n",
       "  'June': 2,\n",
       "  '(DAE)': 1,\n",
       "  'description,': 1,\n",
       "  'JavaScript.': 1,\n",
       "  'graph': 2,\n",
       "  'file': 3,\n",
       "  '∗': 3,\n",
       "  'later.': 1,\n",
       "  '0.10': 2,\n",
       "  'Moon': 1,\n",
       "  'recall': 3,\n",
       "  'Kapravelos,': 1,\n",
       "  'purposes': 1,\n",
       "  '[48]': 2,\n",
       "  'Communication': 15,\n",
       "  'Coefficients': 1,\n",
       "  'boundary': 1,\n",
       "  'second': 1,\n",
       "  '1998': 1,\n",
       "  'Gao,': 1,\n",
       "  'inclined': 1,\n",
       "  'se-': 1,\n",
       "  'importance.': 1,\n",
       "  'work.': 1,\n",
       "  '(10).': 1,\n",
       "  'representative': 2,\n",
       "  'Word2vec': 1,\n",
       "  '2001.': 1,\n",
       "  'Eds.,': 1,\n",
       "  '“b5571d773461c61:': 1,\n",
       "  'such': 21,\n",
       "  'companies': 1,\n",
       "  'focuses': 2,\n",
       "  '(MKTWSVM),': 1,\n",
       "  'homepages': 1,\n",
       "  'biases': 1,\n",
       "  'Chahooki,': 1,\n",
       "  'interaction': 1,\n",
       "  '0.939': 1,\n",
       "  '“home%20.htm”><img': 1,\n",
       "  'manufacturers.': 1,\n",
       "  '09:02:19': 1,\n",
       "  'blog': 2,\n",
       "  'Sadhana,': 1,\n",
       "  'nonlinear': 1,\n",
       "  'final': 2,\n",
       "  'spam,”': 3,\n",
       "  'develop': 1,\n",
       "  'efficiency': 4,\n",
       "  '35': 1,\n",
       "  'theWMDdistance': 1,\n",
       "  '[46]': 4,\n",
       "  'characteristic,': 1,\n",
       "  '1768': 1,\n",
       "  'simple,': 1,\n",
       "  'worse.': 2,\n",
       "  'advantage': 2,\n",
       "  'challenges': 1,\n",
       "  'sorts': 2,\n",
       "  'large': 5,\n",
       "  'visibility:': 1,\n",
       "  'injected': 1,\n",
       "  'libraries': 1,\n",
       "  'Canada,': 2,\n",
       "  'numbers.': 1,\n",
       "  'calculate': 4,\n",
       "  'i,': 1,\n",
       "  'empirically.': 1,\n",
       "  '(8)': 2,\n",
       "  'Classification': 1,\n",
       "  'greater': 2,\n",
       "  'Electrical': 1,\n",
       "  'calculating': 2,\n",
       "  'static': 1,\n",
       "  '2010': 1,\n",
       "  'machine,”': 1,\n",
       "  'Huang;': 1,\n",
       "  'textkeywords,': 1,\n",
       "  '[43]': 1,\n",
       "  'x–powered–by:': 1,\n",
       "  'Journal': 5,\n",
       "  'Liaw,': 1,\n",
       "  'speaking,': 1,\n",
       "  'knuth–morris–pratt': 1,\n",
       "  'up': 3,\n",
       "  'Conference,': 1,\n",
       "  'Alexa': 1,\n",
       "  'put': 1,\n",
       "  'function': 4,\n",
       "  'CNN': 3,\n",
       "  'set,': 1,\n",
       "  'University.': 1,\n",
       "  'detect.': 1,\n",
       "  'Calculating': 1,\n",
       "  'RNN,': 2,\n",
       "  'Configuration.': 1,\n",
       "  'measures,': 1,\n",
       "  'YouTube': 3,\n",
       "  '0.899': 1,\n",
       "  '2017,': 1,\n",
       "  'obtained': 4,\n",
       "  'ExtractDomain():': 1,\n",
       "  'L.': 4,\n",
       "  'reach': 1,\n",
       "  'space.': 3,\n",
       "  'Cham,': 1,\n",
       "  'ones.': 1,\n",
       "  'Bespoke': 1,\n",
       "  'transductive-inductive': 1,\n",
       "  'blogs,': 1,\n",
       "  'visitors.': 1,\n",
       "  'Yaxis': 1,\n",
       "  'each': 30,\n",
       "  'experimented': 1,\n",
       "  '[38,': 1,\n",
       "  'because': 10,\n",
       "  'applications,': 1,\n",
       "  'matching': 1,\n",
       "  'personal': 2,\n",
       "  'Using': 1,\n",
       "  'detail.': 2,\n",
       "  'assigns': 1,\n",
       "  'prepossessing,': 1,\n",
       "  '=': 34,\n",
       "  'be-': 1,\n",
       "  'incoming': 1,\n",
       "  'homepages.': 2,\n",
       "  'new': 10,\n",
       "  'Complexity': 1,\n",
       "  '�����2': 1,\n",
       "  'extract': 14,\n",
       "  'Makkar,': 1,\n",
       "  '“Content-Type”': 1,\n",
       "  'blogs': 1,\n",
       "  '27': 1,\n",
       "  'increase': 6,\n",
       "  'redirection.': 1,\n",
       "  '38': 1,\n",
       "  'figure': 1,\n",
       "  'Posted': 1,\n",
       "  'mutual': 1,\n",
       "  'anticloaking': 1,\n",
       "  'Xie,': 1,\n",
       "  'scheme': 2,\n",
       "  'Milan.': 1,\n",
       "  'study': 2,\n",
       "  'Line': 2,\n",
       "  'Y.': 6,\n",
       "  'header': 2,\n",
       "  'our': 21,\n",
       "  '1.369': 1,\n",
       "  'only': 21,\n",
       "  'LSTM': 6,\n",
       "  'RenatoMoraes': 1,\n",
       "  'helpful': 2,\n",
       "  'Tr': 1,\n",
       "  'standard': 3,\n",
       "  'follows.': 3,\n",
       "  'forms': 1,\n",
       "  '“Amood': 1,\n",
       "  'Edited': 1,\n",
       "  'Adversarial': 5,\n",
       "  'nos.2020YFG0047': 1,\n",
       "  '(DOM)': 1,\n",
       "  'mainly': 3,\n",
       "  'France,': 1,\n",
       "  '166,': 1,\n",
       "  '−0.043': 1,\n",
       "  'pp.': 26,\n",
       "  'null': 2,\n",
       "  'Permanently,”': 1,\n",
       "  'gradient': 2,\n",
       "  'windows–1252': 2,\n",
       "  'Short': 3,\n",
       "  'India,': 1,\n",
       "  'prediction': 2,\n",
       "  'crowds,”': 1,\n",
       "  'selecting': 1,\n",
       "  'level': 1,\n",
       "  'keras': 1,\n",
       "  'Truncatedpagerank_3_hp': 2,\n",
       "  'vectors': 1,\n",
       "  'uniform': 1,\n",
       "  '0.842': 1,\n",
       "  '06': 4,\n",
       "  '·': 2,\n",
       "  'R.M.I': 1,\n",
       "  'searching.': 1,\n",
       "  'addressed': 2,\n",
       "  '(VLDB),': 1,\n",
       "  'weak': 1,\n",
       "  'allocation': 2,\n",
       "  'calculation.': 1,\n",
       "  '“en-us”>': 1,\n",
       "  'memory': 3,\n",
       "  'http://horwichrmicc.co.uk/index.htm': 1,\n",
       "  '2.380': 1,\n",
       "  'Shah,': 1,\n",
       "  \"“'e\": 1,\n",
       "  'indicate': 1,\n",
       "  'Developers': 1,\n",
       "  'day': 2,\n",
       "  'punctuations': 1,\n",
       "  '2.': 3,\n",
       "  'train': 3,\n",
       "  '(not': 1,\n",
       "  '8': 2,\n",
       "  'LRmodel': 1,\n",
       "  '0.420': 1,\n",
       "  'attacks': 1,\n",
       "  '(11)': 2,\n",
       "  'regard.': 1,\n",
       "  '[9]': 1,\n",
       "  'may': 3,\n",
       "  'class.': 1,\n",
       "  'move': 1,\n",
       "  's+': 1,\n",
       "  'mining': 2,\n",
       "  'times.': 1,\n",
       "  'Alsmadi,': 1,\n",
       "  '(SP),': 1,\n",
       "  'R': 2,\n",
       "  'But,': 2,\n",
       "  'validation,': 1,\n",
       "  'match': 1,\n",
       "  'fully:': 1,\n",
       "  'relative': 1,\n",
       "  'makes': 1,\n",
       "  '¡a¿': 1,\n",
       "  'avoid': 1,\n",
       "  'contains': 6,\n",
       "  'default.': 1,\n",
       "  'Sichuan': 4,\n",
       "  'Najork,Web': 1,\n",
       "  'users,': 2,\n",
       "  'GPU:Nvidia': 1,\n",
       "  'Security,': 1,\n",
       "  'WMD': 17,\n",
       "  'IEEE': 3,\n",
       "  '0.7254': 1,\n",
       "  'assigned': 1,\n",
       "  'Googlenews-vectors-negative300.': 1,\n",
       "  'core': 1,\n",
       "  'textexternal)': 1,\n",
       "  'classified,': 1,\n",
       "  '(MDI)': 1,\n",
       "  'choosing': 1,\n",
       "  'queries;': 1,\n",
       "  'chosen': 2,\n",
       "  '“Linked': 1,\n",
       "  'ex-': 1,\n",
       "  'tree.': 1,\n",
       "  'above,': 1,\n",
       "  'Hybrid': 1,\n",
       "  'add': 2,\n",
       "  'homepage': 32,\n",
       "  'web,”': 1,\n",
       "  '3.4.': 1,\n",
       "  'identifying': 1,\n",
       "  'theWMD': 1,\n",
       "  'data': 27,\n",
       "  'turn': 2,\n",
       "  'When': 1,\n",
       "  'Quintián,': 1,\n",
       "  'set': 15,\n",
       "  '(GLOBECOM),': 1,\n",
       "  'Similarity': 5,\n",
       "  '(2)': 11,\n",
       "  'Intelligent': 2,\n",
       "  'rankings.': 1,\n",
       "  'translates': 1,\n",
       "  '0.869': 2,\n",
       "  '957–': 1,\n",
       "  'hierarchy': 1,\n",
       "  'ra': 1,\n",
       "  'trans-': 1,\n",
       "  'Liu,': 4,\n",
       "  'xi': 1,\n",
       "  'necessary': 4,\n",
       "  'invisible': 1,\n",
       "  'worldwide': 1,\n",
       "  'src': 2,\n",
       "  'Technology,': 3,\n",
       "  'Editor:': 1,\n",
       "  'accurately': 1,\n",
       "  '”': 1,\n",
       "  'brief': 1,\n",
       "  'clear': 2,\n",
       "  '“Artificial': 1,\n",
       "  'May': 4,\n",
       "  'list': 3,\n",
       "  'ExtractText():': 1,\n",
       "  'verify': 3,\n",
       "  'Duan,': 1,\n",
       "  '89–92,': 1,\n",
       "  '4': 6,\n",
       "  'keyword,': 1,\n",
       "  'information.': 2,\n",
       "  '(23)': 1,\n",
       "  'repeat': 1,\n",
       "  '1.': 5,\n",
       "  'users’': 1,\n",
       "  'stored': 2,\n",
       "  '−0.0816': 1,\n",
       "  'one-line': 3,\n",
       "  'propose': 3,\n",
       "  '0.8': 2,\n",
       "  'oversampling': 1,\n",
       "  '(24)': 1,\n",
       "  'Natural': 2,\n",
       "  'https://www.': 1,\n",
       "  'total': 4,\n",
       "  'same': 7,\n",
       "  'texts,': 1,\n",
       "  '6(a)': 1,\n",
       "  '4.4.': 1,\n",
       "  '4.': 1,\n",
       "  'permutation': 1,\n",
       "  'University': 2,\n",
       "  'biased,': 1,\n",
       "  'Truncatedpagerank_1_hp': 2,\n",
       "  'applications': 1,\n",
       "  'intent': 2,\n",
       "  'Agarwal,': 1,\n",
       "  '(hp': 1,\n",
       "  'express': 1,\n",
       "  'Web,': 6,\n",
       "  'Vancouver,': 1,\n",
       "  'te': 1,\n",
       "  'classifier.': 3,\n",
       "  'dj,': 2,\n",
       "  'into': 16,\n",
       "  'testing': 1,\n",
       "  'good': 1,\n",
       "  'type': 4,\n",
       "  'GMT': 2,\n",
       "  'links': 32,\n",
       "  'well': 4,\n",
       "  'distances,”': 1,\n",
       "  'real': 2,\n",
       "  '2057536663&cpv': 1,\n",
       "  'linkbased': 1,\n",
       "  '<b><font': 1,\n",
       "  'Khadivi,': 1,\n",
       "  'document,': 2,\n",
       "  'nodes': 4,\n",
       "  'very': 6,\n",
       "  'highly': 1,\n",
       "  'have': 25,\n",
       "  '4]': 1,\n",
       "  '8G': 1,\n",
       "  'worldwide,': 1,\n",
       "  'Sichuan,': 1,\n",
       "  'p.': 1,\n",
       "  '2015.': 3,\n",
       "  '1–8,': 1,\n",
       "  'browse': 1,\n",
       "  'article,': 1,\n",
       "  'choose': 1,\n",
       "  'value': 10,\n",
       "  'domainhp,': 1,\n",
       "  'schools’': 1,\n",
       "  'Austin,': 1,\n",
       "  '[38]': 1,\n",
       "  'advantages': 2,\n",
       "  'universal.': 1,\n",
       "  'fixed': 1,\n",
       "  '(b)': 2,\n",
       "  'Li,': 1,\n",
       "  'tag': 2,\n",
       "  'detailed': 1,\n",
       "  'concluded': 1,\n",
       "  'Picod,': 1,\n",
       "  'Alias,': 1,\n",
       "  'v0.22.': 1,\n",
       "  'Homepage': 4,\n",
       "  '(SMOTE)': 1,\n",
       "  'enough.': 1,\n",
       "  'BMC': 1,\n",
       "  'discuss': 2,\n",
       "  'concrete': 1,\n",
       "  '25': 1,\n",
       "  'metric': 1,\n",
       "  'e-mail': 1,\n",
       "  'solely': 1,\n",
       "  'namely,': 1,\n",
       "  'try': 1,\n",
       "  'Page': 2,\n",
       "  'BUbiNG–guessed–charset:': 1,\n",
       "  'active.': 1,\n",
       "  'Fdez-Glez': 1,\n",
       "  'spammers.': 1,\n",
       "  'explained': 1,\n",
       "  'authors': 4,\n",
       "  'analyzed.': 1,\n",
       "  'Siklósi,': 1,\n",
       "  '<palign': 2,\n",
       "  'Introduction': 1,\n",
       "  'Represent': 1,\n",
       "  '2020': 2,\n",
       "  'three': 13,\n",
       "  \"'is\": 9,\n",
       "  'link’s': 5,\n",
       "  'WMDtext,': 1,\n",
       "  'python,”': 1,\n",
       "  'Nie,': 1,\n",
       "  'RMI': 1,\n",
       "  'L_pagerank_hp': 3,\n",
       "  'wisdom': 1,\n",
       "  'by': 44,\n",
       "  'elimination': 4,\n",
       "  'be': 33,\n",
       "  '1–5,': 1,\n",
       "  '2017': 1,\n",
       "  'After': 3,\n",
       "  'required.': 2,\n",
       "  'Tijc(i,': 1,\n",
       "  '4745': 2,\n",
       "  'Banff,': 1,\n",
       "  'soup': 1,\n",
       "  'filtering': 2,\n",
       "  'larger': 1,\n",
       "  'DPR': 1,\n",
       "  'quickly.': 1,\n",
       "  'becomes': 1,\n",
       "  'stop': 3,\n",
       "  'during': 2,\n",
       "  'embedded': 2,\n",
       "  'Networks': 14,\n",
       "  '1College': 1,\n",
       "  '∗Depth': 2,\n",
       "  'Tianjin,': 1,\n",
       "  'affected': 1,\n",
       "  'search': 25,\n",
       "  'Academic': 1,\n",
       "  'baseline': 1,\n",
       "  'independent': 2,\n",
       "  'Moved': 1,\n",
       "  'individual': 1,\n",
       "  '2009.': 1,\n",
       "  'texthp:�': 1,\n",
       "  'computational': 2,\n",
       "  'K-means': 1,\n",
       "  '0.890': 2,\n",
       "  'store': 3,\n",
       "  'feature.': 1,\n",
       "  'ensemble': 1,\n",
       "  'conflicts': 1,\n",
       "  'os': 1,\n",
       "  'example,': 10,\n",
       "  'blog/google-organic-click-through-rates-in-2014(2019).': 1,\n",
       "  'Sydow,': 1,\n",
       "  '(link)': 2,\n",
       "  'bold': 1,\n",
       "  'commonality': 1,\n",
       "  'LDA': 1,\n",
       "  'Document': 1,\n",
       "  'Expert': 1,\n",
       "  'comes': 2,\n",
       "  'including': 2,\n",
       "  'embedding,': 2,\n",
       "  '10,': 1,\n",
       "  '5-fold': 1,\n",
       "  'pretrained': 2,\n",
       "  'word2vec': 2,\n",
       "  'discussed': 1,\n",
       "  'distinct': 2,\n",
       "  'remove': 1,\n",
       "  'Piskorski,': 1,\n",
       "  'chi-squared': 1,\n",
       "  'related': 6,\n",
       "  'Next': 1,\n",
       "  'comparisons': 1,\n",
       "  'websites': 15,\n",
       "  'Information': 9,\n",
       "  'Firstly,': 2,\n",
       "  'phase': 1,\n",
       "  'see': 2,\n",
       "  'discard': 2,\n",
       "  'component': 2,\n",
       "  'UK2011': 1,\n",
       "  'NY,': 2,\n",
       "  'performance': 21,\n",
       "  'similarity': 16,\n",
       "  'rigorously,': 1,\n",
       "  'repetitions': 1,\n",
       "  'general': 3,\n",
       "  'contextual': 1,\n",
       "  'Revised': 1,\n",
       "  'these': 21,\n",
       "  'tools': 1,\n",
       "  '“center”>&nbsp;</p>': 1,\n",
       "  '0.15': 1,\n",
       "  '[49].': 1,\n",
       "  'characteristics,': 1,\n",
       "  'Truncatedpagerank_2_hp': 2,\n",
       "  '“Using': 1,\n",
       "  '0.917': 1,\n",
       "  'catcher:': 1,\n",
       "  'Total': 1,\n",
       "  'word': 25,\n",
       "  'BUbiNG–content–digest:': 1,\n",
       "  'sparse': 1,\n",
       "  'at': 3,\n",
       "  'F.': 6,\n",
       "  '[7]': 1,\n",
       "  'continuously': 2,\n",
       "  '0.04': 1,\n",
       "  'to.': 1,\n",
       "  'similarities': 1,\n",
       "  'truncatedpagerank_2_hp': 1,\n",
       "  'Seabold': 1,\n",
       "  '0.472': 1,\n",
       "  'entities': 1,\n",
       "  'special': 1,\n",
       "  'websites.': 8,\n",
       "  '5476': 1,\n",
       "  'modeling': 2,\n",
       "  'validation': 3,\n",
       "  'unchanged': 1,\n",
       "  'open-source': 2,\n",
       "  '6%;': 1,\n",
       "  'border': 1,\n",
       "  'years': 1,\n",
       "  'building': 2,\n",
       "  'ci': 2,\n",
       "  '41,': 1,\n",
       "  'Reyes,': 1,\n",
       "  ...},\n",
       " 'bigramCount': {'File Format': 1,\n",
       "  \"'e advantage\": 2,\n",
       "  'check Feature': 1,\n",
       "  'WMD distance': 5,\n",
       "  'declare that': 1,\n",
       "  'we take': 1,\n",
       "  'a sample': 2,\n",
       "  '“http://pub24.bravenet.com/counter/code.php?id =': 1,\n",
       "  'according to': 5,\n",
       "  'but we': 1,\n",
       "  'can ensure': 1,\n",
       "  'study with': 1,\n",
       "  'Users will': 1,\n",
       "  'only focused': 1,\n",
       "  \"(1) 'is\": 2,\n",
       "  'accidental which': 1,\n",
       "  'novel features,': 5,\n",
       "  'textkeywords, textdescription\\U0010ff6e': 1,\n",
       "  'With machine': 1,\n",
       "  'considering external': 1,\n",
       "  'Figure 6(b)': 1,\n",
       "  'reproduced three': 1,\n",
       "  'returned to': 2,\n",
       "  'web applications.': 1,\n",
       "  'spammers try': 1,\n",
       "  'and Technology': 1,\n",
       "  '= 2”>': 1,\n",
       "  'external link': 6,\n",
       "  \"homepage. 'ere\": 1,\n",
       "  'context information.': 1,\n",
       "  'blog/google-organic-click-through-rates-in-2014(2019). [4]': 1,\n",
       "  'Some web': 1,\n",
       "  '(HTML) structure,': 1,\n",
       "  'build machine': 1,\n",
       "  'reason to': 2,\n",
       "  'is imbalanced': 1,\n",
       "  'experiments studies': 1,\n",
       "  'R to': 1,\n",
       "  'to store': 1,\n",
       "  'Springer, New': 1,\n",
       "  'the first-level': 1,\n",
       "  'collected from': 1,\n",
       "  'web page’s': 3,\n",
       "  'correctly as': 1,\n",
       "  'if (24)': 1,\n",
       "  'process raw': 1,\n",
       "  'well. 4.4.3.': 1,\n",
       "  'HORWICH R.M.I': 1,\n",
       "  '. .': 8,\n",
       "  'Huang, X.': 1,\n",
       "  'the First': 1,\n",
       "  'sets is': 1,\n",
       "  'crawlers observing': 1,\n",
       "  'complete. As': 1,\n",
       "  'methods are': 4,\n",
       "  'the Naive': 1,\n",
       "  '13 years,': 1,\n",
       "  'as too': 1,\n",
       "  '41 0.872': 1,\n",
       "  'Algorithmics (http://law.di.unimi.it/)s': 1,\n",
       "  'pages Homepages': 1,\n",
       "  'L. Goh': 1,\n",
       "  'is general': 1,\n",
       "  'dataset. Category': 1,\n",
       "  'in brackets': 1,\n",
       "  '85% of': 1,\n",
       "  '0.929 and': 2,\n",
       "  '[21] Y.': 1,\n",
       "  'keras [42]': 1,\n",
       "  'word vector': 3,\n",
       "  '= “en-us”>': 1,\n",
       "  'SVM, CNN,': 1,\n",
       "  'paper is': 3,\n",
       "  'hp’s domain': 1,\n",
       "  'times in': 1,\n",
       "  'for a': 2,\n",
       "  '0.833) ROC': 1,\n",
       "  'are mistakenly': 2,\n",
       "  'Features. As': 1,\n",
       "  'null (4)': 1,\n",
       "  'aware of': 1,\n",
       "  'depicted in': 1,\n",
       "  'significantly to': 1,\n",
       "  'when she': 1,\n",
       "  'web applications': 1,\n",
       "  'and Computer': 1,\n",
       "  'T. Sarlós,': 1,\n",
       "  'three studies': 1,\n",
       "  '2.3106 0.420': 1,\n",
       "  'K. Chen,': 1,\n",
       "  'system Ubuntu': 1,\n",
       "  'between spam': 2,\n",
       "  'a special': 1,\n",
       "  'that conducting': 1,\n",
       "  'techniques,” Sadhana,': 1,\n",
       "  'Here are': 1,\n",
       "  'some popular': 1,\n",
       "  '2.74e +': 1,\n",
       "  'Kusner, Yu': 1,\n",
       "  'the wisdom': 1,\n",
       "  'it determines': 1,\n",
       "  'by Bespoke': 1,\n",
       "  'positive and': 1,\n",
       "  'Assurance &': 1,\n",
       "  '(2) features': 1,\n",
       "  'Smart-BT, proposed': 1,\n",
       "  'of impurity-based': 1,\n",
       "  'Structure features': 1,\n",
       "  'because web': 1,\n",
       "  'or a': 1,\n",
       "  'al. [48]': 1,\n",
       "  'measures, such': 1,\n",
       "  'document as': 1,\n",
       "  'line 16)': 1,\n",
       "  '(3) shows,': 1,\n",
       "  'Wan Din,': 1,\n",
       "  'is a': 16,\n",
       "  'models. Considering': 1,\n",
       "  'precision rate': 1,\n",
       "  'we discuss': 2,\n",
       "  'two semantic': 1,\n",
       "  'our data.': 1,\n",
       "  'References [1]': 1,\n",
       "  'a framework': 3,\n",
       "  'S. H.': 1,\n",
       "  'FS2RNN, a': 1,\n",
       "  'analysis of': 1,\n",
       "  'BUbiNG–guessed–charset: windows–1252': 1,\n",
       "  'page of': 1,\n",
       "  'model based': 1,\n",
       "  'by previous': 1,\n",
       "  'business, and': 1,\n",
       "  'extraction from': 1,\n",
       "  '4.4.1. Classifier': 1,\n",
       "  'algorithm for': 1,\n",
       "  'and TrustRank': 1,\n",
       "  'between the': 8,\n",
       "  'as possible.': 1,\n",
       "  \"Availability 'e\": 1,\n",
       "  '“index,” “home,”': 1,\n",
       "  'easy, but': 1,\n",
       "  'results of': 8,\n",
       "  'existing features': 6,\n",
       "  '06 0.963': 1,\n",
       "  'users only': 1,\n",
       "  'easy to': 4,\n",
       "  \"'e larger\": 1,\n",
       "  '24, University': 1,\n",
       "  'We acknowledge': 1,\n",
       "  'Besides, we': 2,\n",
       "  'external links:': 1,\n",
       "  'learning and': 3,\n",
       "  'the 23rd': 1,\n",
       "  'and improve': 1,\n",
       "  '(5) texthp:�': 1,\n",
       "  'method only': 1,\n",
       "  'As shown': 2,\n",
       "  '2825–2830, 2011.': 1,\n",
       "  'are practical.': 1,\n",
       "  'al. [22]': 1,\n",
       "  'five-fold cross-validation': 1,\n",
       "  'L_truncatedpagerank_2_hp −8.9288': 1,\n",
       "  '= “bannerentry.gif': 1,\n",
       "  'with user': 2,\n",
       "  'USA, November': 1,\n",
       "  'text of': 4,\n",
       "  'statically from': 1,\n",
       "  'as JavaScript': 1,\n",
       "  'essential or': 1,\n",
       "  'themodels considered': 1,\n",
       "  '0.2 0.4': 1,\n",
       "  'is used': 4,\n",
       "  'Fierce competition': 1,\n",
       "  'are some': 2,\n",
       "  'same dataset': 1,\n",
       "  '“Statsmodels: econometric': 1,\n",
       "  '2.35e +': 1,\n",
       "  'paper proposes': 1,\n",
       "  'entice users': 2,\n",
       "  'run our': 1,\n",
       "  '0.21.3 Matplotlib': 1,\n",
       "  'homepage of': 5,\n",
       "  'tags. However,': 1,\n",
       "  '2017. [8]': 1,\n",
       "  '“/” could': 1,\n",
       "  \"'us, we\": 2,\n",
       "  'pages as': 1,\n",
       "  'Bianchini, and': 1,\n",
       "  'studies on': 2,\n",
       "  'contents. Li': 1,\n",
       "  'losses on': 1,\n",
       "  '(AUC� 0.957)': 1,\n",
       "  'Chiba, Japan,': 1,\n",
       "  'users’ search': 1,\n",
       "  'vol. 7,': 1,\n",
       "  \"'en, we\": 3,\n",
       "  'and contact': 1,\n",
       "  'Sun, 16': 1,\n",
       "  'keywords and': 2,\n",
       "  'spam, there': 1,\n",
       "  'spam content': 2,\n",
       "  'distributed under': 1,\n",
       "  'Using random': 1,\n",
       "  'experimental environment': 1,\n",
       "  'conduct experiments': 1,\n",
       "  'dataset used': 2,\n",
       "  'word embeddings.': 1,\n",
       "  'each website’s': 1,\n",
       "  'presented in': 2,\n",
       "  'will be': 2,\n",
       "  'Figure 5:': 1,\n",
       "  'the graph': 1,\n",
       "  'redirection. Several': 1,\n",
       "  'the moon': 1,\n",
       "  \"'e cross-validation\": 1,\n",
       "  'link to': 1,\n",
       "  'set are': 1,\n",
       "  'sparse matrix': 1,\n",
       "  'web page.': 3,\n",
       "  'voting of': 1,\n",
       "  'the vector': 2,\n",
       "  'was supported': 1,\n",
       "  'short text': 4,\n",
       "  '5 document,': 1,\n",
       "  'on random': 1,\n",
       "  'spam. Moreover,': 1,\n",
       "  'statsmodels [47]': 1,\n",
       "  'system,” 2017,': 1,\n",
       "  'X. Xie,': 1,\n",
       "  '0.9.0 R': 1,\n",
       "  'the 3rd': 1,\n",
       "  'the generalization': 1,\n",
       "  'However, none': 1,\n",
       "  'in Proceedings': 16,\n",
       "  'score is': 1,\n",
       "  'a relatively': 1,\n",
       "  'to. Since': 1,\n",
       "  'information hiding': 1,\n",
       "  'Huang 1': 1,\n",
       "  'R. Cen,': 1,\n",
       "  'respectively. c(i,': 1,\n",
       "  '0.843) ROC': 1,\n",
       "  'mover’s distance.': 1,\n",
       "  'Caruana and': 1,\n",
       "  'content on': 1,\n",
       "  'summary of': 1,\n",
       "  'websites. However,': 1,\n",
       "  'so the': 1,\n",
       "  'N.’A. Maulat': 1,\n",
       "  'features into': 4,\n",
       "  '(b) Figure': 1,\n",
       "  '5%. Our': 1,\n",
       "  'tag and': 1,\n",
       "  'sets, direct': 1,\n",
       "  'Zhang, S.': 1,\n",
       "  'links. Lina': 1,\n",
       "  'the textual': 1,\n",
       "  '1.0 Figure': 1,\n",
       "  'such as': 18,\n",
       "  'challenging. Because': 1,\n",
       "  'importance analysis.': 1,\n",
       "  'Japan, May': 1,\n",
       "  'detection model.': 3,\n",
       "  'and schools’': 1,\n",
       "  'As Table': 1,\n",
       "  '2012. [25]': 1,\n",
       "  'Shah, and': 1,\n",
       "  'tree, we': 1,\n",
       "  'calculating page': 1,\n",
       "  'Section 4.1.': 1,\n",
       "  'the proposedmethod': 1,\n",
       "  'judged whether': 1,\n",
       "  '60 40': 1,\n",
       "  'Jelodar et': 1,\n",
       "  '0.863 0.865': 1,\n",
       "  'vol. 166,': 1,\n",
       "  '(RF) as': 1,\n",
       "  'not been': 1,\n",
       "  'distance. 6': 1,\n",
       "  'our experiments,': 1,\n",
       "  'by crawlers': 1,\n",
       "  'ExtractLinkText (link)': 1,\n",
       "  '0.865 Receiver': 1,\n",
       "  'interesting direction.': 1,\n",
       "  'data from': 2,\n",
       "  'element nodes': 3,\n",
       "  '2019. [19]': 1,\n",
       "  'belongs. In': 1,\n",
       "  'or more': 1,\n",
       "  'operating characteristic': 1,\n",
       "  'easily accessible.': 1,\n",
       "  'the ability': 1,\n",
       "  'Several researchers': 2,\n",
       "  'the consideration': 1,\n",
       "  '37 <b><font': 1,\n",
       "  'the modified': 1,\n",
       "  'Source Code': 1,\n",
       "  'to click.': 1,\n",
       "  'Wang, C.': 1,\n",
       "  'required. Line': 1,\n",
       "  'standard dataset': 1,\n",
       "  'lot of': 1,\n",
       "  'example, Jakub': 1,\n",
       "  'and line': 1,\n",
       "  'tweets, and': 1,\n",
       "  'challenge phase': 1,\n",
       "  'even malicious': 1,\n",
       "  'NY, USA,': 2,\n",
       "  'value. All': 1,\n",
       "  'Proposed Model.': 1,\n",
       "  'not null': 1,\n",
       "  'thought much': 1,\n",
       "  'the 106': 1,\n",
       "  'dependent on': 1,\n",
       "  'web page,': 1,\n",
       "  'Switzerland, 2018.': 1,\n",
       "  'which categorize': 1,\n",
       "  'and Check.': 1,\n",
       "  'spam web': 2,\n",
       "  'pagerank value': 3,\n",
       "  'problem, the': 1,\n",
       "  'analyzed statically': 1,\n",
       "  'It means': 1,\n",
       "  'can remain': 1,\n",
       "  'types have': 1,\n",
       "  'butmay also': 1,\n",
       "  'documents in': 1,\n",
       "  'Table 4:': 1,\n",
       "  'of precision': 1,\n",
       "  'model (DOM)': 1,\n",
       "  'directly copy': 1,\n",
       "  'performance in': 1,\n",
       "  'Xu, and': 1,\n",
       "  'differentiation and': 1,\n",
       "  'comprehensive evaluation': 1,\n",
       "  'rank top': 1,\n",
       "  '“0” src': 1,\n",
       "  'reduction on': 1,\n",
       "  'vanishing of': 1,\n",
       "  'written in': 1,\n",
       "  '32GB RAM': 1,\n",
       "  'changes. Also,': 1,\n",
       "  \"learning. 'erefore,\": 1,\n",
       "  'homepage text,': 1,\n",
       "  '2020 Academic': 1,\n",
       "  'to make': 2,\n",
       "  'al. [16]': 1,\n",
       "  'Furthermore, RF': 1,\n",
       "  'example data': 1,\n",
       "  '8G Genism': 1,\n",
       "  'shown in': 4,\n",
       "  '2008. [17]': 1,\n",
       "  'extracted more': 1,\n",
       "  'experiment results': 2,\n",
       "  '(line 1)': 1,\n",
       "  '[23] 28': 1,\n",
       "  'pages in': 3,\n",
       "  '∗ on': 1,\n",
       "  'google-search-statistics/(2019). [3]': 1,\n",
       "  'probably the': 1,\n",
       "  'detection,” Knowledge-Based': 1,\n",
       "  '0.859 0.842': 1,\n",
       "  '7, no.': 1,\n",
       "  'each step': 1,\n",
       "  'j, as': 1,\n",
       "  'coefficients, standard': 1,\n",
       "  'benchmark traditional': 1,\n",
       "  'Tianjin, China,': 1,\n",
       "  'Also, the': 3,\n",
       "  'very imbalanced.': 2,\n",
       "  'Berkeley, CA,': 1,\n",
       "  'The website': 1,\n",
       "  'Reza Mohammadi': 2,\n",
       "  'LR 0.888': 1,\n",
       "  'in turn': 2,\n",
       "  'encountering a': 1,\n",
       "  'utilizes TPR': 1,\n",
       "  'rate ROC': 1,\n",
       "  'S. Franco,': 1,\n",
       "  'Learning Research,': 1,\n",
       "  'texts −0.0816': 1,\n",
       "  'validation can': 1,\n",
       "  'delicately to': 1,\n",
       "  'reduce computational': 1,\n",
       "  'some pages': 1,\n",
       "  'environment configuration': 1,\n",
       "  'this field.': 1,\n",
       "  'this web': 1,\n",
       "  'studies are': 1,\n",
       "  'automatically 2': 1,\n",
       "  'domain parking': 2,\n",
       "  'by users': 1,\n",
       "  'PageRank (mp)': 1,\n",
       "  'by subtracting': 1,\n",
       "  '4.1. Dataset.': 1,\n",
       "  'to verify': 1,\n",
       "  'CNN, and': 1,\n",
       "  'word embedding': 2,\n",
       "  '5797 3766': 1,\n",
       "  'J corresponds': 1,\n",
       "  '= “center”>&nbsp;</p>': 1,\n",
       "  'document of': 2,\n",
       "  'link from': 1,\n",
       "  'one reason.': 1,\n",
       "  'precision, recall,': 1,\n",
       "  'July 2012.': 1,\n",
       "  '(SEO) that': 1,\n",
       "  'a welldesigned': 1,\n",
       "  'deceive search': 2,\n",
       "  '= 363671': 1,\n",
       "  'paper, we': 6,\n",
       "  'the shortcomings': 1,\n",
       "  'on Novel': 1,\n",
       "  'snippet of': 1,\n",
       "  '4.4.1 Python': 1,\n",
       "  'Universities. References': 1,\n",
       "  'December 2018.': 1,\n",
       "  'more popular': 1,\n",
       "  'spam, and': 2,\n",
       "  'Paul et': 1,\n",
       "  'spam. Secondly,': 1,\n",
       "  'conducting the': 1,\n",
       "  'Conference (IEMCON),': 1,\n",
       "  \"meaningless. 'ere\": 1,\n",
       "  'great significance': 1,\n",
       "  '= “center”>': 4,\n",
       "  'methods including': 1,\n",
       "  'optimistically biased,': 1,\n",
       "  'model (AUC�': 2,\n",
       "  'rate (FPR)': 1,\n",
       "  'specific websites,': 1,\n",
       "  'for users,': 1,\n",
       "  'the precomputed': 2,\n",
       "  'Short Text': 1,\n",
       "  '1.35e +': 1,\n",
       "  \"capabilities. 'ere\": 1,\n",
       "  'Homepage Extraction': 1,\n",
       "  'the web': 20,\n",
       "  'links is': 1,\n",
       "  'template. We': 1,\n",
       "  'ROC curve': 11,\n",
       "  'that, from': 1,\n",
       "  'used to': 7,\n",
       "  'most important': 1,\n",
       "  'Mobile Communication': 1,\n",
       "  '(not bold),': 1,\n",
       "  'paper applies': 1,\n",
       "  'work well': 1,\n",
       "  'indegree of': 1,\n",
       "  'blog websites,': 1,\n",
       "  'less than': 5,\n",
       "  'problem by': 1,\n",
       "  'model that': 1,\n",
       "  '2004. 14': 1,\n",
       "  'check whether': 1,\n",
       "  'stages. For': 1,\n",
       "  'archive/p/word2vec/(2019). [37]': 1,\n",
       "  'homepage is': 4,\n",
       "  'impurity-based feature': 1,\n",
       "  'on web': 4,\n",
       "  '2020; Accepted': 1,\n",
       "  'windows–1252 3': 1,\n",
       "  'used in': 6,\n",
       "  'error in': 1,\n",
       "  'graph neural': 2,\n",
       "  'and each': 2,\n",
       "  'partial web': 1,\n",
       "  'features,” in': 1,\n",
       "  'an F1': 1,\n",
       "  'L_pagerank_hp 0.0472': 1,\n",
       "  '21 0.930': 1,\n",
       "  'features of': 1,\n",
       "  'a differentiation': 1,\n",
       "  'not in': 1,\n",
       "  'pages where': 1,\n",
       "  'attributes that': 1,\n",
       "  'detect organic': 1,\n",
       "  'research, this': 1,\n",
       "  'Spammers design': 1,\n",
       "  'censorship and': 1,\n",
       "  'for storing': 1,\n",
       "  'method can': 2,\n",
       "  'single feature.': 1,\n",
       "  'homepage’s links,': 2,\n",
       "  'Score and': 1,\n",
       "  '0.000 Depth': 1,\n",
       "  'all features.': 1,\n",
       "  'analyzed web': 1,\n",
       "  'Systems with': 1,\n",
       "  'some simple': 1,\n",
       "  'target browser,': 1,\n",
       "  'other hyperparameters,': 1,\n",
       "  'false positive': 1,\n",
       "  '0.902). Also,': 1,\n",
       "  'WARC format.': 1,\n",
       "  'then (5)': 1,\n",
       "  'and detailed': 1,\n",
       "  'Based on': 4,\n",
       "  'much research': 1,\n",
       "  '&usernum =': 1,\n",
       "  'N. Alias,': 1,\n",
       "  'first-level path': 1,\n",
       "  'comparisons based': 1,\n",
       "  'Semantic Similarity': 1,\n",
       "  'Content-based features': 1,\n",
       "  'identify web': 1,\n",
       "  'ground quickly.': 1,\n",
       "  'authoritativeness when': 1,\n",
       "  'Networks classify': 1,\n",
       "  'spam classification': 3,\n",
       "  'and page’s': 1,\n",
       "  'and structure': 2,\n",
       "  'H. Quintián,': 1,\n",
       "  'Z. Gyongyi': 1,\n",
       "  'demonstrates the': 2,\n",
       "  'now. Developers': 1,\n",
       "  'cumulative distance': 1,\n",
       "  'T. Kurt,': 1,\n",
       "  'augment the': 1,\n",
       "  'visiting patterns': 1,\n",
       "  'charset =': 1,\n",
       "  'concluded that': 1,\n",
       "  'features that': 1,\n",
       "  'a challenge': 1,\n",
       "  'lists: texthp': 1,\n",
       "  'in vector': 1,\n",
       "  'if (linkexternal': 2,\n",
       "  'domain name': 1,\n",
       "  'xi, xj': 1,\n",
       "  'achieve redirection,': 1,\n",
       "  'Model. We': 1,\n",
       "  'Nie, and': 1,\n",
       "  '“Comprehensive literature': 1,\n",
       "  'When users': 1,\n",
       "  'course, all': 1,\n",
       "  'to what': 1,\n",
       "  'engine companies': 1,\n",
       "  '(iii) ExtractLinkText():': 1,\n",
       "  'linkbased web': 1,\n",
       "  '[12]. Detection': 1,\n",
       "  'some features,': 1,\n",
       "  'sets. In': 1,\n",
       "  'addition to': 1,\n",
       "  '= 0.875)': 1,\n",
       "  '(12) Receiver': 1,\n",
       "  'permits unrestricted': 1,\n",
       "  'same or': 1,\n",
       "  '0.000 Similarity': 1,\n",
       "  'with efficiency': 1,\n",
       "  'it could': 1,\n",
       "  'on Very': 1,\n",
       "  'predictions over': 1,\n",
       "  'can increase': 1,\n",
       "  'overfitting to': 1,\n",
       "  'can provide': 1,\n",
       "  'set every': 1,\n",
       "  'complexity features,': 1,\n",
       "  \"'e original\": 1,\n",
       "  'distance calculation.': 1,\n",
       "  'Features. We': 1,\n",
       "  'to believe': 2,\n",
       "  'Since models': 1,\n",
       "  'provided the': 1,\n",
       "  'engineering methods': 1,\n",
       "  'are probably': 1,\n",
       "  'X. Robin,': 1,\n",
       "  'the Yaxis': 1,\n",
       "  'homepage. Statistics': 1,\n",
       "  'researchers and': 2,\n",
       "  'paired ROC': 1,\n",
       "  'through searching.': 1,\n",
       "  '(7) linkexternal:�': 1,\n",
       "  'helpful to': 1,\n",
       "  'with useful': 1,\n",
       "  'use these': 1,\n",
       "  'brief definition': 1,\n",
       "  'dataset. As': 1,\n",
       "  'undescribed features': 1,\n",
       "  'pp. 1–30,': 1,\n",
       "  'text and': 4,\n",
       "  'M. Al-Kabi,': 1,\n",
       "  'Picod, and': 1,\n",
       "  'selecting RF': 1,\n",
       "  'article about': 1,\n",
       "  'and number': 1,\n",
       "  'that machine': 1,\n",
       "  'text. As': 1,\n",
       "  'evaluation indicators.': 1,\n",
       "  'of hyperlinks,': 1,\n",
       "  'score Our': 1,\n",
       "  \"proposed method.'e\": 1,\n",
       "  'studies were': 1,\n",
       "  'elimination feature': 1,\n",
       "  'text “moves”': 1,\n",
       "  'a potent': 1,\n",
       "  'S. Obaidat,': 1,\n",
       "  'Generally, for': 1,\n",
       "  'i in': 2,\n",
       "  'phase iii': 1,\n",
       "  'also analyze': 1,\n",
       "  'selection. Belahcen': 1,\n",
       "  'websites and': 2,\n",
       "  '3.5. Classification': 1,\n",
       "  '6091385, ,': 1,\n",
       "  'every external': 1,\n",
       "  'belief networks': 1,\n",
       "  'most common': 1,\n",
       "  'UK-2011 dataset': 1,\n",
       "  'with less': 1,\n",
       "  'normal web': 1,\n",
       "  'Springer, Berlin,': 1,\n",
       "  'of texts': 4,\n",
       "  'speaking, web': 1,\n",
       "  'J. Perktold,': 1,\n",
       "  'How far': 1,\n",
       "  'curves’ p': 1,\n",
       "  'link with': 1,\n",
       "  'functions in': 1,\n",
       "  'G. Varoquaux,': 1,\n",
       "  'Yamakami, “Artificial': 1,\n",
       "  \"'us, WMD\": 1,\n",
       "  '& Information': 1,\n",
       "  'rate and': 1,\n",
       "  'able to': 1,\n",
       "  'top overall.': 1,\n",
       "  'to detect.': 1,\n",
       "  \"correspondingly. 'ere\": 1,\n",
       "  'build web': 1,\n",
       "  'hyperlink is': 1,\n",
       "  'ci \\U0010ff50': 1,\n",
       "  'J. Fdez-Glez,': 1,\n",
       "  \"nonspam. 'e\": 1,\n",
       "  'worldwide, Google': 1,\n",
       "  'that all': 1,\n",
       "  'pretrained English': 1,\n",
       "  \"space. 'e\": 2,\n",
       "  '1.7910 0.249': 1,\n",
       "  'page for': 1,\n",
       "  'main challenges': 1,\n",
       "  'code of': 3,\n",
       "  'that this': 1,\n",
       "  'Technology Program': 1,\n",
       "  'Science Foundation': 1,\n",
       "  'memory (LSTM),': 1,\n",
       "  'websites contain': 1,\n",
       "  'the WEBSPAMUK2007': 1,\n",
       "  'it would': 2,\n",
       "  'Section 3': 2,\n",
       "  'ROC curves': 1,\n",
       "  'RNN has': 1,\n",
       "  'tags but': 1,\n",
       "  '4, after': 1,\n",
       "  'negative (FN)': 1,\n",
       "  'representations in': 1,\n",
       "  'E. Bursztein,': 1,\n",
       "  'its authoritativeness': 1,\n",
       "  'https://arxiv.org/abs/1605.02917. [20]': 1,\n",
       "  '1.16.2 Table': 1,\n",
       "  '(2) Number': 1,\n",
       "  'special case': 1,\n",
       "  'al. [30]': 1,\n",
       "  'al. [24]': 1,\n",
       "  'detail. 3.1.': 1,\n",
       "  'main contributions': 1,\n",
       "  'relative paths': 1,\n",
       "  'is universal.': 1,\n",
       "  'ID 6091385,': 1,\n",
       "  'Truncatedpagerank_4_hp Truncatedpagerank_1_hp': 2,\n",
       "  'some punctuations': 1,\n",
       "  'user visiting': 1,\n",
       "  'Detecting Web': 1,\n",
       "  'a lot': 1,\n",
       "  'the ratio': 1,\n",
       "  'content =': 3,\n",
       "  '[28] H.': 1,\n",
       "  'text or': 1,\n",
       "  'users.When encountering': 1,\n",
       "  'analysis and': 4,\n",
       "  'smaller the': 1,\n",
       "  'she is': 1,\n",
       "  'Jakub Piskorski': 1,\n",
       "  'Fu, X.': 1,\n",
       "  '4745 nonspam': 1,\n",
       "  '(21) else': 1,\n",
       "  'the link-based': 1,\n",
       "  'logistic regression': 2,\n",
       "  'classification result': 1,\n",
       "  'Asdaghi et': 1,\n",
       "  'composed of': 1,\n",
       "  'the sum': 1,\n",
       "  'and features': 1,\n",
       "  'Statistics show': 1,\n",
       "  \"selection. 'is\": 1,\n",
       "  'features contribute': 1,\n",
       "  'class to': 1,\n",
       "  'Technology, vol.': 2,\n",
       "  \"applications. 'e\": 1,\n",
       "  'another document': 2,\n",
       "  'Secondly, cross-validation': 1,\n",
       "  'spam. As': 1,\n",
       "  'results pages,': 1,\n",
       "  'An example': 1,\n",
       "  'in Python,”': 1,\n",
       "  'hyperlinks that': 2,\n",
       "  '0.5. Where': 1,\n",
       "  'only existing': 2,\n",
       "  'and K.': 1,\n",
       "  'data labeled': 1,\n",
       "  'page. (2)': 1,\n",
       "  '(https://chato.cl/webspam/ datasets/uk2007/contents/excerpt.txt)': 1,\n",
       "  'features. If': 1,\n",
       "  'Academic Editor:': 1,\n",
       "  'we only': 4,\n",
       "  'these pages': 2,\n",
       "  'multiple lines': 1,\n",
       "  'html tags': 4,\n",
       "  'spam technique': 1,\n",
       "  'state-of-art methods;': 1,\n",
       "  'three pages': 1,\n",
       "  'with 138': 1,\n",
       "  'Design. We': 1,\n",
       "  'we proposed': 1,\n",
       "  'x–powered–by: ASP.NET': 1,\n",
       "  'last–modified: Sun,': 1,\n",
       "  'end, as': 1,\n",
       "  'statistical characteristics': 1,\n",
       "  'literature [5];': 1,\n",
       "  '4 sets,': 1,\n",
       "  'redirection web': 2,\n",
       "  'the ranking': 3,\n",
       "  'Goh and': 1,\n",
       "  'to detecting': 1,\n",
       "  'Detection model': 1,\n",
       "  'boundary between': 1,\n",
       "  'Sunnyvale, CA,': 1,\n",
       "  'as most': 1,\n",
       "  '(PI) in': 1,\n",
       "  'outstanding characteristic,': 1,\n",
       "  'of metatag': 1,\n",
       "  'types of': 2,\n",
       "  'and T.': 1,\n",
       "  '“FS2RNN: feature': 1,\n",
       "  '(14) end': 1,\n",
       "  'value 100': 1,\n",
       "  '[13] J.': 1,\n",
       "  'j�1 cj': 1,\n",
       "  'and test': 1,\n",
       "  'Foozy, N.': 1,\n",
       "  'content-based analysis': 1,\n",
       "  '3.4.1. Link': 1,\n",
       "  'developed in': 1,\n",
       "  'to another': 3,\n",
       "  'trees voting': 1,\n",
       "  '20 0': 1,\n",
       "  'Gao, T.': 1,\n",
       "  'more labeled': 1,\n",
       "  'backward elimination': 3,\n",
       "  'to other': 1,\n",
       "  'covering the': 1,\n",
       "  'by studying': 1,\n",
       "  'results in': 2,\n",
       "  '(1) hp:': 1,\n",
       "  'page belongs.': 1,\n",
       "  'link features,”': 1,\n",
       "  'an RNN': 2,\n",
       "  'tree model': 1,\n",
       "  'tools for': 1,\n",
       "  '2016, https://arxiv.org/abs/1605.02917.': 1,\n",
       "  'fully: (1)': 1,\n",
       "  'existing methods.': 1,\n",
       "  'experiments, with': 1,\n",
       "  'many research': 1,\n",
       "  '(ROC) curve': 1,\n",
       "  '(6) Cross': 1,\n",
       "  \"'e rest\": 1,\n",
       "  'entry link,': 1,\n",
       "  'spammers by': 1,\n",
       "  'it predicts': 1,\n",
       "  '[17] studied': 1,\n",
       "  'online shopping': 1,\n",
       "  'Expert Systems': 1,\n",
       "  'To extract': 1,\n",
       "  'Matplotlib 3.1.1': 1,\n",
       "  'Document object': 1,\n",
       "  'ranking. Some': 1,\n",
       "  'work in': 1,\n",
       "  'new users.When': 1,\n",
       "  'specific implementation': 1,\n",
       "  'Y. Liu,': 2,\n",
       "  'is compared': 1,\n",
       "  'of tags': 2,\n",
       "  '(TPR), is': 1,\n",
       "  '(22) WMDtext': 1,\n",
       "  'Dataset used': 1,\n",
       "  'of decision': 3,\n",
       "  'research value,': 1,\n",
       "  'hiding technology': 1,\n",
       "  'Rate. We': 1,\n",
       "  'which is': 8,\n",
       "  'of sorts': 1,\n",
       "  'another page': 1,\n",
       "  'it biased': 1,\n",
       "  '2”> 34': 1,\n",
       "  'that very': 1,\n",
       "  'we apply': 1,\n",
       "  'accuracy becomes': 1,\n",
       "  'into numerical': 1,\n",
       "  'et al.,': 5,\n",
       "  'dataset is': 8,\n",
       "  'i to': 1,\n",
       "  'We add': 1,\n",
       "  'performed well.': 1,\n",
       "  'still active.': 1,\n",
       "  'F. Asdaghi': 1,\n",
       "  'largest curve': 1,\n",
       "  'Mohammadi et': 1,\n",
       "  \"'is is\": 1,\n",
       "  'Springer International': 1,\n",
       "  'specific keyword,': 1,\n",
       "  'and effective.': 2,\n",
       "  'link into': 1,\n",
       "  'tags with': 1,\n",
       "  'and qualified-link': 1,\n",
       "  'real-world aerial': 1,\n",
       "  'We extract': 2,\n",
       "  'users, pointing': 1,\n",
       "  '= “horwich”“rmi”“winter': 1,\n",
       "  'econometric and': 1,\n",
       "  'features, number': 1,\n",
       "  'L_truncatedpagerank_3_hp Truncatedpagerank_4_hp': 2,\n",
       "  'data [3,': 1,\n",
       "  'domain Next,': 1,\n",
       "  '(from line': 2,\n",
       "  'Figure 2:': 1,\n",
       "  'with other': 2,\n",
       "  'distinguish web': 3,\n",
       "  'the Ubuntu': 1,\n",
       "  'ensemble learning': 1,\n",
       "  '(3) Initialize': 1,\n",
       "  'Cham, Switzerland,': 1,\n",
       "  'pp. 434–441,': 1,\n",
       "  'models’ area': 1,\n",
       "  'sinceweb spampages': 1,\n",
       "  '4.2.3. Experiment': 1,\n",
       "  'features, and': 4,\n",
       "  'search results': 1,\n",
       "  'parameter “n_estimators”': 1,\n",
       "  'be regarded': 1,\n",
       "  'classifier for': 1,\n",
       "  'practical. 10': 1,\n",
       "  'we re-extracted': 1,\n",
       "  '[46] achieved': 1,\n",
       "  'a DOM': 2,\n",
       "  'example, cloaking': 1,\n",
       "  'design pages': 1,\n",
       "  \"'e three\": 1,\n",
       "  'Alexa Top': 1,\n",
       "  'we find': 2,\n",
       "  'conducted commercial': 1,\n",
       "  'on static': 1,\n",
       "  'accuracy. Many': 1,\n",
       "  'mainly focused': 2,\n",
       "  'element nodes.': 1,\n",
       "  'are the': 1,\n",
       "  'many paragraph': 1,\n",
       "  'X. Liu,': 1,\n",
       "  'a higher': 1,\n",
       "  'WMD Distance.': 1,\n",
       "  'issue to': 1,\n",
       "  'embedded into': 1,\n",
       "  'will also': 1,\n",
       "  'texts ∗Similarity': 2,\n",
       "  'the short': 1,\n",
       "  'As discussed': 1,\n",
       "  '11 greater': 1,\n",
       "  'the main': 3,\n",
       "  'embedding, and': 1,\n",
       "  'spam Nonspam': 1,\n",
       "  '13:11:10 GMT': 1,\n",
       "  '[15] I.': 1,\n",
       "  'document I': 1,\n",
       "  'We utilize': 1,\n",
       "  'detail. Step': 1,\n",
       "  'ranking. Users': 1,\n",
       "  'with sorts': 1,\n",
       "  'spam that': 1,\n",
       "  'samples of': 2,\n",
       "  'n{ }.': 1,\n",
       "  'scheme for': 1,\n",
       "  'little as': 1,\n",
       "  'a website.': 1,\n",
       "  'Search engine': 2,\n",
       "  'imbalanced data,': 1,\n",
       "  'of these': 3,\n",
       "  '24 is': 1,\n",
       "  '“Uncovering cloaking': 1,\n",
       "  'a large': 4,\n",
       "  '(GLOBECOM), pp.': 1,\n",
       "  'evaluates the': 1,\n",
       "  'whether the': 3,\n",
       "  'features (6)': 2,\n",
       "  'learning algorithms,”': 1,\n",
       "  'anchor text∗/': 1,\n",
       "  '957– 966,': 1,\n",
       "  'RF yields': 1,\n",
       "  '3 feature': 1,\n",
       "  'for feature': 2,\n",
       "  'of cross': 7,\n",
       "  'HTML tags.': 1,\n",
       "  'year worldwide': 1,\n",
       "  'classified as': 2,\n",
       "  'useful for': 2,\n",
       "  'automatic classifier': 1,\n",
       "  'Work Web': 1,\n",
       "  '(SP), pp.': 1,\n",
       "  'in microblogs,”': 1,\n",
       "  'and convert': 1,\n",
       "  'factories contain': 1,\n",
       "  'By removing': 1,\n",
       "  'paper does': 1,\n",
       "  'samples was': 1,\n",
       "  'Web spam': 4,\n",
       "  'results are': 4,\n",
       "  'affected by': 1,\n",
       "  \"detection. 'erefore,\": 1,\n",
       "  'Figure 1.': 1,\n",
       "  'depending on': 1,\n",
       "  'step is': 1,\n",
       "  'of mining': 1,\n",
       "  'evaluate the': 6,\n",
       "  'E. Corchado,': 1,\n",
       "  'templates, such': 1,\n",
       "  'Experiment for': 3,\n",
       "  'precomputed existing': 2,\n",
       "  'gradient disappearance;': 1,\n",
       "  'Paper Galaxy': 1,\n",
       "  'users find': 1,\n",
       "  '1–6, IEEE,': 1,\n",
       "  \"data. 'e\": 2,\n",
       "  '0.835 0.810': 1,\n",
       "  'is far': 1,\n",
       "  '45, no.': 1,\n",
       "  'Also, they': 1,\n",
       "  'a comprehensive': 1,\n",
       "  'in Advances': 1,\n",
       "  'on Machine': 2,\n",
       "  'word embedding,': 1,\n",
       "  'into multiple': 1,\n",
       "  '= “0”': 1,\n",
       "  'Analysis 4.4.1.': 1,\n",
       "  'Web Algorithmics': 1,\n",
       "  'results using': 1,\n",
       "  'or not.': 2,\n",
       "  'the minority': 2,\n",
       "  'on specific': 1,\n",
       "  'in mathematical': 1,\n",
       "  'discuss the': 1,\n",
       "  'domain name.': 1,\n",
       "  'superiority of': 1,\n",
       "  'method performs': 1,\n",
       "  'the random': 1,\n",
       "  'Model Accuracy': 1,\n",
       "  'one-line header,': 1,\n",
       "  'utilized for': 1,\n",
       "  'Weiss, “Exploring': 1,\n",
       "  'Comparison Experiment': 1,\n",
       "  'redirection field': 1,\n",
       "  '1College of': 1,\n",
       "  'case of': 2,\n",
       "  'learning methods': 1,\n",
       "  'of web': 14,\n",
       "  'for classification.': 2,\n",
       "  'combined with': 3,\n",
       "  'Edited by': 1,\n",
       "  'Computer Science': 1,\n",
       "  'discover pattern': 1,\n",
       "  'text textexternal': 1,\n",
       "  'we face': 1,\n",
       "  '[8, 9].': 1,\n",
       "  'Step 1': 1,\n",
       "  'spam mainly': 1,\n",
       "  'the result.': 1,\n",
       "  'Additionally, in': 1,\n",
       "  'pornographic websites,': 1,\n",
       "  'L_outdegree_hp −0.0425': 1,\n",
       "  'result, 5797': 1,\n",
       "  'each other': 1,\n",
       "  'manual check': 2,\n",
       "  'semantic similarity.': 1,\n",
       "  '12 Security': 1,\n",
       "  'into classification': 1,\n",
       "  'the blocks': 1,\n",
       "  'as equation': 1,\n",
       "  'dataset using': 1,\n",
       "  'max pagerank': 3,\n",
       "  'Method In': 1,\n",
       "  'detection of': 1,\n",
       "  'internal links': 1,\n",
       "  'becoming more': 1,\n",
       "  'tree of': 1,\n",
       "  ...},\n",
       " 'trigramCount': {'of links ∗Diversity': 2,\n",
       "  'feature importance. (a)': 1,\n",
       "  'discuss the proposed': 1,\n",
       "  'as homepage, and': 1,\n",
       "  'structure and content': 1,\n",
       "  'ensure the full': 1,\n",
       "  'used in the': 1,\n",
       "  'LDA technique for': 1,\n",
       "  '2012. [25] Y.': 1,\n",
       "  'of themodels considered': 1,\n",
       "  'of spam is': 3,\n",
       "  'the homepage which': 1,\n",
       "  'use statsmodels [47]': 1,\n",
       "  'kind of word': 1,\n",
       "  'cross validation. 4.3.': 1,\n",
       "  'Dirichlet allocation (LDA)': 1,\n",
       "  '0.015 pagerank_hp −9.712e': 1,\n",
       "  'injected into. In': 1,\n",
       "  'Laza, J. R.': 1,\n",
       "  'times in the': 1,\n",
       "  '18 to line': 1,\n",
       "  'do not match': 1,\n",
       "  'of every external': 1,\n",
       "  'et al. [27]': 1,\n",
       "  'still uncertain as': 1,\n",
       "  'using machine learning': 2,\n",
       "  'can achieve better': 1,\n",
       "  'Austin, TX, USA,': 1,\n",
       "  'coefficients, standard error,': 1,\n",
       "  '= “FrontPage.Editor.Document”> 25': 1,\n",
       "  'spam. We introduce': 1,\n",
       "  '1, line 1': 1,\n",
       "  'the average importance': 1,\n",
       "  'ordinary users [10,': 1,\n",
       "  'that the web': 1,\n",
       "  'features for web': 2,\n",
       "  '“Web spam taxonomy,”': 1,\n",
       "  'Symposium on Computational': 1,\n",
       "  'proposed method framework,': 1,\n",
       "  'novel features which': 1,\n",
       "  'deep learning algorithms': 2,\n",
       "  'some punctuations and': 1,\n",
       "  'page in search': 1,\n",
       "  'a website. In': 1,\n",
       "  'results. http://webspam.lip6.fr/ wiki/pmwiki.php?n�Main.PhaseIIIResults': 1,\n",
       "  'are more convincing.': 1,\n",
       "  'one web page,': 1,\n",
       "  'of HTML tags.We': 1,\n",
       "  'describes the harvested': 1,\n",
       "  'of the most': 1,\n",
       "  'literature [5]; shortly': 1,\n",
       "  'out 106 precomputed': 1,\n",
       "  'textlink2, . .': 1,\n",
       "  'analyzed web spam': 1,\n",
       "  'is also the': 1,\n",
       "  'Chengdu, China 2College': 1,\n",
       "  '“Robust spammer detection': 1,\n",
       "  'pp. 514–525, Springer': 1,\n",
       "  'and detailed the': 1,\n",
       "  'that conducting the': 1,\n",
       "  'universal. Moreover, during': 1,\n",
       "  '1: Experimental environment': 1,\n",
       "  'same website. Similarly,': 1,\n",
       "  'links. So, there': 1,\n",
       "  '3 million pretrained': 1,\n",
       "  'number of <a>': 1,\n",
       "  'different perspective. 1': 1,\n",
       "  'Liu, X. Huang,': 1,\n",
       "  'dj, ∀j ∈': 1,\n",
       "  'showed that this': 1,\n",
       "  'tection. Fdez-Glez et': 1,\n",
       "  'the texthp and': 1,\n",
       "  'about the moon': 1,\n",
       "  'nodes −0.0123 0.002': 1,\n",
       "  'identifying web spam': 1,\n",
       "  'and textexternal set': 1,\n",
       "  'use the features': 1,\n",
       "  'of features. Next,': 1,\n",
       "  'IEEE Global Communications': 1,\n",
       "  'from the NLTK': 1,\n",
       "  'Li et al.': 1,\n",
       "  'domain that was': 1,\n",
       "  'Diversity of HTML': 2,\n",
       "  'of link and': 1,\n",
       "  'HST_20 2.3106 0.420': 1,\n",
       "  'consideration. First of': 1,\n",
       "  'G. Varoquaux, A.': 1,\n",
       "  'in the test': 1,\n",
       "  'word vectors. It': 1,\n",
       "  'content-based linguistic features': 1,\n",
       "  'links in the': 3,\n",
       "  'with the wisdom': 1,\n",
       "  'spam, Makkar et': 1,\n",
       "  'belongs and counted': 1,\n",
       "  'as extracting the': 1,\n",
       "  'the dataset is': 7,\n",
       "  'neural networks and': 1,\n",
       "  'latent Dirichlet allocation': 1,\n",
       "  'which are obtained': 1,\n",
       "  'validationTransformed link-based Feature': 1,\n",
       "  'In the case': 1,\n",
       "  '96 features, link-based': 1,\n",
       "  'more complete text': 1,\n",
       "  'to combat web': 1,\n",
       "  'attacks about web': 1,\n",
       "  'pp. 2825–2830, 2011.': 1,\n",
       "  'Code--></b> 35 </p>': 1,\n",
       "  'analyze the importance': 1,\n",
       "  'systematic framework to': 1,\n",
       "  'get all the': 1,\n",
       "  'by nearly 5%.': 1,\n",
       "  'technique for web': 1,\n",
       "  '4] indicating that': 1,\n",
       "  '(DPR), which evaluates': 1,\n",
       "  'final result. Furthermore,': 1,\n",
       "  'For example, the': 3,\n",
       "  'certain limitations, such': 1,\n",
       "  'and their results': 1,\n",
       "  'classification approaches to': 1,\n",
       "  'Wang, and W.': 1,\n",
       "  'on the dataset': 3,\n",
       "  '6%. One of': 1,\n",
       "  'companies, governments, and': 2,\n",
       "  '0.863 0.869 0.863': 1,\n",
       "  '5, pp. 55–64,': 1,\n",
       "  'on the dataset,': 1,\n",
       "  'brief definition of': 1,\n",
       "  'is for storing': 1,\n",
       "  'quality of the': 1,\n",
       "  'by using both': 1,\n",
       "  'social spam detection,”': 1,\n",
       "  '2017, https://arxiv.org/abs/ 1710.01387.': 1,\n",
       "  'the data labeled': 1,\n",
       "  'content-based web spam.': 1,\n",
       "  'curve of LR': 1,\n",
       "  'field the HTML': 1,\n",
       "  'locator (https://chato.cl/webspam/ datasets/uk2007/contents/excerpt.txt)': 1,\n",
       "  'Operating system Ubuntu': 1,\n",
       "  'L. Breiman et': 1,\n",
       "  '−1.043e + 05': 1,\n",
       "  'to transform the': 1,\n",
       "  'to another document': 2,\n",
       "  'http–equiv = “Content-Type”': 1,\n",
       "  'impressive to web': 1,\n",
       "  'the domain name.': 1,\n",
       "  'the characteristics of': 2,\n",
       "  'method can effectively': 1,\n",
       "  'number of hyperlinks': 1,\n",
       "  'mining novel features,': 1,\n",
       "  'performs well. 4.4.3.': 1,\n",
       "  'International Conference on': 5,\n",
       "  'Since models accept': 1,\n",
       "  'all web pages': 1,\n",
       "  'also used as': 1,\n",
       "  'on the number': 1,\n",
       "  'A. Belahcen, M.': 1,\n",
       "  '0.929 and a': 2,\n",
       "  '0.911 0.907 0.917': 1,\n",
       "  'L_pagerank_hp HST_20 (a)': 1,\n",
       "  'push all the': 2,\n",
       "  '0.891 0.899 0.891': 1,\n",
       "  'I. Bı́ró, K.': 1,\n",
       "  'is calculated. (2)': 1,\n",
       "  'percentage of homepage': 1,\n",
       "  'importance. (a) Mean': 1,\n",
       "  'one by one': 1,\n",
       "  'and divide them': 1,\n",
       "  'to represent the': 1,\n",
       "  'a classifier with': 1,\n",
       "  'and discard the': 1,\n",
       "  'H. Fu, X.': 1,\n",
       "  'bold), the remaining': 1,\n",
       "  'Procedia Computer Science,': 1,\n",
       "  'in any medium,': 1,\n",
       "  'intent analysis,” in': 1,\n",
       "  'image tags in': 1,\n",
       "  '0.000 L_pagerank_hp 0.0472': 1,\n",
       "  'line 43) are': 1,\n",
       "  'purpose, Bı́ró et': 1,\n",
       "  'explored linguistic features': 1,\n",
       "  'W. I. Sofiah': 1,\n",
       "  '6189 Security and': 1,\n",
       "  'travel to short': 1,\n",
       "  'of certain types': 1,\n",
       "  'of tags but': 1,\n",
       "  '2. Features 3.': 1,\n",
       "  '(15) WMDtext �': 1,\n",
       "  'meaningfulness of using': 1,\n",
       "  'structure, and semantic': 1,\n",
       "  'level compared with': 1,\n",
       "  'the entry link,': 1,\n",
       "  'machine learning algorithm': 1,\n",
       "  'CNN has an': 1,\n",
       "  'while personal blogs': 1,\n",
       "  'the World Wide': 1,\n",
       "  '[35] Beautiful soup': 1,\n",
       "  'means that the': 4,\n",
       "  'texthp:� ExtractText (hp)': 1,\n",
       "  'cluster centers,” in': 1,\n",
       "  'spam filtering,” in': 1,\n",
       "  '© 2020 Jiayong': 1,\n",
       "  '\\U0010ff50 n j�1': 3,\n",
       "  'class is nearly': 1,\n",
       "  'technology to publish': 1,\n",
       "  'a certain extent': 1,\n",
       "  'homepage is still': 1,\n",
       "  'use a pretrained': 1,\n",
       "  'can effectively detect': 1,\n",
       "  'by multiple scholars.': 1,\n",
       "  'Selected existing features': 2,\n",
       "  'comparison on the': 1,\n",
       "  '= “Microso\\x02 FrontPage': 1,\n",
       "  'novel features extracted': 1,\n",
       "  'applications are becoming': 1,\n",
       "  'evaluate the performance': 3,\n",
       "  '(1) we first': 1,\n",
       "  'is often categorized': 1,\n",
       "  'of cross validation.': 1,\n",
       "  'Security and Privacy': 1,\n",
       "  'no. 5, pp.': 1,\n",
       "  'Bing search engine': 1,\n",
       "  'on discriminative content': 1,\n",
       "  'combines feature extraction': 1,\n",
       "  'method has generalization': 1,\n",
       "  'a certain error': 1,\n",
       "  'The website presented': 1,\n",
       "  'different. Based on': 1,\n",
       "  '0.06 0.08 0.10': 1,\n",
       "  'calculates the minimum': 1,\n",
       "  'the different classifiers': 1,\n",
       "  'using information hiding': 1,\n",
       "  'IP has been': 1,\n",
       "  '6 Security and': 1,\n",
       "  'analyze the complexity': 1,\n",
       "  '37 <b><font size': 1,\n",
       "  '2018. [27] A.': 1,\n",
       "  'metrics for binary': 1,\n",
       "  'as spam which': 1,\n",
       "  'features (6) Cross': 1,\n",
       "  'are followed. We': 1,\n",
       "  '<b><font size =': 1,\n",
       "  'engine worldwide, Google': 1,\n",
       "  '+ 05 0.817': 1,\n",
       "  'not highlight its': 1,\n",
       "  '</p> 36 <p': 1,\n",
       "  'J. Pedersen, “Combating': 1,\n",
       "  'spam page through': 1,\n",
       "  '(ICAI), July 2012.': 1,\n",
       "  'specific keyword, these': 1,\n",
       "  'in Table 2,': 1,\n",
       "  'first page of': 1,\n",
       "  'is only the': 1,\n",
       "  'How far down': 1,\n",
       "  'all spam samples': 1,\n",
       "  'As can be': 1,\n",
       "  'Cybersecurity, Sichuan University,': 1,\n",
       "  'vectors. It contains': 1,\n",
       "  'by logit regression': 1,\n",
       "  'both efficiency and': 1,\n",
       "  'browse a different': 1,\n",
       "  'ex- periments. Secondly,': 1,\n",
       "  'precision of 0.929': 1,\n",
       "  'sample, and false': 1,\n",
       "  'analysis between the': 1,\n",
       "  'C. Yuan, and': 1,\n",
       "  'it extracts the': 1,\n",
       "  'the performance of': 10,\n",
       "  'content that a': 1,\n",
       "  'impact of these': 1,\n",
       "  'Electrical Engineering and': 1,\n",
       "  'the random forest': 1,\n",
       "  '2012. [46] S.': 1,\n",
       "  'highlight its advantages.': 1,\n",
       "  'reporting the logistic': 1,\n",
       "  'are several advantages': 1,\n",
       "  'platform often has': 1,\n",
       "  'websites. It can': 1,\n",
       "  'features and put': 1,\n",
       "  'If all features': 1,\n",
       "  'three features of': 1,\n",
       "  'the main content': 2,\n",
       "  'extracted more labeled': 1,\n",
       "  'hypothesis testing to': 1,\n",
       "  'studied the spectrum': 1,\n",
       "  'are 21 features': 1,\n",
       "  'al. [6] present': 1,\n",
       "  'if (linkexternal is': 1,\n",
       "  'of 7 models': 1,\n",
       "  'the vector space.': 2,\n",
       "  '</head> 27 <body>': 1,\n",
       "  'the existing methods.': 1,\n",
       "  'is the result': 2,\n",
       "  'J. Piskorski, M.': 1,\n",
       "  'not null) then': 2,\n",
       "  'of the 2017': 1,\n",
       "  'Technology Program under': 1,\n",
       "  '(SVM) algorithm by': 1,\n",
       "  'that was conducted': 1,\n",
       "  'where a higher': 1,\n",
       "  'of the 23rd': 1,\n",
       "  '(http://law.di.unimi.it/)s University of': 1,\n",
       "  'such scenarios, machine': 1,\n",
       "  'labeled data from': 1,\n",
       "  'we have studied': 1,\n",
       "  'pages are called': 1,\n",
       "  'and A. Juneja,': 1,\n",
       "  'that all pages': 1,\n",
       "  'on Telecommunications, Tehran,': 1,\n",
       "  'word vector after': 1,\n",
       "  'times. We acknowledge': 1,\n",
       "  'make the experimental': 1,\n",
       "  'is null) then': 1,\n",
       "  'through searching. Fierce': 1,\n",
       "  'Since this paper': 2,\n",
       "  'boundary between spam': 1,\n",
       "  'also compare the': 1,\n",
       "  'convolutional neural networks': 1,\n",
       "  'Result. In this': 1,\n",
       "  'features in total,': 1,\n",
       "  'link to some': 1,\n",
       "  'X. Xie, Y.': 1,\n",
       "  'websites are invalid': 1,\n",
       "  'web pages, especially': 1,\n",
       "  'are methods based': 1,\n",
       "  'spam, researchers mainly': 1,\n",
       "  'distance. 6 Security': 1,\n",
       "  'method uses fewer': 1,\n",
       "  'three [44] in': 1,\n",
       "  'countermeasures,” International Journal': 1,\n",
       "  'all about the': 1,\n",
       "  'Related Work Web': 1,\n",
       "  'propose two link': 1,\n",
       "  'the link-based features.': 1,\n",
       "  'that target browser,': 1,\n",
       "  'Previous methods also': 1,\n",
       "  'composed of 3': 1,\n",
       "  'as spam. Recall,': 1,\n",
       "  'the authors thought': 1,\n",
       "  'are discussed, and': 1,\n",
       "  'links, but we': 1,\n",
       "  'Article ID 6091385,': 1,\n",
       "  'evaluate the prediction': 1,\n",
       "  'steps: short text': 1,\n",
       "  'the one-line header': 1,\n",
       "  'the feature selection': 1,\n",
       "  'derive from multiple': 1,\n",
       "  'of our data.': 1,\n",
       "  'detection framework using': 1,\n",
       "  'detect organic visitors.': 1,\n",
       "  'a black-hat search': 1,\n",
       "  'has the largest': 1,\n",
       "  'dependent on data,': 1,\n",
       "  'It includes each': 1,\n",
       "  'SVM, RF, convolutional': 1,\n",
       "  'would verify that': 1,\n",
       "  'content = “Microso\\x02': 1,\n",
       "  'classifier with the': 1,\n",
       "  \"(2) 'is paper\": 1,\n",
       "  \"context information. 'e\": 1,\n",
       "  'spam classification method': 1,\n",
       "  'pornographic websites, to': 1,\n",
       "  'for storing the': 1,\n",
       "  'n ∈ N': 2,\n",
       "  'later, experiment results': 1,\n",
       "  'University of California,': 1,\n",
       "  '1.369 0.472 Novel': 1,\n",
       "  'LR is closely': 1,\n",
       "  'a galaxy A': 1,\n",
       "  'predictions of the': 2,\n",
       "  'April 2009. [16]': 1,\n",
       "  'of their tags.': 1,\n",
       "  'by the top': 2,\n",
       "  'As in Table': 1,\n",
       "  'parse the HTML': 1,\n",
       "  'os iti ve': 1,\n",
       "  'HTML documents (from': 1,\n",
       "  'model (AUC� 0.957)': 1,\n",
       "  'the validity of': 1,\n",
       "  'the homepage’s title,': 1,\n",
       "  'detector algorithm and': 1,\n",
       "  'regression model results': 1,\n",
       "  'of a DOM': 1,\n",
       "  'the p value': 1,\n",
       "  'Foozy, N. Alias,': 1,\n",
       "  'structures for web': 1,\n",
       "  'analysis and using': 1,\n",
       "  'stages. For example,': 1,\n",
       "  'differences between spam': 1,\n",
       "  'total, which categorize': 1,\n",
       "  '1.766 0.000 L_truncatedpagerank_3_hp': 1,\n",
       "  'representative methods as': 1,\n",
       "  'each model on': 1,\n",
       "  'subjective issue to': 1,\n",
       "  'sparse matrix where': 1,\n",
       "  '+ 04 4.2e': 1,\n",
       "  'pseudocode of this': 1,\n",
       "  'welldesigned template, unlike': 1,\n",
       "  'easy to interpret': 1,\n",
       "  'textdescription\\U0010ff6e \\U0010ff6f, linkexternal': 1,\n",
       "  'display related information': 1,\n",
       "  'the future, mining': 1,\n",
       "  'dataset to detect': 1,\n",
       "  'the recent years,': 1,\n",
       "  'When users search': 1,\n",
       "  'discover that many': 1,\n",
       "  'html tags L_pagerank_hp': 2,\n",
       "  'some benchmark traditional': 1,\n",
       "  'Google processes over': 1,\n",
       "  'Smart-BT, proposed by': 1,\n",
       "  'transductive-inductive model that': 1,\n",
       "  'Commons Attribution License,': 1,\n",
       "  'on the same': 1,\n",
       "  'new framework according': 1,\n",
       "  'the all 6479': 1,\n",
       "  'Communication Networks 9': 1,\n",
       "  '= “en-us”> 21': 1,\n",
       "  'page from the': 1,\n",
       "  'shows that the': 1,\n",
       "  'with the domain': 1,\n",
       "  'returned to search': 1,\n",
       "  'J. Zhang, J.': 1,\n",
       "  'type of tags': 1,\n",
       "  'no. 1, 2012.': 1,\n",
       "  'high accuracy of': 1,\n",
       "  \"follows. (1) 'is\": 1,\n",
       "  'appear times in': 1,\n",
       "  'sequence content, such': 1,\n",
       "  '“Scikit-learn: machine learning': 1,\n",
       "  'can be seen': 2,\n",
       "  'object model (DOM)': 1,\n",
       "  \"'e WARC format\": 1,\n",
       "  'and statistical modeling': 1,\n",
       "  'International Publishing, Cham,': 1,\n",
       "  '06 0.968 L_outdegree_hp': 1,\n",
       "  'spammer detection in': 1,\n",
       "  '0.875 0.872 0.875': 1,\n",
       "  '261–270, 2018. [26]': 1,\n",
       "  'of word representations': 1,\n",
       "  \"is spam. 'e\": 1,\n",
       "  'has traditionally been': 1,\n",
       "  'in all spam': 1,\n",
       "  '1.16.2 Table 2:': 1,\n",
       "  'in the vector': 2,\n",
       "  'is presented. A': 1,\n",
       "  'tags: different types': 1,\n",
       "  'to the same': 1,\n",
       "  'accurate enough. In': 1,\n",
       "  'spam from the': 1,\n",
       "  'another text. As': 1,\n",
       "  'method in Section': 1,\n",
       "  \"improved. 'erefore, we\": 1,\n",
       "  'domain (2) dhp:': 1,\n",
       "  'Collectlinks(): this function': 1,\n",
       "  'Eds., “Amood analysis': 1,\n",
       "  'links: in contrast': 1,\n",
       "  'Random forest Web': 1,\n",
       "  'web Security and': 1,\n",
       "  'Liu,1 Yu Su,1': 1,\n",
       "  'linkexternal:� Collectlinks (hp)': 1,\n",
       "  'N. Alias, P.': 1,\n",
       "  'which are described': 1,\n",
       "  'both the explicit': 1,\n",
       "  \"Figure 3: 'e\": 1,\n",
       "  '2015. [28] H.': 1,\n",
       "  'the results using': 1,\n",
       "  'multiple kernels in': 1,\n",
       "  'concluded that these': 1,\n",
       "  'Information Assurance &': 1,\n",
       "  'apparent differences between': 1,\n",
       "  'turn, which is': 1,\n",
       "  'optimization (SEO) that': 1,\n",
       "  '(area = 0.875)': 1,\n",
       "  'redirect to other': 1,\n",
       "  'document, we propose': 1,\n",
       "  'identify web spam': 1,\n",
       "  'data, and different': 1,\n",
       "  'and UK-2011 dataset': 1,\n",
       "  'kernels in twin': 2,\n",
       "  'detection using recurrent': 1,\n",
       "  'and links, but': 1,\n",
       "  'for computing the': 1,\n",
       "  \"effective. (2) 'is\": 1,\n",
       "  'value, the more': 1,\n",
       "  '2005. [6] A.': 1,\n",
       "  'text of the': 3,\n",
       "  'have conducted much': 1,\n",
       "  'Sichuan Science and': 1,\n",
       "  'reproduced three representative': 1,\n",
       "  'will also have': 1,\n",
       "  '“Document sentiment modeling': 1,\n",
       "  'the folder name': 1,\n",
       "  'the three features': 1,\n",
       "  'Dean, “Efficient estimation': 1,\n",
       "  'services, personal blog': 1,\n",
       "  'at least one': 1,\n",
       "  'original web pages’': 1,\n",
       "  'Word2Vec is a': 1,\n",
       "  'means other hyperparameters': 1,\n",
       "  'linkexternal and textexternal': 1,\n",
       "  'et al. [6]': 1,\n",
       "  'longer sequence data,': 1,\n",
       "  'and Soleimani [23]': 3,\n",
       "  'to external links,': 1,\n",
       "  '[40], which combines': 1,\n",
       "  'Experiment results show': 1,\n",
       "  'is a subjective': 1,\n",
       "  'will most people': 1,\n",
       "  'HTML tags and': 1,\n",
       "  'and detection model.': 1,\n",
       "  'in some link': 1,\n",
       "  'some benchmark deep': 1,\n",
       "  'In the future,': 1,\n",
       "  '“Using machine learning': 1,\n",
       "  'it through the': 1,\n",
       "  'are independent during': 1,\n",
       "  'less than 0.05,': 1,\n",
       "  'E. Ezpeleta, M.': 1,\n",
       "  'TP + TN': 2,\n",
       "  'resources and cause': 1,\n",
       "  'Page Source Code': 1,\n",
       "  '“Youtube spam detection': 1,\n",
       "  'there are no': 1,\n",
       "  '20 0 Spam': 1,\n",
       "  'for the comparisons': 1,\n",
       "  'and calculate the': 1,\n",
       "  'experiments dataset. Category': 1,\n",
       "  'vector of another': 1,\n",
       "  'pp. 1–31, 2017.': 1,\n",
       "  '0.004 Similarity of': 1,\n",
       "  '2College of Computer': 1,\n",
       "  'we propose a': 1,\n",
       "  'in vector space,”': 1,\n",
       "  'However, none of': 1,\n",
       "  'not easy in': 1,\n",
       "  '9th Python in': 1,\n",
       "  'Section 3 and': 1,\n",
       "  'M. Zhang, S.': 1,\n",
       "  'short text semantic': 1,\n",
       "  'the amount of': 1,\n",
       "  'spamming in the': 1,\n",
       "  'T≥0 \\U0010ff58 n': 1,\n",
       "  'is properly cited.': 1,\n",
       "  'score greater than': 1,\n",
       "  'which means any': 1,\n",
       "  \"Section 4.2. 'e\": 1,\n",
       "  'dataset in all': 1,\n",
       "  'comprehensive evaluation metrics': 1,\n",
       "  'domain of all': 1,\n",
       "  'Journal of Advanced': 1,\n",
       "  'F. Othman, and': 1,\n",
       "  'networks for content-based': 1,\n",
       "  'Besides, the model': 1,\n",
       "  'detection via commercial': 1,\n",
       "  'the clickthrough rate': 1,\n",
       "  'dataset and recursive': 1,\n",
       "  'analyzed the three': 1,\n",
       "  'only the root': 1,\n",
       "  'two main problems': 1,\n",
       "  'n j�1 Tij': 3,\n",
       "  'suitable for the': 1,\n",
       "  'path roughly.We set': 1,\n",
       "  'Intelligent Systems, E.': 1,\n",
       "  'to a word': 1,\n",
       "  'binary classification problems.': 1,\n",
       "  \"calculation. 'us, WMD\": 1,\n",
       "  'of content. We': 1,\n",
       "  'are easily used': 1,\n",
       "  'methods; for example,': 1,\n",
       "  'L_outdegree_hp Outdegree_hp Pagerank_hp': 2,\n",
       "  'malicious websites such': 1,\n",
       "  \"Short Text Cleaning.'e\": 1,\n",
       "  'necessary to extract': 1,\n",
       "  'numerical forms or': 1,\n",
       "  'PCA and RFE': 1,\n",
       "  '277 precomputed features': 1,\n",
       "  'about data augmentation': 1,\n",
       "  'Systems, and Applications,': 1,\n",
       "  'et al. [16]': 1,\n",
       "  'Validity of the': 1,\n",
       "  'meta tag and': 1,\n",
       "  'corre- sponding weights': 1,\n",
       "  'name is the': 1,\n",
       "  'gradient disappearance; it': 1,\n",
       "  \"'ere are two\": 1,\n",
       "  'to detect spam,': 2,\n",
       "  'million pretrained English': 1,\n",
       "  'and the Figure': 1,\n",
       "  'building and classification': 1,\n",
       "  'research, and its': 1,\n",
       "  'to select fewer': 1,\n",
       "  'https://doi.org/10.1155/2020/6662166 accuracy of': 1,\n",
       "  'and W. I.': 1,\n",
       "  'Comparison of Detection': 1,\n",
       "  'patterns of spam': 1,\n",
       "  'and choosing the': 1,\n",
       "  'measurement of the': 1,\n",
       "  'curve of SVM': 1,\n",
       "  'web spam. We': 1,\n",
       "  'spam method. 4': 1,\n",
       "  'WMDlink � WMD': 1,\n",
       "  'WMDtext � 0': 1,\n",
       "  'a systematic framework': 1,\n",
       "  'Electronics and Mobile': 1,\n",
       "  'on the utility': 1,\n",
       "  'link characteristics because': 1,\n",
       "  'curves are ‘paired’': 1,\n",
       "  'these machine learning': 1,\n",
       "  '5 illustrates the': 1,\n",
       "  'through only the': 1,\n",
       "  'in equation (9).': 1,\n",
       "  'Algorithm. Judging whether': 1,\n",
       "  'have extracted the': 1,\n",
       "  'M. Bianchini, and': 1,\n",
       "  '[48] X. Robin,': 1,\n",
       "  'clear boundaries. It': 1,\n",
       "  'have compared some': 1,\n",
       "  'performed well. Also,': 1,\n",
       "  'we take cross': 1,\n",
       "  'often has a': 1,\n",
       "  'high ranking. Users': 1,\n",
       "  'dynamic scripts in': 1,\n",
       "  'or embedded in': 1,\n",
       "  '[23] to reduce': 1,\n",
       "  'applied to detect': 1,\n",
       "  'Random forest feature': 1,\n",
       "  'primary method is': 1,\n",
       "  'to interpret and': 1,\n",
       "  'texts and links.': 1,\n",
       "  'speaking, web spamming': 1,\n",
       "  'meta tags (ii)': 1,\n",
       "  'score is the': 1,\n",
       "  'author used the': 1,\n",
       "  'on web page': 2,\n",
       "  'on.We compared the': 1,\n",
       "  'proposed by the': 1,\n",
       "  'represent words as': 1,\n",
       "  'the graph neural': 1,\n",
       "  'Fdez-Glez et al.': 1,\n",
       "  'demonstrates that the': 1,\n",
       "  '<html> 19 <head>': 1,\n",
       "  'and counted the': 1,\n",
       "  'includes each feature’s': 1,\n",
       "  'chosen classifier RF': 1,\n",
       "  'the redirection field': 1,\n",
       "  'eliminating a set': 1,\n",
       "  'classification, RF solves': 1,\n",
       "  '2019. [19] S.': 1,\n",
       "  'E. Corchado, Ed.,': 1,\n",
       "  '0.911 0.909 0.911': 1,\n",
       "  'classification algorithm training': 1,\n",
       "  'web pages use': 1,\n",
       "  'the Web Spam': 1,\n",
       "  'types of websites': 1,\n",
       "  'and content are': 1,\n",
       "  '[23] to accomplish': 1,\n",
       "  'knuth–morris–pratt algorithm to': 1,\n",
       "  'values indicate the': 1,\n",
       "  'iii results. http://webspam.lip6.fr/': 1,\n",
       "  '0.000 L_truncatedpagerank_2_hp −8.9288': 1,\n",
       "  'and N. Kumar,': 1,\n",
       "  'of a homepage': 1,\n",
       "  'method has features': 1,\n",
       "  'curve of 7': 1,\n",
       "  'of features, rather': 1,\n",
       "  'some companies, governments,': 1,\n",
       "  '[29] N.’A. Maulat': 1,\n",
       "  'Some web pages': 1,\n",
       "  'a result, 5797': 1,\n",
       "  'widely used indicator': 1,\n",
       "  'increase the clickthrough': 1,\n",
       "  'links that, from': 1,\n",
       "  'process. In this': 1,\n",
       "  'It helps us': 1,\n",
       "  '“center”> 37 <b><font': 1,\n",
       "  'and false positive': 1,\n",
       "  'dataset from the': 1,\n",
       "  'returns different content': 1,\n",
       "  'of our dataset': 1,\n",
       "  'analyze a certain': 1,\n",
       "  'Python in Science': 1,\n",
       "  'studies of content-based': 1,\n",
       "  'are not based': 1,\n",
       "  'on the consideration': 1,\n",
       "  'from the homepage': 2,\n",
       "  'theWMD distance to': 1,\n",
       "  'that the novel': 3,\n",
       "  'websites. Security and': 1,\n",
       "  'features of the': 1,\n",
       "  'and qualified-link analysis': 1,\n",
       "  'structural characteristics in': 1,\n",
       "  'comments and a': 1,\n",
       "  'results of all': 1,\n",
       "  'Soup Python library': 1,\n",
       "  'if (24) end': 1,\n",
       "  'element-type nodes, HTML': 1,\n",
       "  'easily accessible. ∗Number': 1,\n",
       "  'and LSTM performance': 1,\n",
       "  'minimum distance that': 1,\n",
       "  'spam which is': 1,\n",
       "  'content. We conduct': 1,\n",
       "  'a feature selection': 2,\n",
       "  'that some websites': 1,\n",
       "  'Considering the dataset': 1,\n",
       "  'provided the original': 1,\n",
       "  'comments spam. To': 1,\n",
       "  'text’s semantic similarity': 1,\n",
       "  'word j, as': 1,\n",
       "  'FN , (9)': 1,\n",
       "  'dataset is inadequate,': 1,\n",
       "  \"Text Cleaning.'e HTML\": 1,\n",
       "  'the previous studies': 1,\n",
       "  'harvested content and': 1,\n",
       "  '3 BUbiNG–content–digest: f05592c825fa9619306efcccd187391e': 1,\n",
       "  'L_truncatedpagerank_3_hp 3.5543 2.380': 1,\n",
       "  'extracts the domain': 1,\n",
       "  'valid than the': 1,\n",
       "  \"Acknowledgments 'is work\": 1,\n",
       "  'Web spam challenge': 1,\n",
       "  'and denoising autoencoder': 1,\n",
       "  'mover’s distance (WMD)': 1,\n",
       "  'parser Homepage check': 1,\n",
       "  'in mathematical space.': 1,\n",
       "  'engines and ordinary': 1,\n",
       "  'of methods to': 1,\n",
       "  'memory Security and': 1,\n",
       "  'active. 4.2. Experimental': 1,\n",
       "  'de Mendizabal, U.': 1,\n",
       "  '[22] H. Jelodar,': 1,\n",
       "  'score because of': 1,\n",
       "  'to the weight': 2,\n",
       "  ', n{ }.': 1,\n",
       "  '“b5571d773461c61: b506b” 15': 1,\n",
       "  'WARC Parser. First': 1,\n",
       "  'Many researchers and': 1,\n",
       "  'accept–ranges: bytes 10': 1,\n",
       "  \"space. 'e vector\": 1,\n",
       "  'separate web spam': 1,\n",
       "  'Zurutuza, and António': 1,\n",
       "  'efficiency and Hindawi': 1,\n",
       "  'each domain of': 1,\n",
       "  'used to support': 1,\n",
       "  \"'e vector mapped\": 1,\n",
       "  'in the linking': 1,\n",
       "  'anchor texts link': 1,\n",
       "  'China, June 2018.': 1,\n",
       "  'Experimental Design. We': 1,\n",
       "  'the default value': 1,\n",
       "  'by Robin et': 1,\n",
       "  'RF model yields': 1,\n",
       "  'and word j,': 1,\n",
       "  'open access article': 1,\n",
       "  'File Format that': 1,\n",
       "  'on random forest': 1,\n",
       "  'this issue, we': 1,\n",
       "  'is a reason': 1,\n",
       "  'does not pay': 1,\n",
       "  'by DOM. Structural': 1,\n",
       "  '0.909 0.937 Novel': 1,\n",
       "  'Web Spam Based': 1,\n",
       "  'other models could': 1,\n",
       "  'in Section 4.3.': 1,\n",
       "  '21 <meta http–equiv': 1,\n",
       "  '06 0.980 truncatedpagerank_4_hp': 1,\n",
       "  \"et al. 'is\": 1,\n",
       "  'and the Fundamental': 1,\n",
       "  '∗/ (7) linkexternal:�': 1,\n",
       "  'classifier in this': 1,\n",
       "  'July 2015. [34]': 1,\n",
       "  'are ‘paired’ if': 1,\n",
       "  'documentation. https://www.crummy.com/ software/BeautifulSoup/bs4/doc': 1,\n",
       "  'pp. 291–296, IEEE,': 1,\n",
       "  'DOM tree of': 1,\n",
       "  'research the web': 1,\n",
       "  'the domain of': 3,\n",
       "  'multiple lines of': 1,\n",
       "  'far less than': 1,\n",
       "  'and a modified': 1,\n",
       "  '(1) Step 2': 1,\n",
       "  'a supervised learning': 1,\n",
       "  'the RF model': 5,\n",
       "  'HTML documents one': 1,\n",
       "  'represent the similarity,': 1,\n",
       "  'search engines and': 3,\n",
       "  'in detail. 3.1.': 1,\n",
       "  'affect the result.': 1,\n",
       "  'path is only': 1,\n",
       "  '(RF) as the': 1,\n",
       "  'to counter spam': 1,\n",
       "  'about to follow': 1,\n",
       "  'Communication Networks 5': 1,\n",
       "  'of web applications.': 1,\n",
       "  'of Asdaghi et': 1,\n",
       "  'else if (linkexternal': 1,\n",
       "  'or not. We': 1,\n",
       "  'some pages that': 1,\n",
       "  'to improve rankings': 1,\n",
       "  'differentiation page-based K-means': 1,\n",
       "  'not deliberately increase': 1,\n",
       "  'of each domain': 2,\n",
       "  'obtained by mathematically': 1,\n",
       "  'by subtracting the': 1,\n",
       "  'use these features': 1,\n",
       "  'defined in the': 1,\n",
       "  '= “Content-Type” content': 1,\n",
       "  'average of precision': 1,\n",
       "  'users who are': 1,\n",
       "  'of 105,896,555 pages': 1,\n",
       "  'from that in': 1,\n",
       "  'Security and Communication': 14,\n",
       "  'feature selection method': 3,\n",
       "  'input into the': 1,\n",
       "  'homepage text, linkexternal': 1,\n",
       "  'in theWeb Spam': 1,\n",
       "  'as a nonspam': 1,\n",
       "  'that the proposed': 1,\n",
       "  'belief networks and': 1,\n",
       "  '\\U0010ff09, n ∈': 1,\n",
       "  'the homepage. Of': 1,\n",
       "  'into. In this': 1,\n",
       "  'We only consider': 1,\n",
       "  'find that some': 1,\n",
       "  'Chen, “Robust spammer': 1,\n",
       "  'they generated a': 1,\n",
       "  'ue p os': 1,\n",
       "  'to blur. Also,': 1,\n",
       "  'depicts, we have': 1,\n",
       "  'novel framework for': 1,\n",
       "  \"'ese web pages\": 1,\n",
       "  'experiment results are': 1,\n",
       "  'Applications, vol. 96,': 1,\n",
       "  'Corrado, and J.': 1,\n",
       "  '−8.9288 1.766 0.000': 1,\n",
       "  'there are methods': 1,\n",
       "  \"'e main contributions\": 1,\n",
       "  'that we explained': 1,\n",
       "  'not be very': 1,\n",
       "  '+ FN .': 1,\n",
       "  'of HTML tags:': 2,\n",
       "  'backward elimination approach,': 1,\n",
       "  'of the 5th': 1,\n",
       "  'features related to': 2,\n",
       "  'effects of novel': 1,\n",
       "  'by, a plurality': 1,\n",
       "  \"detection model. 'e\": 2,\n",
       "  'the similarity, which': 1,\n",
       "  '(WARC) format proposed': 1,\n",
       "  'depicted in Figure': 1,\n",
       "  'classifier to distinguish': 1,\n",
       "  'Search engine is': 1,\n",
       "  'which is higher': 1,\n",
       "  '1.35e + 06': 1,\n",
       "  'configuration is shown': 1,\n",
       "  'to characters with': 1,\n",
       "  'papers, in this': 1,\n",
       "  'closely followed, and': 1,\n",
       "  '6 x–powered–by: ASP.NET': 1,\n",
       "  'logit regression analysis.': 1,\n",
       "  'the web pages': 4,\n",
       "  'features, both efficiency': 1,\n",
       "  'Google search statistics.': 1,\n",
       "  'forest Web spam': 1,\n",
       "  'a large-scale empirical': 1,\n",
       "  '0.902). Also, the': 1,\n",
       "  'ci \\U0010ff50 n': 1,\n",
       "  'al. [20] proposed': 1,\n",
       "  'methods; some difficult': 1,\n",
       "  'results show that': 2,\n",
       "  'Y. Mei, J.': 1,\n",
       "  'largest PageRank value': 1,\n",
       "  'and UK-2007 datasets.': 1,\n",
       "  '(3) We evaluate': 1,\n",
       "  'ordinary ones. Luca': 1,\n",
       "  'website, they intentionally': 1,\n",
       "  'of popular machine': 1,\n",
       "  'and related attacks': 1,\n",
       "  '� WMD (texthp,': 1,\n",
       "  'external links and': 2,\n",
       "  'storing the anchor': 1,\n",
       "  '2.35e + 06': 1,\n",
       "  'as spam based': 1,\n",
       "  'IEEE, New Delhi,': 1,\n",
       "  'to improve support': 1,\n",
       "  'are affected by': 1,\n",
       "  'apply to the': 1,\n",
       "  \"less biased. 'us,\": 1,\n",
       "  'on the Web,': 6,\n",
       "  'FPR (equations (9)': 1,\n",
       "  'websites. “Invalid” means': 1,\n",
       "  'of the different': 1,\n",
       "  '6: Logit regression': 1,\n",
       "  'features. Since this': 1,\n",
       "  'between spam and': 2,\n",
       "  'significance to detect': 1,\n",
       "  '0.10 0.15 Truncatedpagerank_2_hp': 1,\n",
       "  'assigning PageRank values.': 1,\n",
       "  'homepage text and': 1,\n",
       "  'the estimation of': 1,\n",
       "  'between hp’s domain': 1,\n",
       "  'environment Configuration. Designation': 1,\n",
       "  'E. Chen, “Robust': 1,\n",
       "  'be web spam.': 1,\n",
       "  'of this algorithm': 1,\n",
       "  'for performance of': 1,\n",
       "  'of using the': 1,\n",
       "  'be the direction': 1,\n",
       "  'web pages as': 1,\n",
       "  'wisdom of the': 1,\n",
       "  'without considering the': 2,\n",
       "  'each website is': 1,\n",
       "  'spam, Ezpeleta et': 1,\n",
       "  'Nonspam 5476 1768': 1,\n",
       "  'with similar regularities,': 1,\n",
       "  '\\U0010ff58 n j�1': 1,\n",
       "  '(3) shows, and': 1,\n",
       "  'It is also': 1,\n",
       "  'personal blog websites,': 1,\n",
       "  'to some extent,': 1,\n",
       "  'spam web page': 1,\n",
       "  'article, document I': 1,\n",
       "  'spam or not.': 2,\n",
       "  'can be solved': 1,\n",
       "  'link-based Feature extraction': 1,\n",
       "  'with novel feature': 1,\n",
       "  'Bursztein, “Cloak of': 1,\n",
       "  'Hence, it is': 1,\n",
       "  'al., “Scikit-learn: machine': 1,\n",
       "  'Jakub Piskorski et': 1,\n",
       "  'some regression results': 1,\n",
       "  'Furthermore, there are': 1,\n",
       "  'rate (FPR) is': 1,\n",
       "  'and E. Chen,': 1,\n",
       "  '0.980 truncatedpagerank_4_hp −1.084e': 1,\n",
       "  'homepages extraction and': 1,\n",
       "  'presented in this': 1,\n",
       "  '<head> 20 <meta': 1,\n",
       "  'where user visiting': 1,\n",
       "  'whereas the production': 1,\n",
       "  'documents in each': 1,\n",
       "  'HTML document is': 1,\n",
       "  'namely, similarity of': 1,\n",
       "  'the advance of': 1,\n",
       "  'more than one': 2,\n",
       "  'file. We can': 1,\n",
       "  'C. Chen, A.': 1,\n",
       "  'and efficiency of': 1,\n",
       "  \"'is is an\": 1,\n",
       "  'the data without': 1,\n",
       "  'different techniques, particularly': 1,\n",
       "  'Number of external': 2,\n",
       "  'is the web': 1,\n",
       "  '(NB) classifier. Many': 1,\n",
       "  'et al. [24]': 1,\n",
       "  'novel features into': 1,\n",
       "  'deep belief networks,”': 1,\n",
       "  'most common web': 1,\n",
       "  'tags.We not only': 1,\n",
       "  'both users and': 1,\n",
       "  'long Security and': 1,\n",
       "  'of Detection Rate.': 1,\n",
       "  'results given by': 1,\n",
       "  'on the web': 1,\n",
       "  'Bı́ró, K. .': 1,\n",
       "  'Abu Doush, M.': 1,\n",
       "  \"'e next step\": 1,\n",
       "  'linkn\\U0010ff08 \\U0010ff09, n': 1,\n",
       "  'an HTML document': 1,\n",
       "  'external links of': 1,\n",
       "  'website is spam.': 1,\n",
       "  'link and anchor': 1,\n",
       "  'Novel features 0.911': 1,\n",
       "  'evade detection. Also,': 1,\n",
       "  'galaxy A blog': 1,\n",
       "  'analysis techniques. Based': 1,\n",
       "  'features. Reza Mohammadi': 1,\n",
       "  'spam pages nowadays.': 1,\n",
       "  'domain which means': 1,\n",
       "  '24 is the': 1,\n",
       "  'spam classification,” Procedia': 1,\n",
       "  'comparison of supervised': 1,\n",
       "  'in 114,529 hosts': 1,\n",
       "  'the precomputed existing': 2,\n",
       "  'special case of': 1,\n",
       "  'de- tection. Fdez-Glez': 1,\n",
       "  'slightly worse. NB': 1,\n",
       "  'because other than': 1,\n",
       "  'plurality of popular': 1,\n",
       "  'judged whether a': 1,\n",
       "  'Neural Networks: Computational': 1,\n",
       "  'recursive feature elimination': 1,\n",
       "  'test set, whereas': 1,\n",
       "  'state-of-art methods, paper': 1,\n",
       "  'learning techniques are': 1,\n",
       "  'biased, we take': 1,\n",
       "  'of cross links:': 1,\n",
       "  'web pages are': 1,\n",
       "  'As one of': 1,\n",
       "  '90% of Internet': 1,\n",
       "  'the results given': 1,\n",
       "  'Roul, S. R.': 1,\n",
       "  'the problem that': 1,\n",
       "  ...}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef9548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
